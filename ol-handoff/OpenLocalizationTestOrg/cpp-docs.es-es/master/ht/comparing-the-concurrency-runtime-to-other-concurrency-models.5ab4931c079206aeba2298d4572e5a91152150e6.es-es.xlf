<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="es-es">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-04506c2" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c0f469847fb2e4a33a9c7341ecf29898c8071cbe</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">docs\parallel\concrt\comparing-the-concurrency-runtime-to-other-concurrency-models.md</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">4bcaa925accb78c3fa8efe179fc6010cdc0f5457</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d76a3fee68ecef6ad56ca5d3dff6cdb0166a10c2</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Comparing the Concurrency Runtime to Other Concurrency Models | Microsoft Docs</source>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Comparing the Concurrency Runtime to Other Concurrency Models</source>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>This document describes the differences between the features and programming models of the Concurrency Runtime and other technologies.</source>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>By understanding how the benefits of the Concurrency Runtime compare to the benefits of other programming models, you can select the technology that best satisfies the requirements of your applications.</source>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>If you are currently using another programming model, such as the Windows thread pool or OpenMP, there are situations where it can be appropriate to migrate to the Concurrency Runtime.</source>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>For example, the topic <bpt id="p1">[</bpt>Migrating from OpenMP to the Concurrency Runtime<ept id="p1">](../../parallel/concrt/migrating-from-openmp-to-the-concurrency-runtime.md)</ept> describes when it can be appropriate to migrate from OpenMP to the Concurrency Runtime.</source>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>However, if you are satisfied with application performance and current debugging support, migration is not required.</source>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>You can use the features and productivity benefits of the Concurrency Runtime to complement your existing application that uses another concurrency model.</source>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime cannot guarantee load balancing when multiple task schedulers compete for the same computing resources.</source>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>However, when workloads do not overlap, this effect is minimal.</source>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Sections</source>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Comparing Preemptive Scheduling to Cooperative Scheduling</source>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Comparing the Concurrency Runtime to the Windows API</source>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Comparing the Concurrency Runtime to OpenMP</source>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Comparing Preemptive Scheduling to Cooperative Scheduling</source>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The preemptive model and cooperative scheduling models are two common ways to enable multiple tasks to share computing resources, for example, processors or hardware threads.</source>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Preemptive and Cooperative Scheduling</source>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">*</bpt>Preemptive scheduling<ept id="p1">*</ept> is a round-robin, priority-based mechanism that gives every task exclusive access to a computing resource for a given time period, and then switches to another task.</source>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Preemptive scheduling is common in multitasking operating systems such as Windows<bpt id="p1">*</bpt>. Cooperative scheduling<ept id="p1">*</ept> is a mechanism that gives every task exclusive access to a computing resource until the task finishes or until the task yields its access to the resource.</source>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime uses cooperative scheduling together with the preemptive scheduler of the operating system to achieve maximum usage of processing resources.</source>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Differences Between Preemptive and Cooperative Schedulers</source>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Preemptive schedulers seek to give multiple threads equal access to computing resources to ensure that every thread makes progress.</source>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>On computers that have many computing resources, ensuring fair access becomes less problematic; however, ensuring efficient utilization of the resources becomes more problematic.</source>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>A preemptive kernel-mode scheduler requires the application code to rely on the operating system to make scheduling decisions.</source>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Conversely, a user-mode cooperative scheduler enables application code to make its own scheduling decisions.</source>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Because cooperative scheduling enables many scheduling decisions to be made by the application, it reduces much of the overhead that is associated with kernel-mode synchronization.</source>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>A cooperative scheduler typically defers scheduling decisions to the operating system kernel when it has no other work to schedule.</source>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>A cooperative scheduler also defers to the operating system scheduler when there is a blocking operation that is communicated to the kernel, but that operation is not communicated to the user-mode scheduler.</source>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Cooperative Scheduling and Efficiency</source>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>To a preemptive scheduler, all work that has the same priority level is equal.</source>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>A preemptive scheduler typically schedules threads in the order in which they are created.</source>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Furthermore, a preemptive scheduler gives every thread a time slice in a round-robin manner, based on thread priority.</source>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Although this mechanism provides fairness (every thread makes forward progress), it comes at some cost of efficiency.</source>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>For example, many computation-intensive algorithms do not require fairness.</source>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Instead, it is important that related tasks finish in the least overall time.</source>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Cooperative scheduling enables an application to more efficiently schedule work.</source>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>For example, consider an application that has many threads.</source>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Scheduling threads that do not share resources to run concurrently can reduce synchronization overhead and thereby increase efficiency.</source>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Another efficient way to schedule tasks is to run pipelines of tasks (where each task acts on the output of the previous one) on the same processor so that the input of each pipeline stage is already loaded into the memory cache.</source>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Using Preemptive and Cooperative Scheduling Together</source>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Cooperative scheduling does not solve all scheduling problems.</source>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>For example, tasks that do not fairly yield to other tasks can consume all available computing resources and prevent other tasks from making progress.</source>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime uses the efficiency benefits of cooperative scheduling to complement the fairness guarantees of preemptive scheduling.</source>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>By default, the Concurrency Runtime provides a cooperative scheduler that uses a work-stealing algorithm to efficiently distribute work among computing resources.</source>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>However, the Concurrency Runtime scheduler also relies on the preemptive scheduler of the operating system to fairly distribute resources among applications.</source>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>You can also create custom schedulers and scheduler policies in your applications to produce fine-grained control over thread execution.</source>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>[<bpt id="p1">[</bpt>Top<ept id="p1">](#top)</ept>]</source>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Comparing the Concurrency Runtime to the Windows API</source>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>The Microsoft Windows application programming interface, which is typically referred to as the Windows API (and formerly known as Win32), provides a programming model that enables concurrency in your applications.</source>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime builds on the Windows API to provide additional programming models that are not available from the underlying operating system.</source>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime builds on the Windows API thread model to perform parallel work.</source>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>It also uses the Windows API memory management and thread-local storage mechanisms.</source>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>On Windows 7 and Windows Server 2008 R2, it uses Windows API support for user-schedulable threads and computers that have more than 64 hardware threads.</source>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime extends the Windows API model by providing a cooperative task scheduler and a work-stealing algorithm to maximize the use of computing resources, and by enabling multiple simultaneous scheduler instances.</source>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Programming Languages</source>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>The Windows API uses the C programming language to expose the programming model.</source>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime provides a C++ programming interface that takes advantage of the newest features in the C++ language.</source>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>For example, lambda functions provide a succinct, type-safe mechanism for defining parallel work functions.</source>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>For more information about the newest C++ features that the Concurrency Runtime uses, see <bpt id="p1">[</bpt>Overview<ept id="p1">](../../parallel/concrt/asynchronous-message-blocks.md)</ept>.</source>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Threads and Thread Pools</source>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>The central concurrency mechanism in the Windows API is the thread.</source>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>You typically use the <bpt id="p1">[</bpt>CreateThread<ept id="p1">](http://msdn.microsoft.com/library/windows/desktop/ms682453)</ept> function to create threads.</source>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Although threads are relatively easy to create and use, the operating system allocates a significant amount of time and other resources to manage them.</source>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Additionally, although each thread is guaranteed to receive the same execution time as any other thread at the same priority level, the associated overhead requires that you create sufficiently large tasks.</source>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>For smaller or more fine-grained tasks, the overhead that is associated with concurrency can outweigh the benefit of running the tasks in parallel.</source>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Thread pools are one way to reduce the cost of thread management.</source>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Custom thread pools and the thread pool implementation that is provided by the Windows API both enable small work items to efficiently run in parallel.</source>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>The Windows thread pool maintains work items in a first-in, first-out (FIFO) queue.</source>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Each work item is started in the order in which it was added to the pool.</source>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime implements a work-stealing algorithm to extend the FIFO scheduling mechanism.</source>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>The algorithm moves tasks that have not yet started to threads that run out of work items.</source>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Although the work-stealing algorithm can balance workloads, it can also cause work items to be reordered.</source>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>This reordering process can cause a work item to start in a different order than it was submitted.</source>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>This is useful with recursive algorithms, where there is a better chance that data is shared among newer tasks than among older ones.</source>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Getting the new items to run first means fewer cache misses and possibly fewer page faults.</source>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>From the perspective of the operating system, work stealing is unfair.</source>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>However, when an application implements an algorithm or task to run in parallel, fairness among the sub-tasks does not always matter.</source>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>What does matter is how quickly the overall task finishes.</source>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>For other algorithms, FIFO is the appropriate scheduling strategy.</source>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Behavior on Various Operating Systems</source>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>On Windows XP and Windows Vista, applications that use the Concurrency Runtime behave similarly, except that heap performance is improved on Windows Vista.</source>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>In Windows 7 and Windows Server 2008 R2, the operating system further supports concurrency and scalability.</source>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>For example, these operating systems support computers that have more than 64 hardware threads.</source>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>An existing application that uses the Windows API must be modified to take advantage of these new features.</source>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>However, an application that uses the Concurrency Runtime automatically uses these features and does not require modifications.</source>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>base.user-mode_scheduling</source>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>[<bpt id="p1">[</bpt>Top<ept id="p1">](#top)</ept>]</source>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Comparing the Concurrency Runtime to OpenMP</source>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime enables a variety of programming models.</source>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>These models may overlap or complement the models of other libraries.</source>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>This section compares the Concurrency Runtime to <bpt id="p1">[</bpt>OpenMP<ept id="p1">](../../parallel/concrt/comparing-the-concurrency-runtime-to-other-concurrency-models.md#openmp)</ept>.</source>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>The OpenMP programming model is defined by an open standard and has well-defined bindings to the Fortran and C/C++ programming languages.</source>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>OpenMP versions 2.0 and 2.5 are well-suited for parallel algorithms that are iterative; that is, they perform parallel iteration over an array of data.</source>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>OpenMP is most efficient when the degree of parallelism is pre-determined and matches the available resources on the system.</source>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The OpenMP model is an especially good match for high-performance computing, where very large computational problems are distributed across the processing resources of a single computer.</source>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>In this scenario, the hardware environment is known and the developer can reasonably expect to have exclusive access to computing resources when the algorithm is executed.</source>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>However, other, less constrained computing environments may not be a good match for OpenMP.</source>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>For example, recursive problems (such as the quicksort algorithm or searching a tree of data) are more difficult to implement by using OpenMP.</source>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>The Concurrency Runtime complements the capabilities of OpenMP by providing the <bpt id="p1">[</bpt>Parallel Patterns Library<ept id="p1">](../../parallel/concrt/parallel-patterns-library-ppl.md)</ept> (PPL) and the <bpt id="p2">[</bpt>Asynchronous Agents Library<ept id="p2">](../../parallel/concrt/asynchronous-agents-library.md)</ept>.</source>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>Unlike OpenMP, the Concurrency Runtime provides a dynamic scheduler that adapts to available resources and adjusts the degree of parallelism as workloads change.</source>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Many of the features in the Concurrency Runtime can be extended.</source>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>You can also combine existing features to compose new ones.</source>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>Because OpenMP relies on compiler directives, it cannot be extended easily.</source>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>For more information about how the Concurrency Runtime compares to OpenMP and how to migrate existing OpenMP code to use the Concurrency Runtime, see <bpt id="p1">[</bpt>Migrating from OpenMP to the Concurrency Runtime<ept id="p1">](../../parallel/concrt/migrating-from-openmp-to-the-concurrency-runtime.md)</ept>.</source>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>[<bpt id="p1">[</bpt>Top<ept id="p1">](#top)</ept>]</source>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>See Also</source>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Concurrency Runtime</source>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Overview</source>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Parallel Patterns Library (PPL)</source>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Asynchronous Agents Library</source>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>OpenMP</source>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>