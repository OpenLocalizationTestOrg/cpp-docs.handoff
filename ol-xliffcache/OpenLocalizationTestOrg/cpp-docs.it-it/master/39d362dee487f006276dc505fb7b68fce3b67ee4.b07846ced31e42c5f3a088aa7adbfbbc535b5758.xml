{"nodes":[{"pos":[12,78],"content":"General Best Practices in the Concurrency Runtime | Microsoft Docs","needQuote":false,"needEscape":true,"nodes":[{"content":"General Best Practices in the Concurrency Runtime | Microsoft Docs","pos":[0,66]}]},{"content":"General Best Practices in the Concurrency Runtime","pos":[657,706]},{"content":"This document describes best practices that apply to multiple areas of the Concurrency Runtime.","pos":[707,802]},{"pos":[831,839],"content":"Sections"},{"content":"This document contains the following sections:","pos":[843,889]},{"content":"Use Cooperative Synchronization Constructs When Possible","pos":[898,954]},{"content":"Avoid Lengthy Tasks That Do Not Yield","pos":[982,1019]},{"content":"Use Oversubscription to Offset Operations That Block or Have High Latency","pos":[1037,1110]},{"content":"Use Concurrent Memory Management Functions When Possible","pos":[1139,1195]},{"content":"Use RAII to Manage the Lifetime of Concurrency Objects","pos":[1214,1268]},{"content":"Do Not Create Concurrency Objects at Global Scope","pos":[1285,1334]},{"content":"Do Not Use Concurrency Objects in Shared Data Segments","pos":[1359,1413]},{"pos":[1469,1525],"content":"Use Cooperative Synchronization Constructs When Possible"},{"content":"The Concurrency Runtime provides many concurrency-safe constructs that do not require an external synchronization object.","pos":[1529,1650]},{"content":"For example, the <bpt id=\"p1\">[</bpt>concurrency::concurrent_vector<ept id=\"p1\">](../../parallel/concrt/reference/concurrent-vector-class.md)</ept> class provides concurrency-safe append and element access operations.","pos":[1651,1830],"source":" For example, the [concurrency::concurrent_vector](../../parallel/concrt/reference/concurrent-vector-class.md) class provides concurrency-safe append and element access operations."},{"content":"However, for cases where you require exclusive access to a resource, the runtime provides the <bpt id=\"p1\">[</bpt>concurrency::critical_section<ept id=\"p1\">](../../parallel/concrt/reference/critical-section-class.md)</ept>, <bpt id=\"p2\">[</bpt>concurrency::reader_writer_lock<ept id=\"p2\">](../../parallel/concrt/reference/reader-writer-lock-class.md)</ept>, and <bpt id=\"p3\">[</bpt>concurrency::event<ept id=\"p3\">](../../parallel/concrt/reference/event-class.md)</ept> classes.","pos":[1831,2194],"source":" However, for cases where you require exclusive access to a resource, the runtime provides the [concurrency::critical_section](../../parallel/concrt/reference/critical-section-class.md), [concurrency::reader_writer_lock](../../parallel/concrt/reference/reader-writer-lock-class.md), and [concurrency::event](../../parallel/concrt/reference/event-class.md) classes."},{"content":"These types behave cooperatively; therefore, the task scheduler can reallocate processing resources to another context as the first task waits for data.","pos":[2195,2347]},{"content":"When possible, use these synchronization types instead of other synchronization mechanisms, such as those provided by the Windows API, which do not behave cooperatively.","pos":[2348,2517]},{"content":"For more information about these synchronization types and a code example, see <bpt id=\"p1\">[</bpt>Synchronization Data Structures<ept id=\"p1\">](../../parallel/concrt/synchronization-data-structures.md)</ept> and <bpt id=\"p2\">[</bpt>Comparing Synchronization Data Structures to the Windows API<ept id=\"p2\">](../../parallel/concrt/comparing-synchronization-data-structures-to-the-windows-api.md)</ept>.","pos":[2518,2843],"source":" For more information about these synchronization types and a code example, see [Synchronization Data Structures](../../parallel/concrt/synchronization-data-structures.md) and [Comparing Synchronization Data Structures to the Windows API](../../parallel/concrt/comparing-synchronization-data-structures-to-the-windows-api.md)."},{"pos":[2850,2863],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[2894,2931],"content":"Avoid Lengthy Tasks That Do Not Yield"},{"content":"Because the task scheduler behaves cooperatively, it does not provide fairness among tasks.","pos":[2935,3026]},{"content":"Therefore, a task can prevent other tasks from starting.","pos":[3027,3083]},{"content":"Although this is acceptable in some cases, in other cases this can cause deadlock or starvation.","pos":[3084,3180]},{"content":"The following example performs more tasks than the number of allocated processing resources.","pos":[3187,3279]},{"content":"The first task does not yield to the task scheduler and therefore the second task does not start until the first task finishes.","pos":[3280,3407]},{"pos":[3425,3451],"content":"concrt-cooperative-tasks#1"},{"content":"This example produces the following output:","pos":[3555,3598]},{"content":"1: 250000000 1: 500000000 1: 750000000 1: 1000000000 2: 250000000 2: 500000000 2: 750000000 2: 1000000000","pos":[3605,3710]},{"content":"There are several ways to enable cooperation between the two tasks.","pos":[3718,3785]},{"content":"One way is to occasionally yield to the task scheduler in a long-running task.","pos":[3786,3864]},{"content":"The following example modifies the <ph id=\"ph1\">`task`</ph> function to call the <bpt id=\"p1\">[</bpt>concurrency::Context::Yield<ept id=\"p1\">](reference/context-class.md#yield)</ept> method to yield execution to the task scheduler so that another task can run.","pos":[3865,4069],"source":" The following example modifies the `task` function to call the [concurrency::Context::Yield](reference/context-class.md#yield) method to yield execution to the task scheduler so that another task can run."},{"pos":[4088,4114],"content":"concrt-cooperative-tasks#2"},{"content":"This example produces the following output:","pos":[4218,4261]},{"content":"The <ph id=\"ph1\">`Context::Yield`</ph> method yields only another active thread on the scheduler to which the current thread belongs, a lightweight task, or another operating system thread.","pos":[4411,4582],"source":"The `Context::Yield` method yields only another active thread on the scheduler to which the current thread belongs, a lightweight task, or another operating system thread."},{"content":"This method does not yield to work that is scheduled to run in a <bpt id=\"p1\">[</bpt>concurrency::task_group<ept id=\"p1\">](reference/task-group-class.md)</ept> or <bpt id=\"p2\">[</bpt>concurrency::structured_task_group<ept id=\"p2\">](../../parallel/concrt/reference/structured-task-group-class.md)</ept> object but has not yet started.","pos":[4583,4840],"source":" This method does not yield to work that is scheduled to run in a [concurrency::task_group](reference/task-group-class.md) or [concurrency::structured_task_group](../../parallel/concrt/reference/structured-task-group-class.md) object but has not yet started."},{"content":"There are other ways to enable cooperation among long-running tasks.","pos":[4847,4915]},{"content":"You can break a large task into smaller subtasks.","pos":[4916,4965]},{"content":"You can also enable oversubscription during a lengthy task.","pos":[4966,5025]},{"content":"Oversubscription lets you create more threads than the available number of hardware threads.","pos":[5026,5118]},{"content":"Oversubscription is especially useful when a lengthy task contains a high amount of latency, for example, reading data from disk or from a network connection.","pos":[5119,5277]},{"content":"For more information about lightweight tasks and oversubscription, see <bpt id=\"p1\">[</bpt>Task Scheduler<ept id=\"p1\">](../../parallel/concrt/task-scheduler-concurrency-runtime.md)</ept>.","pos":[5278,5427],"source":" For more information about lightweight tasks and oversubscription, see [Task Scheduler](../../parallel/concrt/task-scheduler-concurrency-runtime.md)."},{"pos":[5434,5447],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[5489,5562],"content":"Use Oversubscription to Offset Operations That Block or Have High Latency"},{"content":"The Concurrency Runtime provides synchronization primitives, such as <bpt id=\"p1\">[</bpt>concurrency::critical_section<ept id=\"p1\">](../../parallel/concrt/reference/critical-section-class.md)</ept>, that enable tasks to cooperatively block and yield to each other.","pos":[5566,5792],"source":"The Concurrency Runtime provides synchronization primitives, such as [concurrency::critical_section](../../parallel/concrt/reference/critical-section-class.md), that enable tasks to cooperatively block and yield to each other."},{"content":"When one task cooperatively blocks or yields, the task scheduler can reallocate processing resources to another context as the first task waits for data.","pos":[5793,5946]},{"content":"There are cases in which you cannot use the cooperative blocking mechanism that is provided by the Concurrency Runtime.","pos":[5953,6072]},{"content":"For example, an external library that you use might use a different synchronization mechanism.","pos":[6073,6167]},{"content":"Another example is when you perform an operation that could have a high amount of latency, for example, when you use the Windows API <ph id=\"ph1\">`ReadFile`</ph> function to read data from a network connection.","pos":[6168,6360],"source":" Another example is when you perform an operation that could have a high amount of latency, for example, when you use the Windows API `ReadFile` function to read data from a network connection."},{"content":"In these cases, oversubscription can enable other tasks to run when another task is idle.","pos":[6361,6450]},{"content":"Oversubscription lets you create more threads than the available number of hardware threads.","pos":[6451,6543]},{"content":"Consider the following function, <ph id=\"ph1\">`download`</ph>, which downloads the file at the given URL.","pos":[6550,6637],"source":"Consider the following function, `download`, which downloads the file at the given URL."},{"content":"This example uses the <bpt id=\"p1\">[</bpt>concurrency::Context::Oversubscribe<ept id=\"p1\">](reference/context-class.md#oversubscribe)</ept> method to temporarily increase the number of active threads.","pos":[6638,6800],"source":" This example uses the [concurrency::Context::Oversubscribe](reference/context-class.md#oversubscribe) method to temporarily increase the number of active threads."},{"pos":[6816,6850],"content":"concrt-download-oversubscription#4"},{"content":"Because the <ph id=\"ph1\">`GetHttpFile`</ph> function performs a potentially latent operation, oversubscription can enable other tasks to run as the current task waits for data.","pos":[6954,7112],"source":"Because the `GetHttpFile` function performs a potentially latent operation, oversubscription can enable other tasks to run as the current task waits for data."},{"content":"For the complete version of this example, see <bpt id=\"p1\">[</bpt>How to: Use Oversubscription to Offset Latency<ept id=\"p1\">](../../parallel/concrt/how-to-use-oversubscription-to-offset-latency.md)</ept>.","pos":[7113,7280],"source":" For the complete version of this example, see [How to: Use Oversubscription to Offset Latency](../../parallel/concrt/how-to-use-oversubscription-to-offset-latency.md)."},{"pos":[7287,7300],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[7332,7388],"content":"Use Concurrent Memory Management Functions When Possible"},{"content":"Use the memory management functions, <bpt id=\"p1\">[</bpt>concurrency::Alloc<ept id=\"p1\">](reference/concurrency-namespace-functions.md#alloc)</ept> and <bpt id=\"p2\">[</bpt>concurrency::Free<ept id=\"p2\">](reference/concurrency-namespace-functions.md#free)</ept>, when you have fine-grained tasks that frequently allocate small objects that have a relatively short lifetime.","pos":[7393,7689],"source":"Use the memory management functions, [concurrency::Alloc](reference/concurrency-namespace-functions.md#alloc) and [concurrency::Free](reference/concurrency-namespace-functions.md#free), when you have fine-grained tasks that frequently allocate small objects that have a relatively short lifetime."},{"content":"The Concurrency Runtime holds a separate memory cache for each running thread.","pos":[7690,7768]},{"content":"The <ph id=\"ph1\">`Alloc`</ph> and <ph id=\"ph2\">`Free`</ph> functions allocate and free memory from these caches without the use of locks or memory barriers.","pos":[7769,7889],"source":" The `Alloc` and `Free` functions allocate and free memory from these caches without the use of locks or memory barriers."},{"content":"For more information about these memory management functions, see <bpt id=\"p1\">[</bpt>Task Scheduler<ept id=\"p1\">](../../parallel/concrt/task-scheduler-concurrency-runtime.md)</ept>.","pos":[7896,8040],"source":"For more information about these memory management functions, see [Task Scheduler](../../parallel/concrt/task-scheduler-concurrency-runtime.md)."},{"content":"For an example that uses these functions, see <bpt id=\"p1\">[</bpt>How to: Use Alloc and Free to Improve Memory Performance<ept id=\"p1\">](../../parallel/concrt/how-to-use-alloc-and-free-to-improve-memory-performance.md)</ept>.","pos":[8041,8228],"source":" For an example that uses these functions, see [How to: Use Alloc and Free to Improve Memory Performance](../../parallel/concrt/how-to-use-alloc-and-free-to-improve-memory-performance.md)."},{"pos":[8235,8248],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[8278,8332],"content":"Use RAII to Manage the Lifetime of Concurrency Objects"},{"content":"The Concurrency Runtime uses exception handling to implement features such as cancellation.","pos":[8336,8427]},{"content":"Therefore, write exception-safe code when you call into the runtime or call another library that calls into the runtime.","pos":[8428,8548]},{"content":"The <bpt id=\"p1\">*</bpt>Resource Acquisition Is Initialization<ept id=\"p1\">*</ept> (RAII) pattern is one way to safely manage the lifetime of a concurrency object under a given scope.","pos":[8555,8700],"source":"The *Resource Acquisition Is Initialization* (RAII) pattern is one way to safely manage the lifetime of a concurrency object under a given scope."},{"content":"Under the RAII pattern, a data structure is allocated on the stack.","pos":[8701,8768]},{"content":"That data structure initializes or acquires a resource when it is created and destroys or releases that resource when the data structure is destroyed.","pos":[8769,8919]},{"content":"The RAII pattern guarantees that the destructor is called before the enclosing scope exits.","pos":[8920,9011]},{"content":"This pattern is useful when a function contains multiple <ph id=\"ph1\">`return`</ph> statements.","pos":[9012,9089],"source":" This pattern is useful when a function contains multiple `return` statements."},{"content":"This pattern also helps you write exception-safe code.","pos":[9090,9144]},{"content":"When a <ph id=\"ph1\">`throw`</ph> statement causes the stack to unwind, the destructor for the RAII object is called; therefore, the resource is always correctly deleted or released.","pos":[9145,9308],"source":" When a `throw` statement causes the stack to unwind, the destructor for the RAII object is called; therefore, the resource is always correctly deleted or released."},{"content":"The runtime defines several classes that use the RAII pattern, for example, <bpt id=\"p1\">[</bpt>concurrency::critical_section::scoped_lock<ept id=\"p1\">](../../parallel/concrt/reference/critical-section-class.md#critical_section__scoped_lock_class)</ept> and <bpt id=\"p2\">[</bpt>concurrency::reader_writer_lock::scoped_lock<ept id=\"p2\">](reference/reader-writer-lock-class.md#scoped_lock_class)</ept>.","pos":[9315,9639],"source":"The runtime defines several classes that use the RAII pattern, for example, [concurrency::critical_section::scoped_lock](../../parallel/concrt/reference/critical-section-class.md#critical_section__scoped_lock_class) and [concurrency::reader_writer_lock::scoped_lock](reference/reader-writer-lock-class.md#scoped_lock_class)."},{"content":"These helper classes are known as <bpt id=\"p1\">*</bpt>scoped locks<ept id=\"p1\">*</ept>.","pos":[9640,9689],"source":" These helper classes are known as *scoped locks*."},{"content":"These classes provide several benefits when you work with <bpt id=\"p1\">[</bpt>concurrency::critical_section<ept id=\"p1\">](../../parallel/concrt/reference/critical-section-class.md)</ept> or <bpt id=\"p2\">[</bpt>concurrency::reader_writer_lock<ept id=\"p2\">](../../parallel/concrt/reference/reader-writer-lock-class.md)</ept> objects.","pos":[9690,9945],"source":" These classes provide several benefits when you work with [concurrency::critical_section](../../parallel/concrt/reference/critical-section-class.md) or [concurrency::reader_writer_lock](../../parallel/concrt/reference/reader-writer-lock-class.md) objects."},{"content":"The constructor of these classes acquires access to the provided <ph id=\"ph1\">`critical_section`</ph> or <ph id=\"ph2\">`reader_writer_lock`</ph> object; the destructor releases access to that object.","pos":[9946,10108],"source":" The constructor of these classes acquires access to the provided `critical_section` or `reader_writer_lock` object; the destructor releases access to that object."},{"content":"Because a scoped lock releases access to its mutual exclusion object automatically when it is destroyed, you do not manually unlock the underlying object.","pos":[10109,10263]},{"pos":[10270,10384],"content":"Consider the following class, <ph id=\"ph1\">`account`</ph>, which is defined by an external library and therefore cannot be modified.","source":"Consider the following class, `account`, which is defined by an external library and therefore cannot be modified."},{"pos":[10402,10431],"content":"concrt-account-transactions#1"},{"content":"The following example performs multiple transactions on an <ph id=\"ph1\">`account`</ph> object in parallel.","pos":[10533,10621],"source":"The following example performs multiple transactions on an `account` object in parallel."},{"content":"The example uses a <ph id=\"ph1\">`critical_section`</ph> object to synchronize access to the <ph id=\"ph2\">`account`</ph> object because the <ph id=\"ph3\">`account`</ph> class is not concurrency-safe.","pos":[10622,10765],"source":" The example uses a `critical_section` object to synchronize access to the `account` object because the `account` class is not concurrency-safe."},{"content":"Each parallel operation uses a <ph id=\"ph1\">`critical_section::scoped_lock`</ph> object to guarantee that the <ph id=\"ph2\">`critical_section`</ph> object is unlocked when the operation either succeeds or fails.","pos":[10766,10940],"source":" Each parallel operation uses a `critical_section::scoped_lock` object to guarantee that the `critical_section` object is unlocked when the operation either succeeds or fails."},{"content":"When the account balance is negative, the <ph id=\"ph1\">`withdraw`</ph> operation fails by throwing an exception.","pos":[10941,11035],"source":" When the account balance is negative, the `withdraw` operation fails by throwing an exception."},{"pos":[11053,11082],"content":"concrt-account-transactions#2"},{"content":"This example produces the following sample output:","pos":[11186,11236]},{"pos":[11469,11997],"content":"For additional examples that use the RAII pattern to manage the lifetime of concurrency objects, see <bpt id=\"p1\">[</bpt>Walkthrough: Removing Work from a User-Interface Thread<ept id=\"p1\">](../../parallel/concrt/walkthrough-removing-work-from-a-user-interface-thread.md)</ept>, <bpt id=\"p2\">[</bpt>How to: Use the Context Class to Implement a Cooperative Semaphore<ept id=\"p2\">](../../parallel/concrt/how-to-use-the-context-class-to-implement-a-cooperative-semaphore.md)</ept>, and <bpt id=\"p3\">[</bpt>How to: Use Oversubscription to Offset Latency<ept id=\"p3\">](../../parallel/concrt/how-to-use-oversubscription-to-offset-latency.md)</ept>.","source":"For additional examples that use the RAII pattern to manage the lifetime of concurrency objects, see [Walkthrough: Removing Work from a User-Interface Thread](../../parallel/concrt/walkthrough-removing-work-from-a-user-interface-thread.md), [How to: Use the Context Class to Implement a Cooperative Semaphore](../../parallel/concrt/how-to-use-the-context-class-to-implement-a-cooperative-semaphore.md), and [How to: Use Oversubscription to Offset Latency](../../parallel/concrt/how-to-use-oversubscription-to-offset-latency.md)."},{"pos":[12004,12017],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[12055,12104],"content":"Do Not Create Concurrency Objects at Global Scope"},{"content":"When you create a concurrency object at global scope you can cause issues such as deadlock or memory access violations to occur in your application.","pos":[12108,12256]},{"content":"For example, when you create a Concurrency Runtime object, the runtime creates a default scheduler for you if one was not yet created.","pos":[12263,12397]},{"content":"A runtime object that is created during global object construction will accordingly cause the runtime to create this default scheduler.","pos":[12398,12533]},{"content":"However, this process takes an internal lock, which can interfere with the initialization of other objects that support the Concurrency Runtime infrastructure.","pos":[12534,12693]},{"content":"This internal lock might be required by another infrastructure object that has not yet been initialized, and can thus cause deadlock to occur in your application.","pos":[12694,12856]},{"content":"The following example demonstrates the creation of a global <bpt id=\"p1\">[</bpt>concurrency::Scheduler<ept id=\"p1\">](../../parallel/concrt/reference/scheduler-class.md)</ept> object.","pos":[12863,13007],"source":"The following example demonstrates the creation of a global [concurrency::Scheduler](../../parallel/concrt/reference/scheduler-class.md) object."},{"content":"This pattern applies not only to the <ph id=\"ph1\">`Scheduler`</ph> class but all other types that are provided by the Concurrency Runtime.","pos":[13008,13128],"source":" This pattern applies not only to the `Scheduler` class but all other types that are provided by the Concurrency Runtime."},{"content":"We recommend that you do not follow this pattern because it can cause unexpected behavior in your application.","pos":[13129,13239]},{"pos":[13257,13282],"content":"concrt-global-scheduler#1"},{"pos":[13386,13531],"content":"For examples of the correct way to create <ph id=\"ph1\">`Scheduler`</ph> objects, see <bpt id=\"p1\">[</bpt>Task Scheduler<ept id=\"p1\">](../../parallel/concrt/task-scheduler-concurrency-runtime.md)</ept>.","source":"For examples of the correct way to create `Scheduler` objects, see [Task Scheduler](../../parallel/concrt/task-scheduler-concurrency-runtime.md)."},{"pos":[13538,13551],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[13588,13642],"content":"Do Not Use Concurrency Objects in Shared Data Segments"},{"content":"The Concurrency Runtime does not support the use of concurrency objects in a shared data section, for example, a data section that is created by the <bpt id=\"p1\">[</bpt>data_seg<ept id=\"p1\">](../../preprocessor/data-seg.md)</ept><ph id=\"ph1\">`#pragma`</ph> directive.","pos":[13646,13857],"source":"The Concurrency Runtime does not support the use of concurrency objects in a shared data section, for example, a data section that is created by the [data_seg](../../preprocessor/data-seg.md)`#pragma` directive."},{"content":"A concurrency object that is shared across process boundaries could put the runtime in an inconsistent or invalid state.","pos":[13858,13978]},{"pos":[13985,13998],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"content":"See Also","pos":[14007,14015]},{"content":"Concurrency Runtime Best Practices","pos":[14020,14054]},{"content":"Parallel Patterns Library (PPL)","pos":[14122,14153]},{"content":"Asynchronous Agents Library","pos":[14216,14243]},{"content":"Task Scheduler","pos":[14304,14318]},{"content":"Synchronization Data Structures","pos":[14386,14417]},{"content":"Comparing Synchronization Data Structures to the Windows API","pos":[14482,14542]},{"content":"How to: Use Alloc and Free to Improve Memory Performance","pos":[14636,14692]},{"content":"How to: Use Oversubscription to Offset Latency","pos":[14781,14827]},{"content":"How to: Use the Context Class to Implement a Cooperative Semaphore","pos":[14906,14972]},{"content":"Walkthrough: Removing Work from a User-Interface Thread","pos":[15071,15126]},{"content":"Best Practices in the Parallel Patterns Library","pos":[15214,15261]},{"content":"Best Practices in the Asynchronous Agents Library","pos":[15342,15391]}],"content":"---\ntitle: \"General Best Practices in the Concurrency Runtime | Microsoft Docs\"\nms.custom: \"\"\nms.date: \"11/04/2016\"\nms.reviewer: \"\"\nms.suite: \"\"\nms.technology: \n  - \"devlang-cpp\"\nms.tgt_pltfrm: \"\"\nms.topic: \"article\"\ndev_langs: \n  - \"C++\"\nhelpviewer_keywords: \n  - \"Concurrency Runtime, general best practices\"\nms.assetid: ce5c784c-051e-44a6-be84-8b3e1139c18b\ncaps.latest.revision: 16\nauthor: \"mikeblome\"\nms.author: \"mblome\"\nmanager: \"ghogen\"\ntranslation.priority.ht: \n  - \"de-de\"\n  - \"es-es\"\n  - \"fr-fr\"\n  - \"it-it\"\n  - \"ja-jp\"\n  - \"ko-kr\"\n  - \"ru-ru\"\n  - \"zh-cn\"\n  - \"zh-tw\"\ntranslation.priority.mt: \n  - \"cs-cz\"\n  - \"pl-pl\"\n  - \"pt-br\"\n  - \"tr-tr\"\n---\n# General Best Practices in the Concurrency Runtime\nThis document describes best practices that apply to multiple areas of the Concurrency Runtime.  \n  \n##  <a name=\"top\"></a> Sections  \n This document contains the following sections:  \n  \n- [Use Cooperative Synchronization Constructs When Possible](#synchronization)  \n  \n- [Avoid Lengthy Tasks That Do Not Yield](#yield)  \n  \n- [Use Oversubscription to Offset Operations That Block or Have High Latency](#oversubscription)  \n  \n- [Use Concurrent Memory Management Functions When Possible](#memory)  \n  \n- [Use RAII to Manage the Lifetime of Concurrency Objects](#raii)  \n  \n- [Do Not Create Concurrency Objects at Global Scope](#global-scope)  \n  \n- [Do Not Use Concurrency Objects in Shared Data Segments](#shared-data)  \n  \n##  <a name=\"synchronization\"></a> Use Cooperative Synchronization Constructs When Possible  \n The Concurrency Runtime provides many concurrency-safe constructs that do not require an external synchronization object. For example, the [concurrency::concurrent_vector](../../parallel/concrt/reference/concurrent-vector-class.md) class provides concurrency-safe append and element access operations. However, for cases where you require exclusive access to a resource, the runtime provides the [concurrency::critical_section](../../parallel/concrt/reference/critical-section-class.md), [concurrency::reader_writer_lock](../../parallel/concrt/reference/reader-writer-lock-class.md), and [concurrency::event](../../parallel/concrt/reference/event-class.md) classes. These types behave cooperatively; therefore, the task scheduler can reallocate processing resources to another context as the first task waits for data. When possible, use these synchronization types instead of other synchronization mechanisms, such as those provided by the Windows API, which do not behave cooperatively. For more information about these synchronization types and a code example, see [Synchronization Data Structures](../../parallel/concrt/synchronization-data-structures.md) and [Comparing Synchronization Data Structures to the Windows API](../../parallel/concrt/comparing-synchronization-data-structures-to-the-windows-api.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"yield\"></a> Avoid Lengthy Tasks That Do Not Yield  \n Because the task scheduler behaves cooperatively, it does not provide fairness among tasks. Therefore, a task can prevent other tasks from starting. Although this is acceptable in some cases, in other cases this can cause deadlock or starvation.  \n  \n The following example performs more tasks than the number of allocated processing resources. The first task does not yield to the task scheduler and therefore the second task does not start until the first task finishes.  \n  \n [!code-cpp[concrt-cooperative-tasks#1](../../parallel/concrt/codesnippet/cpp/general-best-practices-in-the-concurrency-runtime_1.cpp)]  \n  \n This example produces the following output:  \n  \n 1: 250000000 1: 500000000 1: 750000000 1: 1000000000 2: 250000000 2: 500000000 2: 750000000 2: 1000000000  \n  \n\n There are several ways to enable cooperation between the two tasks. One way is to occasionally yield to the task scheduler in a long-running task. The following example modifies the `task` function to call the [concurrency::Context::Yield](reference/context-class.md#yield) method to yield execution to the task scheduler so that another task can run.  \n\n  \n [!code-cpp[concrt-cooperative-tasks#2](../../parallel/concrt/codesnippet/cpp/general-best-practices-in-the-concurrency-runtime_2.cpp)]  \n  \n This example produces the following output:  \n  \n```Output  \n1: 250000000  \n2: 250000000  \n1: 500000000  \n2: 500000000  \n1: 750000000  \n2: 750000000  \n1: 1000000000  \n2: 1000000000  \n```  \n  \n The `Context::Yield` method yields only another active thread on the scheduler to which the current thread belongs, a lightweight task, or another operating system thread. This method does not yield to work that is scheduled to run in a [concurrency::task_group](reference/task-group-class.md) or [concurrency::structured_task_group](../../parallel/concrt/reference/structured-task-group-class.md) object but has not yet started.  \n  \n There are other ways to enable cooperation among long-running tasks. You can break a large task into smaller subtasks. You can also enable oversubscription during a lengthy task. Oversubscription lets you create more threads than the available number of hardware threads. Oversubscription is especially useful when a lengthy task contains a high amount of latency, for example, reading data from disk or from a network connection. For more information about lightweight tasks and oversubscription, see [Task Scheduler](../../parallel/concrt/task-scheduler-concurrency-runtime.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"oversubscription\"></a> Use Oversubscription to Offset Operations That Block or Have High Latency  \n The Concurrency Runtime provides synchronization primitives, such as [concurrency::critical_section](../../parallel/concrt/reference/critical-section-class.md), that enable tasks to cooperatively block and yield to each other. When one task cooperatively blocks or yields, the task scheduler can reallocate processing resources to another context as the first task waits for data.  \n  \n There are cases in which you cannot use the cooperative blocking mechanism that is provided by the Concurrency Runtime. For example, an external library that you use might use a different synchronization mechanism. Another example is when you perform an operation that could have a high amount of latency, for example, when you use the Windows API `ReadFile` function to read data from a network connection. In these cases, oversubscription can enable other tasks to run when another task is idle. Oversubscription lets you create more threads than the available number of hardware threads.  \n  \n Consider the following function, `download`, which downloads the file at the given URL. This example uses the [concurrency::Context::Oversubscribe](reference/context-class.md#oversubscribe) method to temporarily increase the number of active threads.  \n\n [!code-cpp[concrt-download-oversubscription#4](../../parallel/concrt/codesnippet/cpp/general-best-practices-in-the-concurrency-runtime_3.cpp)]  \n  \n Because the `GetHttpFile` function performs a potentially latent operation, oversubscription can enable other tasks to run as the current task waits for data. For the complete version of this example, see [How to: Use Oversubscription to Offset Latency](../../parallel/concrt/how-to-use-oversubscription-to-offset-latency.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"memory\"></a> Use Concurrent Memory Management Functions When Possible  \n\n Use the memory management functions, [concurrency::Alloc](reference/concurrency-namespace-functions.md#alloc) and [concurrency::Free](reference/concurrency-namespace-functions.md#free), when you have fine-grained tasks that frequently allocate small objects that have a relatively short lifetime. The Concurrency Runtime holds a separate memory cache for each running thread. The `Alloc` and `Free` functions allocate and free memory from these caches without the use of locks or memory barriers.  \n  \n For more information about these memory management functions, see [Task Scheduler](../../parallel/concrt/task-scheduler-concurrency-runtime.md). For an example that uses these functions, see [How to: Use Alloc and Free to Improve Memory Performance](../../parallel/concrt/how-to-use-alloc-and-free-to-improve-memory-performance.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"raii\"></a> Use RAII to Manage the Lifetime of Concurrency Objects  \n The Concurrency Runtime uses exception handling to implement features such as cancellation. Therefore, write exception-safe code when you call into the runtime or call another library that calls into the runtime.  \n  \n The *Resource Acquisition Is Initialization* (RAII) pattern is one way to safely manage the lifetime of a concurrency object under a given scope. Under the RAII pattern, a data structure is allocated on the stack. That data structure initializes or acquires a resource when it is created and destroys or releases that resource when the data structure is destroyed. The RAII pattern guarantees that the destructor is called before the enclosing scope exits. This pattern is useful when a function contains multiple `return` statements. This pattern also helps you write exception-safe code. When a `throw` statement causes the stack to unwind, the destructor for the RAII object is called; therefore, the resource is always correctly deleted or released.  \n  \n The runtime defines several classes that use the RAII pattern, for example, [concurrency::critical_section::scoped_lock](../../parallel/concrt/reference/critical-section-class.md#critical_section__scoped_lock_class) and [concurrency::reader_writer_lock::scoped_lock](reference/reader-writer-lock-class.md#scoped_lock_class). These helper classes are known as *scoped locks*. These classes provide several benefits when you work with [concurrency::critical_section](../../parallel/concrt/reference/critical-section-class.md) or [concurrency::reader_writer_lock](../../parallel/concrt/reference/reader-writer-lock-class.md) objects. The constructor of these classes acquires access to the provided `critical_section` or `reader_writer_lock` object; the destructor releases access to that object. Because a scoped lock releases access to its mutual exclusion object automatically when it is destroyed, you do not manually unlock the underlying object.  \n  \n Consider the following class, `account`, which is defined by an external library and therefore cannot be modified.  \n  \n [!code-cpp[concrt-account-transactions#1](../../parallel/concrt/codesnippet/cpp/general-best-practices-in-the-concurrency-runtime_4.h)]  \n  \n The following example performs multiple transactions on an `account` object in parallel. The example uses a `critical_section` object to synchronize access to the `account` object because the `account` class is not concurrency-safe. Each parallel operation uses a `critical_section::scoped_lock` object to guarantee that the `critical_section` object is unlocked when the operation either succeeds or fails. When the account balance is negative, the `withdraw` operation fails by throwing an exception.  \n  \n [!code-cpp[concrt-account-transactions#2](../../parallel/concrt/codesnippet/cpp/general-best-practices-in-the-concurrency-runtime_5.cpp)]  \n  \n This example produces the following sample output:  \n  \n```Output  \nBalance before deposit: 1924  \nBalance after deposit: 2924  \nBalance before withdrawal: 2924  \nBalance after withdrawal: -76  \nBalance before withdrawal: -76  \nError details:  \n    negative balance: -76  \n```  \n  \n For additional examples that use the RAII pattern to manage the lifetime of concurrency objects, see [Walkthrough: Removing Work from a User-Interface Thread](../../parallel/concrt/walkthrough-removing-work-from-a-user-interface-thread.md), [How to: Use the Context Class to Implement a Cooperative Semaphore](../../parallel/concrt/how-to-use-the-context-class-to-implement-a-cooperative-semaphore.md), and [How to: Use Oversubscription to Offset Latency](../../parallel/concrt/how-to-use-oversubscription-to-offset-latency.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"global-scope\"></a> Do Not Create Concurrency Objects at Global Scope  \n When you create a concurrency object at global scope you can cause issues such as deadlock or memory access violations to occur in your application.  \n  \n For example, when you create a Concurrency Runtime object, the runtime creates a default scheduler for you if one was not yet created. A runtime object that is created during global object construction will accordingly cause the runtime to create this default scheduler. However, this process takes an internal lock, which can interfere with the initialization of other objects that support the Concurrency Runtime infrastructure. This internal lock might be required by another infrastructure object that has not yet been initialized, and can thus cause deadlock to occur in your application.  \n  \n The following example demonstrates the creation of a global [concurrency::Scheduler](../../parallel/concrt/reference/scheduler-class.md) object. This pattern applies not only to the `Scheduler` class but all other types that are provided by the Concurrency Runtime. We recommend that you do not follow this pattern because it can cause unexpected behavior in your application.  \n  \n [!code-cpp[concrt-global-scheduler#1](../../parallel/concrt/codesnippet/cpp/general-best-practices-in-the-concurrency-runtime_6.cpp)]  \n  \n For examples of the correct way to create `Scheduler` objects, see [Task Scheduler](../../parallel/concrt/task-scheduler-concurrency-runtime.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"shared-data\"></a> Do Not Use Concurrency Objects in Shared Data Segments  \n The Concurrency Runtime does not support the use of concurrency objects in a shared data section, for example, a data section that is created by the [data_seg](../../preprocessor/data-seg.md)`#pragma` directive. A concurrency object that is shared across process boundaries could put the runtime in an inconsistent or invalid state.  \n  \n [[Top](#top)]  \n  \n## See Also  \n [Concurrency Runtime Best Practices](../../parallel/concrt/concurrency-runtime-best-practices.md)   \n [Parallel Patterns Library (PPL)](../../parallel/concrt/parallel-patterns-library-ppl.md)   \n [Asynchronous Agents Library](../../parallel/concrt/asynchronous-agents-library.md)   \n [Task Scheduler](../../parallel/concrt/task-scheduler-concurrency-runtime.md)   \n [Synchronization Data Structures](../../parallel/concrt/synchronization-data-structures.md)   \n [Comparing Synchronization Data Structures to the Windows API](../../parallel/concrt/comparing-synchronization-data-structures-to-the-windows-api.md)   \n [How to: Use Alloc and Free to Improve Memory Performance](../../parallel/concrt/how-to-use-alloc-and-free-to-improve-memory-performance.md)   \n [How to: Use Oversubscription to Offset Latency](../../parallel/concrt/how-to-use-oversubscription-to-offset-latency.md)   \n [How to: Use the Context Class to Implement a Cooperative Semaphore](../../parallel/concrt/how-to-use-the-context-class-to-implement-a-cooperative-semaphore.md)   \n [Walkthrough: Removing Work from a User-Interface Thread](../../parallel/concrt/walkthrough-removing-work-from-a-user-interface-thread.md)   \n [Best Practices in the Parallel Patterns Library](../../parallel/concrt/best-practices-in-the-parallel-patterns-library.md)   \n [Best Practices in the Asynchronous Agents Library](../../parallel/concrt/best-practices-in-the-asynchronous-agents-library.md)\n"}