{"nodes":[{"pos":[12,60],"content":"concurrency namespace functions | Microsoft Docs","needQuote":false,"needEscape":true,"nodes":[{"content":"concurrency namespace functions | Microsoft Docs","pos":[0,48]}]},{"content":"concurrency namespace functions","pos":[302,333]},{"content":"Alloc","pos":[353,358]},{"content":"CreateResourceManager","pos":[369,390]},{"content":"DisableTracing","pos":[417,431]},{"content":"EnableTracing","pos":[455,468]},{"content":"Free","pos":[487,491]},{"content":"GetExecutionContextId","pos":[501,522]},{"content":"GetOSVersion","pos":[553,565]},{"content":"GetProcessorCount","pos":[583,600]},{"content":"GetProcessorNodeCount","pos":[623,644]},{"content":"GetSchedulerId","pos":[675,689]},{"content":"Trace_agents_register_name","pos":[709,735]},{"content":"asend","pos":[767,772]},{"content":"cancel_current_task","pos":[787,806]},{"content":"clear","pos":[831,836]},{"content":"create_async","pos":[847,859]},{"content":"create_task","pos":[881,892]},{"content":"get_ambient_scheduler","pos":[909,930]},{"content":"internal_assign_iterators","pos":[957,982]},{"content":"interruption_point","pos":[1017,1035]},{"content":"is_current_task_group_canceling","pos":[1059,1090]},{"content":"make_choice","pos":[1127,1138]},{"content":"make_greedy_join","pos":[1159,1175]},{"content":"make_join","pos":[1197,1206]},{"content":"make_task","pos":[1221,1230]},{"content":"parallel_buffered_sort","pos":[1249,1271]},{"content":"parallel_for","pos":[1299,1311]},{"content":"parallel_for_each","pos":[1329,1346]},{"content":"parallel_invoke","pos":[1373,1388]},{"content":"parallel_radixsort","pos":[1409,1427]},{"content":"parallel_reduce","pos":[1451,1466]},{"content":"parallel_sort","pos":[1491,1504]},{"content":"parallel_transform","pos":[1523,1541]},{"content":"receive","pos":[1565,1572]},{"content":"run_with_cancellation_token","pos":[1589,1616]},{"content":"send","pos":[1649,1653]},{"content":"set_ambient_scheduler","pos":[1663,1684]},{"content":"set_task_execution_resources","pos":[1715,1743]},{"content":"swap","pos":[1777,1781]},{"content":"task_from_exception","pos":[1791,1810]},{"content":"task_from_result","pos":[1839,1855]},{"content":"try_receive","pos":[1877,1888]},{"content":"wait","pos":[1905,1909]},{"content":"when_all","pos":[1923,1931]},{"content":"when_any","pos":[1945,1953]},{"pos":[1998,2003],"content":"Alloc"},{"content":"Allocates a block of memory of the size specified from the Concurrency Runtime Caching Suballocator.","pos":[2007,2107]},{"content":"Parameters","pos":[2169,2179]},{"content":"The number of bytes of memory to allocate.","pos":[2198,2240]},{"content":"Return Value","pos":[2250,2262]},{"content":"A pointer to newly allocated memory.","pos":[2266,2302]},{"content":"Remarks","pos":[2312,2319]},{"pos":[2323,2522],"content":"For more information about which scenarios in your application could benefit from using the Caching Suballocator, see <bpt id=\"p1\">[</bpt>Task Scheduler<ept id=\"p1\">](../../../parallel/concrt/task-scheduler-concurrency-runtime.md)</ept>.","source":"For more information about which scenarios in your application could benefit from using the Caching Suballocator, see [Task Scheduler](../../../parallel/concrt/task-scheduler-concurrency-runtime.md)."},{"pos":[2554,2559],"content":"asend"},{"content":"An asynchronous send operation, which schedules a task to propagate the data to the target block.","pos":[2563,2660]},{"content":"Parameters","pos":[2840,2850]},{"content":"The type of the data to be sent.","pos":[2861,2893]},{"content":"A pointer or reference to the target to which data is sent.","pos":[2910,2969]},{"content":"A reference to the data to be sent.","pos":[2987,3022]},{"content":"Return Value","pos":[3032,3044]},{"pos":[3055,3129],"content":"if the message was accepted before the method returned, <ph id=\"ph1\">`false`</ph> otherwise.","source":" if the message was accepted before the method returned, `false` otherwise."},{"content":"Remarks","pos":[3139,3146]},{"pos":[3150,3259],"content":"For more information, see <bpt id=\"p1\">[</bpt>Message Passing Functions<ept id=\"p1\">](../../../parallel/concrt/message-passing-functions.md)</ept>.","source":"For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md)."},{"pos":[3305,3324],"content":"cancel_current_task"},{"content":"Cancels the currently executing task.","pos":[3328,3365]},{"content":"This function can be called from within the body of a task to abort the task's execution and cause it to enter the <ph id=\"ph1\">`canceled`</ph> state.","pos":[3366,3498],"source":" This function can be called from within the body of a task to abort the task's execution and cause it to enter the `canceled` state."},{"content":"It is not a supported scenario to call this function if you are not within the body of a <ph id=\"ph1\">`task`</ph>.","pos":[3505,3601],"source":"It is not a supported scenario to call this function if you are not within the body of a `task`."},{"content":"Doing so will result in undefined behavior such as a crash or a hang in your application.","pos":[3602,3691]},{"pos":[3800,3805],"content":"clear"},{"content":"Clears the concurrent queue, destroying any currently enqueued elements.","pos":[3809,3881]},{"content":"This method is not concurrency-safe.","pos":[3882,3918]},{"content":"Parameters","pos":[4018,4028]},{"pos":[4083,4095],"content":"create_async"},{"content":"Creates a Windows Runtime asynchronous construct based on a user supplied lambda or function object.","pos":[4099,4199]},{"content":"The return type of <ph id=\"ph1\">`create_async`</ph> is one of either <ph id=\"ph2\">`IAsyncAction^`</ph>, <ph id=\"ph3\">`IAsyncActionWithProgress&lt;TProgress&gt;^`</ph>, <ph id=\"ph4\">`IAsyncOperation&lt;TResult&gt;^`</ph>, or <ph id=\"ph5\">`IAsyncOperationWithProgress&lt;TResult, TProgress&gt;^`</ph> based on the signature of the lambda passed to the method.","pos":[4200,4449],"source":" The return type of `create_async` is one of either `IAsyncAction^`, `IAsyncActionWithProgress<TProgress>^`, `IAsyncOperation<TResult>^`, or `IAsyncOperationWithProgress<TResult, TProgress>^` based on the signature of the lambda passed to the method."},{"content":"Parameters","pos":[4638,4648]},{"content":"The lambda or function object from which to create a Windows Runtime asynchronous construct.","pos":[4678,4770]},{"content":"Return Value","pos":[4780,4792]},{"content":"An asynchronous construct represented by an IAsyncAction^, IAsyncActionWithProgress<ph id=\"ph1\">\\&lt;</ph>TProgress&gt;^, IAsyncOperation<ph id=\"ph2\">\\&lt;</ph>TResult&gt;^, or an IAsyncOperationWithProgress<ph id=\"ph3\">\\&lt;</ph>TResult, TProgress&gt;^.","pos":[4796,4978],"source":"An asynchronous construct represented by an IAsyncAction^, IAsyncActionWithProgress\\<TProgress>^, IAsyncOperation\\<TResult>^, or an IAsyncOperationWithProgress\\<TResult, TProgress>^."},{"content":"The interface returned depends on the signature of the lambda passed into the function.","pos":[4979,5066]},{"content":"Remarks","pos":[5076,5083]},{"content":"The return type of the lambda determines whether the construct is an action or an operation.","pos":[5087,5179]},{"content":"Lambdas that return void cause the creation of actions.","pos":[5186,5241]},{"content":"Lambdas that return a result of type <ph id=\"ph1\">`TResult`</ph> cause the creation of operations of TResult.","pos":[5242,5333],"source":" Lambdas that return a result of type `TResult` cause the creation of operations of TResult."},{"content":"The lambda may also return a <ph id=\"ph1\">`task&lt;TResult&gt;`</ph> which encapsulates the aysnchronous work within itself or is the continuation of a chain of tasks that represent the asynchronous work.","pos":[5340,5520],"source":"The lambda may also return a `task<TResult>` which encapsulates the aysnchronous work within itself or is the continuation of a chain of tasks that represent the asynchronous work."},{"content":"In this case, the lambda itself is executed inline, since the tasks are the ones that execute asynchronously, and the return type of the lambda is unwrapped to produce the asynchronous construct returned by <ph id=\"ph1\">`create_async`</ph>.","pos":[5521,5743],"source":" In this case, the lambda itself is executed inline, since the tasks are the ones that execute asynchronously, and the return type of the lambda is unwrapped to produce the asynchronous construct returned by `create_async`."},{"content":"This implies that a lambda that returns a task<ph id=\"ph1\">\\&lt;</ph>void&gt; will cause the creation of actions, and a lambda that returns a task<ph id=\"ph2\">\\&lt;</ph>TResult&gt; will cause the creation of operations of TResult.","pos":[5744,5926],"source":" This implies that a lambda that returns a task\\<void> will cause the creation of actions, and a lambda that returns a task\\<TResult> will cause the creation of operations of TResult."},{"content":"The lambda may take either zero, one or two arguments.","pos":[5933,5987]},{"content":"The valid arguments are <ph id=\"ph1\">`progress_reporter&lt;TProgress&gt;`</ph> and <ph id=\"ph2\">`cancellation_token`</ph>, in that order if both are used.","pos":[5988,6100],"source":" The valid arguments are `progress_reporter<TProgress>` and `cancellation_token`, in that order if both are used."},{"content":"A lambda without arguments causes the creation of an asynchronous construct without the capability for progress reporting.","pos":[6101,6223]},{"content":"A lambda that takes a progress_reporter<ph id=\"ph1\">\\&lt;</ph>TProgress&gt; will cause <ph id=\"ph2\">`create_async`</ph> to return an asynchronous construct which reports progress of type TProgress each time the <ph id=\"ph3\">`report`</ph> method of the progress_reporter object is called.","pos":[6224,6451],"source":" A lambda that takes a progress_reporter\\<TProgress> will cause `create_async` to return an asynchronous construct which reports progress of type TProgress each time the `report` method of the progress_reporter object is called."},{"content":"A lambda that takes a cancellation_token may use that token to check for cancellation, or pass it to tasks that it creates so that cancellation of the asynchronous construct causes cancellation of those tasks.","pos":[6452,6661]},{"content":"If the body of the lambda or function object returns a result (and not a task<ph id=\"ph1\">\\&lt;</ph>TResult&gt;), the lamdba will be executed asynchronously within the process MTA in the context of a task the Runtime implicitly creates for it.","pos":[6668,6887],"source":"If the body of the lambda or function object returns a result (and not a task\\<TResult>), the lamdba will be executed asynchronously within the process MTA in the context of a task the Runtime implicitly creates for it."},{"content":"The <ph id=\"ph1\">`IAsyncInfo::Cancel`</ph> method will cause cancellation of the implicit task.","pos":[6888,6965],"source":" The `IAsyncInfo::Cancel` method will cause cancellation of the implicit task."},{"content":"If the body of the lambda returns a task, the lamba executes inline, and by declaring the lambda to take an argument of type <ph id=\"ph1\">`cancellation_token`</ph> you can trigger cancellation of any tasks you create within the lambda by passing that token in when you create them.","pos":[6972,7235],"source":"If the body of the lambda returns a task, the lamba executes inline, and by declaring the lambda to take an argument of type `cancellation_token` you can trigger cancellation of any tasks you create within the lambda by passing that token in when you create them."},{"content":"You may also use the <ph id=\"ph1\">`register_callback`</ph> method on the token to cause the Runtime to invoke a callback when you call <ph id=\"ph2\">`IAsyncInfo::Cancel`</ph> on the async operation or action produced..","pos":[7236,7417],"source":" You may also use the `register_callback` method on the token to cause the Runtime to invoke a callback when you call `IAsyncInfo::Cancel` on the async operation or action produced.."},{"content":"This function is only available to Windows Store apps.","pos":[7424,7478]},{"pos":[7526,7547],"content":"CreateResourceManager"},{"content":"Returns an interface that represents the singleton instance of the Concurrency Runtime's Resource Manager.","pos":[7551,7657]},{"content":"The Resource Manager is responsible for assigning resources to schedulers that want to cooperate with each other.","pos":[7658,7771]},{"content":"Return Value","pos":[7845,7857]},{"pos":[7861,7893],"content":"An <ph id=\"ph1\">`IResourceManager`</ph> interface.","source":"An `IResourceManager` interface."},{"content":"Remarks","pos":[7903,7910]},{"content":"Multiple subsequent calls to this method will return the same instance of the Resource Manager.","pos":[7914,8009]},{"content":"Each call to the method increments a reference count on the Resource Manager, and must be matched with a call to the <bpt id=\"p1\">[</bpt>IResourceManager::Release<ept id=\"p1\">](http://msdn.microsoft.com/en-us/5d1356ec-fbd3-4284-a361-1e9e20bbb522)</ept> method when your scheduler is done communicating with the Resource Manager.","pos":[8010,8300],"source":" Each call to the method increments a reference count on the Resource Manager, and must be matched with a call to the [IResourceManager::Release](http://msdn.microsoft.com/en-us/5d1356ec-fbd3-4284-a361-1e9e20bbb522) method when your scheduler is done communicating with the Resource Manager."},{"pos":[8307,8427],"content":"<bpt id=\"p1\">[</bpt>unsupported_os<ept id=\"p1\">](unsupported-os-class.md)</ept> is thrown if the operating system is not supported by the Concurrency Runtime.","source":"[unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime."},{"pos":[8465,8476],"content":"create_task"},{"content":"Creates a PPL <bpt id=\"p1\">[</bpt>task<ept id=\"p1\">](http://msdn.microsoft.com/en-us/5389e8a5-5038-40b6-844a-55e9b58ad35f)</ept> object.","pos":[8480,8578],"source":"Creates a PPL [task](http://msdn.microsoft.com/en-us/5389e8a5-5038-40b6-844a-55e9b58ad35f) object."},{"content":"can be used anywhere you would have used a task constructor.","pos":[8593,8653]},{"content":"It is provided mainly for convenience, because it allows use of the <ph id=\"ph1\">`auto`</ph> keyword while creating tasks.","pos":[8654,8758],"source":" It is provided mainly for convenience, because it allows use of the `auto` keyword while creating tasks."},{"content":"Parameters","pos":[9080,9090]},{"content":"The type of the parameter from which the task is to be constructed.","pos":[9101,9168]},{"content":"The parameter from which the task is to be constructed.","pos":[9204,9259]},{"content":"This could be a lambda or function object, a <ph id=\"ph1\">`task_completion_event`</ph> object, a different <ph id=\"ph2\">`task`</ph> object, or a Windows::Foundation::IAsyncInfo interface if you are using tasks in your Windows Store app.","pos":[9260,9460],"source":" This could be a lambda or function object, a `task_completion_event` object, a different `task` object, or a Windows::Foundation::IAsyncInfo interface if you are using tasks in your Windows Store app."},{"content":"Return Value","pos":[9502,9514]},{"pos":[9518,9573],"content":"A new task of type <ph id=\"ph1\">`T`</ph>, that is inferred from <ph id=\"ph2\">`_Param`</ph>.","source":"A new task of type `T`, that is inferred from `_Param`."},{"content":"Remarks","pos":[9583,9590]},{"content":"The first overload behaves like a task constructor that takes a single parameter.","pos":[9594,9675]},{"content":"The second overload associates the cancellation token provided with the newly created task.","pos":[9682,9773]},{"content":"If you use this overload you are not allowed to pass in a different <ph id=\"ph1\">`task`</ph> object as the first parameter.","pos":[9774,9879],"source":" If you use this overload you are not allowed to pass in a different `task` object as the first parameter."},{"content":"The type of the returned task is inferred from the first parameter to the function.","pos":[9886,9969]},{"content":"If <ph id=\"ph1\">`_Param`</ph> is a <ph id=\"ph2\">`task_completion_event&lt;T&gt;`</ph>, a <ph id=\"ph3\">`task&lt;T&gt;`</ph>, or a functor that returns either type <ph id=\"ph4\">`T`</ph> or <ph id=\"ph5\">`task&lt;T&gt;`</ph>, the type of the created task is <ph id=\"ph6\">`task&lt;T&gt;`</ph>.","pos":[9970,10126],"source":" If `_Param` is a `task_completion_event<T>`, a `task<T>`, or a functor that returns either type `T` or `task<T>`, the type of the created task is `task<T>`."},{"content":"In a Windows Store app, if <ph id=\"ph1\">`_Param`</ph> is of type Windows::Foundation::IAsyncOperation<ph id=\"ph2\">\\&lt;</ph>T&gt;^ or Windows::Foundation::IAsyncOperationWithProgress<ph id=\"ph3\">\\&lt;</ph>T,P&gt;^, or a functor that returns either of those types, the created task will be of type <ph id=\"ph4\">`task&lt;T&gt;`</ph>.","pos":[10133,10374],"source":"In a Windows Store app, if `_Param` is of type Windows::Foundation::IAsyncOperation\\<T>^ or Windows::Foundation::IAsyncOperationWithProgress\\<T,P>^, or a functor that returns either of those types, the created task will be of type `task<T>`."},{"content":"If <ph id=\"ph1\">`_Param`</ph> is of type Windows::Foundation::IAsyncAction^ or Windows::Foundation::IAsyncActionWithProgress<ph id=\"ph2\">\\&lt;</ph>P&gt;^, or a functor that returns either of those types, the created task will have type <ph id=\"ph3\">`task&lt;void&gt;`</ph>.","pos":[10375,10582],"source":" If `_Param` is of type Windows::Foundation::IAsyncAction^ or Windows::Foundation::IAsyncActionWithProgress\\<P>^, or a functor that returns either of those types, the created task will have type `task<void>`."},{"pos":[10623,10637],"content":"DisableTracing"},{"content":"Disables tracing in the Concurrency Runtime.","pos":[10641,10685]},{"content":"This function is deprecated because ETW tracing is unregistered by default.","pos":[10686,10761]},{"content":"Return Value","pos":[10906,10918]},{"content":"If tracing was correctly disabled, <ph id=\"ph1\">`S_OK`</ph> is returned.","pos":[10922,10976],"source":"If tracing was correctly disabled, `S_OK` is returned."},{"content":"If tracing was not previously initiated, <ph id=\"ph1\">`E_NOT_STARTED`</ph> is returned","pos":[10977,11045],"source":" If tracing was not previously initiated, `E_NOT_STARTED` is returned"},{"pos":[11085,11098],"content":"EnableTracing"},{"content":"Enables tracing in the Concurrency Runtime.","pos":[11102,11145]},{"content":"This function is deprecated because ETW tracing is now on by default.","pos":[11146,11215]},{"content":"Return Value","pos":[11358,11370]},{"pos":[11374,11469],"content":"If tracing was correctly initiated, <ph id=\"ph1\">`S_OK`</ph> is returned; otherwise, <ph id=\"ph2\">`E_NOT_STARTED`</ph> is returned.","source":"If tracing was correctly initiated, `S_OK` is returned; otherwise, `E_NOT_STARTED` is returned."},{"pos":[11500,11504],"content":"Free"},{"pos":[11508,11626],"content":"Releases a block of memory previously allocated by the <ph id=\"ph1\">`Alloc`</ph> method to the Concurrency Runtime Caching Suballocator.","source":"Releases a block of memory previously allocated by the `Alloc` method to the Concurrency Runtime Caching Suballocator."},{"content":"Parameters","pos":[11719,11729]},{"content":"A pointer to memory previously allocated by the <ph id=\"ph1\">`Alloc`</ph> method which is to be freed.","pos":[11751,11835],"source":" A pointer to memory previously allocated by the `Alloc` method which is to be freed."},{"content":"If the parameter <ph id=\"ph1\">`_PAllocation`</ph> is set to the value <ph id=\"ph2\">`NULL`</ph>, this method will ignore it and return immediately.","pos":[11836,11946],"source":" If the parameter `_PAllocation` is set to the value `NULL`, this method will ignore it and return immediately."},{"content":"Remarks","pos":[11956,11963]},{"pos":[11967,12166],"content":"For more information about which scenarios in your application could benefit from using the Caching Suballocator, see <bpt id=\"p1\">[</bpt>Task Scheduler<ept id=\"p1\">](../../../parallel/concrt/task-scheduler-concurrency-runtime.md)</ept>.","source":"For more information about which scenarios in your application could benefit from using the Caching Suballocator, see [Task Scheduler](../../../parallel/concrt/task-scheduler-concurrency-runtime.md)."},{"pos":[12214,12235],"content":"get_ambient_scheduler"},{"content":"Return Value","pos":[12342,12354]},{"pos":[12402,12423],"content":"GetExecutionContextId"},{"pos":[12427,12550],"content":"Returns a unique identifier that can be assigned to an execution context that implements the <ph id=\"ph1\">`IExecutionContext`</ph> interface.","source":"Returns a unique identifier that can be assigned to an execution context that implements the `IExecutionContext` interface."},{"content":"Return Value","pos":[12619,12631]},{"content":"A unique identifier for an execution context.","pos":[12635,12680]},{"content":"Remarks","pos":[12690,12697]},{"pos":[12701,12886],"content":"Use this method to obtain an identifier for your execution context before you pass an <ph id=\"ph1\">`IExecutionContext`</ph> interface as a parameter to any of the methods offered by the Resource Manager.","source":"Use this method to obtain an identifier for your execution context before you pass an `IExecutionContext` interface as a parameter to any of the methods offered by the Resource Manager."},{"pos":[12925,12937],"content":"GetOSVersion"},{"content":"Returns the operating system version.","pos":[12941,12978]},{"content":"Return Value","pos":[13053,13065]},{"content":"An enumerated value representing the operating system.","pos":[13069,13123]},{"content":"Remarks","pos":[13133,13140]},{"pos":[13144,13264],"content":"<bpt id=\"p1\">[</bpt>unsupported_os<ept id=\"p1\">](unsupported-os-class.md)</ept> is thrown if the operating system is not supported by the Concurrency Runtime.","source":"[unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime."},{"pos":[13308,13325],"content":"GetProcessorCount"},{"content":"Returns the number of hardware threads on the underlying system.","pos":[13329,13393]},{"content":"Return Value","pos":[13458,13470]},{"content":"The number of hardware threads.","pos":[13474,13505]},{"content":"Remarks","pos":[13515,13522]},{"pos":[13526,13646],"content":"<bpt id=\"p1\">[</bpt>unsupported_os<ept id=\"p1\">](unsupported-os-class.md)</ept> is thrown if the operating system is not supported by the Concurrency Runtime.","source":"[unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime."},{"pos":[13694,13715],"content":"GetProcessorNodeCount"},{"content":"Returns the number of NUMA nodes or processor packages on the underlying system.","pos":[13719,13799]},{"content":"Return Value","pos":[13868,13880]},{"content":"The number of NUMA nodes or processor packages.","pos":[13884,13931]},{"content":"Remarks","pos":[13941,13948]},{"content":"If the system contains more NUMA nodes than processor packages, the number of NUMA nodes is returned, otherwise, the number of processor packages is returned.","pos":[13952,14110]},{"pos":[14117,14237],"content":"<bpt id=\"p1\">[</bpt>unsupported_os<ept id=\"p1\">](unsupported-os-class.md)</ept> is thrown if the operating system is not supported by the Concurrency Runtime.","source":"[unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime."},{"pos":[14278,14292],"content":"GetSchedulerId"},{"pos":[14296,14403],"content":"Returns a unique identifier that can be assigned to a scheduler that implements the <ph id=\"ph1\">`IScheduler`</ph> interface.","source":"Returns a unique identifier that can be assigned to a scheduler that implements the `IScheduler` interface."},{"content":"Return Value","pos":[14465,14477]},{"content":"A unique identifier for a scheduler.","pos":[14481,14517]},{"content":"Remarks","pos":[14527,14534]},{"pos":[14538,14708],"content":"Use this method to obtain an identifier for your scheduler before you pass an <ph id=\"ph1\">`IScheduler`</ph> interface as a parameter to any of the methods offered by the Resource Manager.","source":"Use this method to obtain an identifier for your scheduler before you pass an `IScheduler` interface as a parameter to any of the methods offered by the Resource Manager."},{"pos":[14760,14785],"content":"internal_assign_iterators"},{"content":"Parameters","pos":[14953,14963]},{"pos":[15053,15071],"content":"interruption_point"},{"content":"Creates an interruption point for cancellation.","pos":[15075,15122]},{"content":"If a cancellation is in progress in the context where this function is called, this will throw an internal exception that aborts the execution of the currently executing parallel work.","pos":[15123,15307]},{"content":"If cancellation is not in progress, the function does nothing.","pos":[15308,15370]},{"content":"Remarks","pos":[15427,15434]},{"content":"You should not catch the internal cancellation exception thrown by the <ph id=\"ph1\">`interruption_point()`</ph> function.","pos":[15438,15541],"source":"You should not catch the internal cancellation exception thrown by the `interruption_point()` function."},{"content":"The exception will be caught and handled by the runtime, and catching it may cause your program to behave abnormally.","pos":[15542,15659]},{"pos":[15717,15748],"content":"is_current_task_group_canceling"},{"content":"Returns an indication of whether the task group which is currently executing inline on the current context is in the midst of an active cancellation (or will be shortly).","pos":[15752,15922]},{"content":"Note that if there is no task group currently executing inline on the current context, <ph id=\"ph1\">`false`</ph> will be returned.","pos":[15923,16035],"source":" Note that if there is no task group currently executing inline on the current context, `false` will be returned."},{"content":"Return Value","pos":[16106,16118]},{"pos":[16129,16208],"content":"if the task group which is currently executing is canceling, <ph id=\"ph1\">`false`</ph> otherwise.","source":" if the task group which is currently executing is canceling, `false` otherwise."},{"content":"Remarks","pos":[16218,16225]},{"pos":[16229,16358],"content":"For more information, see <bpt id=\"p1\">[</bpt>Cancellation<ept id=\"p1\">](../../../parallel/concrt/exception-handling-in-the-concurrency-runtime.md#cancellation)</ept>.","source":"For more information, see [Cancellation](../../../parallel/concrt/exception-handling-in-the-concurrency-runtime.md#cancellation)."},{"pos":[16396,16407],"content":"make_choice"},{"pos":[16411,16527],"content":"Constructs a <ph id=\"ph1\">`choice`</ph> messaging block from an optional <ph id=\"ph2\">`Scheduler`</ph> or <ph id=\"ph3\">`ScheduleGroup`</ph> and two or more input sources.","source":"Constructs a `choice` messaging block from an optional `Scheduler` or `ScheduleGroup` and two or more input sources."},{"content":"Parameters","pos":[17102,17112]},{"content":"The message block type of the first source.","pos":[17124,17167]},{"content":"The message block type of the second source.","pos":[17182,17226]},{"content":"The <ph id=\"ph1\">`Scheduler`</ph> object within which the propagation task for the <ph id=\"ph2\">`choice`</ph> messaging block is scheduled.","pos":[17250,17353],"source":" The `Scheduler` object within which the propagation task for the `choice` messaging block is scheduled."},{"content":"The first source.","pos":[17372,17389]},{"content":"The second source.","pos":[17408,17426]},{"content":"Additional sources.","pos":[17445,17464]},{"content":"The <ph id=\"ph1\">`ScheduleGroup`</ph> object within which the propagation task for the <ph id=\"ph2\">`choice`</ph> messaging block is scheduled.","pos":[17492,17599],"source":" The `ScheduleGroup` object within which the propagation task for the `choice` messaging block is scheduled."},{"content":"The <ph id=\"ph1\">`Scheduler`</ph> object used is implied by the schedule group.","pos":[17600,17661],"source":" The `Scheduler` object used is implied by the schedule group."},{"content":"Return Value","pos":[17671,17683]},{"pos":[17687,17743],"content":"A <ph id=\"ph1\">`choice`</ph> message block with two or more input sources.","source":"A `choice` message block with two or more input sources."},{"pos":[17786,17802],"content":"make_greedy_join"},{"pos":[17806,17937],"content":"Constructs a <ph id=\"ph1\">`greedy multitype_join`</ph> messaging block from an optional <ph id=\"ph2\">`Scheduler`</ph> or <ph id=\"ph3\">`ScheduleGroup`</ph> and two or more input sources.","source":"Constructs a `greedy multitype_join` messaging block from an optional `Scheduler` or `ScheduleGroup` and two or more input sources."},{"content":"Parameters","pos":[18587,18597]},{"content":"The message block type of the first source.","pos":[18609,18652]},{"content":"The message block type of the second source.","pos":[18667,18711]},{"content":"The <ph id=\"ph1\">`Scheduler`</ph> object within which the propagation task for the <ph id=\"ph2\">`multitype_join`</ph> messaging block is scheduled.","pos":[18735,18846],"source":" The `Scheduler` object within which the propagation task for the `multitype_join` messaging block is scheduled."},{"content":"The first source.","pos":[18865,18882]},{"content":"The second source.","pos":[18901,18919]},{"content":"Additional sources.","pos":[18938,18957]},{"content":"The <ph id=\"ph1\">`ScheduleGroup`</ph> object within which the propagation task for the <ph id=\"ph2\">`multitype_join`</ph> messaging block is scheduled.","pos":[18985,19100],"source":" The `ScheduleGroup` object within which the propagation task for the `multitype_join` messaging block is scheduled."},{"content":"The <ph id=\"ph1\">`Scheduler`</ph> object used is implied by the schedule group.","pos":[19101,19162],"source":" The `Scheduler` object used is implied by the schedule group."},{"content":"Return Value","pos":[19172,19184]},{"pos":[19188,19259],"content":"A <ph id=\"ph1\">`greedy multitype_join`</ph> message block with two or more input sources.","source":"A `greedy multitype_join` message block with two or more input sources."},{"pos":[19295,19304],"content":"make_join"},{"pos":[19308,19443],"content":"Constructs a <ph id=\"ph1\">`non_greedy multitype_join`</ph> messaging block from an optional <ph id=\"ph2\">`Scheduler`</ph> or <ph id=\"ph3\">`ScheduleGroup`</ph> and two or more input sources.","source":"Constructs a `non_greedy multitype_join` messaging block from an optional `Scheduler` or `ScheduleGroup` and two or more input sources."},{"content":"Parameters","pos":[19987,19997]},{"content":"The message block type of the first source.","pos":[20009,20052]},{"content":"The message block type of the second source.","pos":[20067,20111]},{"content":"The <ph id=\"ph1\">`Scheduler`</ph> object within which the propagation task for the <ph id=\"ph2\">`multitype_join`</ph> messaging block is scheduled.","pos":[20135,20246],"source":" The `Scheduler` object within which the propagation task for the `multitype_join` messaging block is scheduled."},{"content":"The first source.","pos":[20265,20282]},{"content":"The second source.","pos":[20301,20319]},{"content":"Additional sources.","pos":[20338,20357]},{"content":"The <ph id=\"ph1\">`ScheduleGroup`</ph> object within which the propagation task for the <ph id=\"ph2\">`multitype_join`</ph> messaging block is scheduled.","pos":[20385,20500],"source":" The `ScheduleGroup` object within which the propagation task for the `multitype_join` messaging block is scheduled."},{"content":"The <ph id=\"ph1\">`Scheduler`</ph> object used is implied by the schedule group.","pos":[20501,20562],"source":" The `Scheduler` object used is implied by the schedule group."},{"content":"Return Value","pos":[20572,20584]},{"pos":[20588,20663],"content":"A <ph id=\"ph1\">`non_greedy multitype_join`</ph> message block with two or more input sources.","source":"A `non_greedy multitype_join` message block with two or more input sources."},{"pos":[20699,20708],"content":"make_task"},{"pos":[20712,20765],"content":"A factory method for creating a <ph id=\"ph1\">`task_handle`</ph> object.","source":"A factory method for creating a `task_handle` object."},{"content":"Parameters","pos":[20873,20883]},{"content":"The type of the function object that will be invoked to execute the work represented by the <ph id=\"ph1\">`task_handle`</ph> object.","pos":[20902,21015],"source":" The type of the function object that will be invoked to execute the work represented by the `task_handle` object."},{"content":"The function that will be invoked to execute the work represented by the <ph id=\"ph1\">`task_handle`</ph> object.","pos":[21033,21127],"source":" The function that will be invoked to execute the work represented by the `task_handle` object."},{"content":"This may be a lambda functor, a pointer to a function, or any object that supports a version of the function call operator with the signature <ph id=\"ph1\">`void operator()()`</ph>.","pos":[21128,21290],"source":" This may be a lambda functor, a pointer to a function, or any object that supports a version of the function call operator with the signature `void operator()()`."},{"content":"Return Value","pos":[21300,21312]},{"pos":[21316,21339],"content":"A <ph id=\"ph1\">`task_handle`</ph> object.","source":"A `task_handle` object."},{"content":"Remarks","pos":[21349,21356]},{"pos":[21360,21552],"content":"This function is useful when you need to create a <ph id=\"ph1\">`task_handle`</ph> object with a lambda expression, because it allows you to create the object without knowing the true type of the lambda functor.","source":"This function is useful when you need to create a `task_handle` object with a lambda expression, because it allows you to create the object without knowing the true type of the lambda functor."},{"pos":[21601,21623],"content":"parallel_buffered_sort"},{"content":"Arranges the elements in a specified range into a nondescending order, or according to an ordering criterion specified by a binary predicate, in parallel.","pos":[21627,21781]},{"content":"This function is semantically similar to <ph id=\"ph1\">`std::sort`</ph> in that it is a compare-based, unstable, in-place sort except that it needs <ph id=\"ph2\">`O(n)`</ph> additional space, and requires default initialization for the elements being sorted.","pos":[21782,22002],"source":" This function is semantically similar to `std::sort` in that it is a compare-based, unstable, in-place sort except that it needs `O(n)` additional space, and requires default initialization for the elements being sorted."},{"content":"Parameters","pos":[23315,23325]},{"content":"The iterator type of the input range.","pos":[23351,23388]},{"content":"The type of an STL compatible memory allocator.","pos":[23411,23458]},{"content":"The type of the binary comparator.","pos":[23480,23514]},{"content":"A random-access iterator addressing the position of the first element in the range to be sorted.","pos":[23533,23629]},{"content":"A random-access iterator addressing the position one past the final element in the range to be sorted.","pos":[23646,23748]},{"content":"An instance of an STL compatible memory allocator.","pos":[23767,23817]},{"content":"A user-defined predicate function object that defines the comparison criterion to be satisfied by successive elements in the ordering.","pos":[23835,23969]},{"content":"A binary predicate takes two arguments and returns <ph id=\"ph1\">`true`</ph> when satisfied and <ph id=\"ph2\">`false`</ph> when not satisfied.","pos":[23970,24074],"source":" A binary predicate takes two arguments and returns `true` when satisfied and `false` when not satisfied."},{"content":"This comparator function must impose a strict weak ordering on pairs of elements from the sequence.","pos":[24075,24174]},{"content":"The mimimum size of a chunk that will be split into two for parallel execution.","pos":[24198,24277]},{"content":"Remarks","pos":[24287,24294]},{"content":"All overloads require <ph id=\"ph1\">`n * sizeof(T)`</ph> additional space, where <ph id=\"ph2\">`n`</ph> is the number of elements to be sorted, and <ph id=\"ph3\">`T`</ph> is the element type.","pos":[24298,24432],"source":"All overloads require `n * sizeof(T)` additional space, where `n` is the number of elements to be sorted, and `T` is the element type."},{"content":"In most cases parallel_buffered_sort will show an improvement in performance over <bpt id=\"p1\">[</bpt>parallel_sort<ept id=\"p1\">](concurrency-namespace-functions.md)</ept>, and you should use it over parallel_sort if you have the memory available.","pos":[24433,24642],"source":" In most cases parallel_buffered_sort will show an improvement in performance over [parallel_sort](concurrency-namespace-functions.md), and you should use it over parallel_sort if you have the memory available."},{"pos":[24649,24796],"content":"If you do not supply a binary comparator <ph id=\"ph1\">`std::less`</ph> is used as the default, which requires the element type to provide the operator <ph id=\"ph2\">`operator&lt;()`</ph>.","source":"If you do not supply a binary comparator `std::less` is used as the default, which requires the element type to provide the operator `operator<()`."},{"pos":[24803,24931],"content":"If you do not supply an allocator type or instance, the STL memory allocator <ph id=\"ph1\">`std::allocator&lt;T&gt;`</ph> is used to allocate the buffer.","source":"If you do not supply an allocator type or instance, the STL memory allocator `std::allocator<T>` is used to allocate the buffer."},{"content":"The algorithm divides the input range into two chunks and successively divides each chunk into two sub-chunks for execution in parallel.","pos":[24938,25074]},{"content":"The optional argument <ph id=\"ph1\">`_Chunk_size`</ph> can be used to indicate to the algorithm that it should handles chunks of size &lt; <ph id=\"ph2\">`_Chunk_size`</ph> serially.","pos":[25075,25215],"source":" The optional argument `_Chunk_size` can be used to indicate to the algorithm that it should handles chunks of size < `_Chunk_size` serially."},{"pos":[25254,25266],"content":"parallel_for"},{"pos":[25285,25387],"content":"iterates over a range of indices and executes a user-supplied function at each iteration, in parallel."},{"content":"Parameters","pos":[26543,26553]},{"content":"The type of the index being used for the iteration.","pos":[26574,26625]},{"content":"The type of the function that will be executed at each iteration.","pos":[26647,26712]},{"content":"The type of the partitioner that is used to partition the supplied range.","pos":[26737,26810]},{"content":"The first index to be included in the iteration.","pos":[26828,26876]},{"content":"The index one past the last index to be included in the iteration.","pos":[26893,26959]},{"content":"The value by which to step when iterating from <ph id=\"ph1\">`first`</ph> to <ph id=\"ph2\">`last`</ph>.","pos":[26977,27042],"source":" The value by which to step when iterating from `first` to `last`."},{"content":"The step must be positive.","pos":[27043,27069]},{"content":"<bpt id=\"p1\">[</bpt>invalid_argument<ept id=\"p1\">](../../../standard-library/invalid-argument-class.md)</ept> is thrown if the step is less than 1.","pos":[27070,27179],"source":"[invalid_argument](../../../standard-library/invalid-argument-class.md) is thrown if the step is less than 1."},{"content":"The function to be executed at each iteration.","pos":[27197,27243]},{"content":"This may be a lambda expression, a function pointer, or any object that supports a version of the function call operator with the signature <ph id=\"ph1\">`void operator()(``_Index_type``)`</ph>.","pos":[27244,27419],"source":" This may be a lambda expression, a function pointer, or any object that supports a version of the function call operator with the signature `void operator()(``_Index_type``)`."},{"content":"A reference to the partitioner object.","pos":[27437,27475]},{"content":"The argument can be one of <ph id=\"ph1\">`const`</ph><bpt id=\"p1\">[</bpt>auto_partitioner<ept id=\"p1\">](auto-partitioner-class.md)</ept><ph id=\"ph2\">`&amp;`</ph>, <ph id=\"ph3\">`const`</ph><bpt id=\"p2\">[</bpt>static_partitioner<ept id=\"p2\">](static-partitioner-class.md)</ept><ph id=\"ph4\">`&amp;`</ph>, <ph id=\"ph5\">`const`</ph><bpt id=\"p3\">[</bpt>simple_partitioner<ept id=\"p3\">](simple-partitioner-class.md)</ept><ph id=\"ph6\">`&amp;`</ph> or <bpt id=\"p4\">[</bpt>affinity_partitioner<ept id=\"p4\">](affinity-partitioner-class.md)</ept><ph id=\"ph7\">`&amp;`</ph> If an <bpt id=\"p5\">[</bpt>affinity_partitioner<ept id=\"p5\">](affinity-partitioner-class.md)</ept> object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use.","pos":[27476,27935],"source":" The argument can be one of `const`[auto_partitioner](auto-partitioner-class.md)`&`, `const`[static_partitioner](static-partitioner-class.md)`&`, `const`[simple_partitioner](simple-partitioner-class.md)`&` or [affinity_partitioner](affinity-partitioner-class.md)`&` If an [affinity_partitioner](affinity-partitioner-class.md) object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use."},{"content":"Remarks","pos":[27945,27952]},{"pos":[27956,28053],"content":"For more information, see <bpt id=\"p1\">[</bpt>Parallel Algorithms<ept id=\"p1\">](../../../parallel/concrt/parallel-algorithms.md)</ept>.","source":"For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md)."},{"pos":[28097,28114],"content":"parallel_for_each"},{"content":"applies a specified function to each element within a range, in parallel.","pos":[28138,28211]},{"content":"It is semantically equivalent to the <ph id=\"ph1\">`for_each`</ph> function in the <ph id=\"ph2\">`std`</ph> namespace, except that iteration over the elements is performed in parallel, and the order of iteration is unspecified.","pos":[28212,28401],"source":" It is semantically equivalent to the `for_each` function in the `std` namespace, except that iteration over the elements is performed in parallel, and the order of iteration is unspecified."},{"content":"The argument <ph id=\"ph1\">`_Func`</ph> must support a function call operator of the form <ph id=\"ph2\">`operator()(T)`</ph> where the parameter <ph id=\"ph3\">`T`</ph> is the item type of the container being iterated over.","pos":[28402,28567],"source":" The argument `_Func` must support a function call operator of the form `operator()(T)` where the parameter `T` is the item type of the container being iterated over."},{"content":"Parameters","pos":[28928,28938]},{"content":"The type of the iterator being used to iterate over the container.","pos":[28957,29023]},{"content":"The type of the function that will be applied to each element within the range.","pos":[29045,29124]},{"content":"An iterator addressing the position of the first element to be included in parallel iteration.","pos":[29160,29254]},{"content":"An iterator addressing the position one past the final element to be included in parallel iteration.","pos":[29271,29371]},{"content":"A user-defined function object that is applied to each element in the range.","pos":[29389,29465]},{"content":"A reference to the partitioner object.","pos":[29483,29521]},{"content":"The argument can be one of <ph id=\"ph1\">`const`</ph><bpt id=\"p1\">[</bpt>auto_partitioner<ept id=\"p1\">](auto-partitioner-class.md)</ept><ph id=\"ph2\">`&amp;`</ph>, <ph id=\"ph3\">`const`</ph><bpt id=\"p2\">[</bpt>static_partitioner<ept id=\"p2\">](static-partitioner-class.md)</ept><ph id=\"ph4\">`&amp;`</ph>, <ph id=\"ph5\">`const`</ph><bpt id=\"p3\">[</bpt>simple_partitioner<ept id=\"p3\">](simple-partitioner-class.md)</ept><ph id=\"ph6\">`&amp;`</ph> or <bpt id=\"p4\">[</bpt>affinity_partitioner<ept id=\"p4\">](affinity-partitioner-class.md)</ept><ph id=\"ph7\">`&amp;`</ph> If an <bpt id=\"p5\">[</bpt>affinity_partitioner<ept id=\"p5\">](affinity-partitioner-class.md)</ept> object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use.","pos":[29522,29981],"source":" The argument can be one of `const`[auto_partitioner](auto-partitioner-class.md)`&`, `const`[static_partitioner](static-partitioner-class.md)`&`, `const`[simple_partitioner](simple-partitioner-class.md)`&` or [affinity_partitioner](affinity-partitioner-class.md)`&` If an [affinity_partitioner](affinity-partitioner-class.md) object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use."},{"content":"Remarks","pos":[29991,29998]},{"pos":[30002,30110],"content":"<bpt id=\"p1\">[</bpt>auto_partitioner<ept id=\"p1\">](auto-partitioner-class.md)</ept> will be used for the overload without an explicit partitioner.","source":"[auto_partitioner](auto-partitioner-class.md) will be used for the overload without an explicit partitioner."},{"pos":[30117,30230],"content":"For iterators that do not support random access, only <bpt id=\"p1\">[</bpt>auto_partitioner<ept id=\"p1\">](auto-partitioner-class.md)</ept> is supported.","source":"For iterators that do not support random access, only [auto_partitioner](auto-partitioner-class.md) is supported."},{"pos":[30237,30334],"content":"For more information, see <bpt id=\"p1\">[</bpt>Parallel Algorithms<ept id=\"p1\">](../../../parallel/concrt/parallel-algorithms.md)</ept>.","source":"For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md)."},{"pos":[30376,30391],"content":"parallel_invoke"},{"content":"Executes the function objects supplied as parameters in parallel, and blocks until they have finished executing.","pos":[30395,30507]},{"content":"Each function object could be a lambda expression, a pointer to function, or any object that supports the function call operator with the signature <ph id=\"ph1\">`void operator()()`</ph>.","pos":[30508,30676],"source":" Each function object could be a lambda expression, a pointer to function, or any object that supports the function call operator with the signature `void operator()()`."},{"content":"Parameters","pos":[33929,33939]},{"content":"The type of the first function object to be executed in parallel.","pos":[33959,34024]},{"content":"The type of the second function object to be executed in parallel.","pos":[34047,34113]},{"content":"The type of the third function object to be executed in parallel.","pos":[34136,34201]},{"content":"The type of the fourth function object to be executed in parallel.","pos":[34224,34290]},{"content":"The type of the fifth function object to be executed in parallel.","pos":[34313,34378]},{"content":"The type of the sixth function object to be executed in parallel.","pos":[34401,34466]},{"content":"The type of the seventh function object to be executed in parallel.","pos":[34489,34556]},{"content":"The type of the eighth function object to be executed in parallel.","pos":[34579,34645]},{"content":"The type of the ninth function object to be executed in parallel.","pos":[34668,34733]},{"content":"The type of the tenth function object to be executed in parallel.","pos":[34757,34822]},{"content":"The first function object to be executed in parallel.","pos":[34841,34894]},{"content":"The second function object to be executed in parallel.","pos":[34913,34967]},{"content":"The third function object to be executed in parallel.","pos":[34986,35039]},{"content":"The fourth function object to be executed in parallel.","pos":[35058,35112]},{"content":"The fifth function object to be executed in parallel.","pos":[35131,35184]},{"content":"The sixth function object to be executed in parallel.","pos":[35203,35256]},{"content":"The seventh function object to be executed in parallel.","pos":[35275,35330]},{"content":"The eighth function object to be executed in parallel.","pos":[35349,35403]},{"content":"The ninth function object to be executed in parallel.","pos":[35422,35475]},{"content":"The tenth function object to be executed in parallel.","pos":[35495,35548]},{"content":"Remarks","pos":[35558,35565]},{"content":"Note that one or more of the function objects supplied as parameters may execute inline on the calling context.","pos":[35569,35680]},{"pos":[35687,35898],"content":"If one or more of the function objects passed as parameters to this function throws an exception, the runtime will select one such exception of its choosing and propagate it out of the call to <ph id=\"ph1\">`parallel_invoke`</ph>.","source":"If one or more of the function objects passed as parameters to this function throws an exception, the runtime will select one such exception of its choosing and propagate it out of the call to `parallel_invoke`."},{"pos":[35905,36002],"content":"For more information, see <bpt id=\"p1\">[</bpt>Parallel Algorithms<ept id=\"p1\">](../../../parallel/concrt/parallel-algorithms.md)</ept>.","source":"For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md)."},{"pos":[36047,36065],"content":"parallel_radixsort"},{"content":"Arranges elements in a specified range into an non descending order using a radix sorting algorithm.","pos":[36069,36169]},{"content":"This is a stable sort function which requires a projection function that can project elements to be sorted into unsigned integer-like keys.","pos":[36170,36309]},{"content":"Default initialization is required for the elements being sorted.","pos":[36310,36375]},{"content":"Parameters","pos":[37675,37685]},{"content":"The iterator type of the input range.","pos":[37711,37748]},{"content":"The type of an STL compatible memory allocator.","pos":[37771,37818]},{"content":"The type of the projection function.","pos":[37840,37876]},{"content":"A random-access iterator addressing the position of the first element in the range to be sorted.","pos":[37895,37991]},{"content":"A random-access iterator addressing the position one past the final element in the range to be sorted.","pos":[38008,38110]},{"content":"An instance of an STL compatible memory allocator.","pos":[38129,38179]},{"content":"A user-defined projection function object that converts an element into an integral value.","pos":[38202,38292]},{"content":"The mimimum size of a chunk that will be split into two for parallel execution.","pos":[38316,38395]},{"content":"Remarks","pos":[38405,38412]},{"content":"All overloads require <ph id=\"ph1\">`n * sizeof(T)`</ph> additional space, where <ph id=\"ph2\">`n`</ph> is the number of elements to be sorted, and <ph id=\"ph3\">`T`</ph> is the element type.","pos":[38416,38550],"source":"All overloads require `n * sizeof(T)` additional space, where `n` is the number of elements to be sorted, and `T` is the element type."},{"content":"An unary projection functor with the signature <ph id=\"ph1\">`I _Proj_func(T)`</ph> is required to return a key when given an element, where <ph id=\"ph2\">`T`</ph> is the element type and <ph id=\"ph3\">`I`</ph> is an unsigned integer-like type.","pos":[38551,38738],"source":" An unary projection functor with the signature `I _Proj_func(T)` is required to return a key when given an element, where `T` is the element type and `I` is an unsigned integer-like type."},{"content":"If you do not supply a projection function, a default projection function which simply returns the element is used for integral types.","pos":[38745,38879]},{"content":"The function will fail to compile if the element is not an integral type in the absence of a projection function.","pos":[38880,38993]},{"pos":[39000,39128],"content":"If you do not supply an allocator type or instance, the STL memory allocator <ph id=\"ph1\">`std::allocator&lt;T&gt;`</ph> is used to allocate the buffer.","source":"If you do not supply an allocator type or instance, the STL memory allocator `std::allocator<T>` is used to allocate the buffer."},{"content":"The algorithm divides the input range into two chunks and successively divides each chunk into two sub-chunks for execution in parallel.","pos":[39135,39271]},{"content":"The optional argument <ph id=\"ph1\">`_Chunk_size`</ph> can be used to indicate to the algorithm that it should handles chunks of size &lt; <ph id=\"ph2\">`_Chunk_size`</ph> serially.","pos":[39272,39412],"source":" The optional argument `_Chunk_size` can be used to indicate to the algorithm that it should handles chunks of size < `_Chunk_size` serially."},{"pos":[39454,39469],"content":"parallel_reduce"},{"content":"Computes the sum of all elements in a specified range by computing successive partial sums, or computes the result of successive partial results similarly obtained from using a specified binary operation other than sum, in parallel.","pos":[39473,39705]},{"content":"is semantically similar to <ph id=\"ph1\">`std::accumulate`</ph>, except that it requires the binary operation to be associative, and requires an identity value instead of an initial value.","pos":[39724,39893],"source":" is semantically similar to `std::accumulate`, except that it requires the binary operation to be associative, and requires an identity value instead of an initial value."},{"content":"Parameters","pos":[40838,40848]},{"content":"The iterator type of input range.","pos":[40875,40908]},{"content":"The type of the symmetric reduction function.","pos":[40936,40981]},{"content":"This must be a function type with signature <ph id=\"ph1\">`_Reduce_type _Sym_fun(_Reduce_type, _Reduce_type)`</ph>, where _Reduce_type is the same as the identity type and the result type of the reduction.","pos":[40982,41168],"source":" This must be a function type with signature `_Reduce_type _Sym_fun(_Reduce_type, _Reduce_type)`, where _Reduce_type is the same as the identity type and the result type of the reduction."},{"content":"For the third overload, this should be consistent with the output type of <ph id=\"ph1\">`_Range_reduce_fun`</ph>.","pos":[41169,41263],"source":" For the third overload, this should be consistent with the output type of `_Range_reduce_fun`."},{"content":"The type that the input will reduce to, which can be different from the input element type.","pos":[41288,41379]},{"content":"The return value and identity value will has this type.","pos":[41380,41435]},{"content":"The type of the range reduction function.","pos":[41465,41506]},{"content":"This must be a function type with signature <ph id=\"ph1\">`_Reduce_type _Range_fun(_Forward_iterator, _Forward_iterator, _Reduce_type)`</ph>, _Reduce_type is the same as the identity type and the result type of the reduction.","pos":[41507,41713],"source":" This must be a function type with signature `_Reduce_type _Range_fun(_Forward_iterator, _Forward_iterator, _Reduce_type)`, _Reduce_type is the same as the identity type and the result type of the reduction."},{"content":"An input iterator addressing the first element in the range to be reduced.","pos":[41732,41806]},{"content":"An input iterator addressing the element that is one position beyond the final element in the range to be reduced.","pos":[41823,41937]},{"content":"The identity value <ph id=\"ph1\">`_Identity`</ph> is of the same type as the result type of the reduction and also the <ph id=\"ph2\">`value_type`</ph> of the iterator for the first and second overloads.","pos":[41959,42123],"source":" The identity value `_Identity` is of the same type as the result type of the reduction and also the `value_type` of the iterator for the first and second overloads."},{"content":"For the third overload, the identity value must have the same type as the result type of the reduction, but can be different from the <ph id=\"ph1\">`value_type`</ph> of the iterator.","pos":[42124,42287],"source":" For the third overload, the identity value must have the same type as the result type of the reduction, but can be different from the `value_type` of the iterator."},{"content":"It must have an appropriate value such that the range reduction operator <ph id=\"ph1\">`_Range_fun`</ph>, when applied to a range of a single element of type <ph id=\"ph2\">`value_type`</ph> and the identity value, behaves like a type cast of the value from type <ph id=\"ph3\">`value_type`</ph> to the identity type.","pos":[42288,42546],"source":" It must have an appropriate value such that the range reduction operator `_Range_fun`, when applied to a range of a single element of type `value_type` and the identity value, behaves like a type cast of the value from type `value_type` to the identity type."},{"content":"The symmetric function that will be used in the second of the reduction.","pos":[42567,42639]},{"content":"Refer to Remarks for more information.","pos":[42640,42678]},{"content":"The function that will be used in the first phase of the reduction.","pos":[42701,42768]},{"content":"Refer to Remarks for more information.","pos":[42769,42807]},{"content":"Return Value","pos":[42817,42829]},{"content":"The result of the reduction.","pos":[42833,42861]},{"content":"Remarks","pos":[42871,42878]},{"content":"To perform a parallel reduction, the function divides the range into chunks based on the number of workers available to the underlying scheduler.","pos":[42882,43027]},{"content":"The reduction takes place in two phases, the first phase performs a reduction within each chunk, and the second phase performs a reduction between the partial results from each chunk.","pos":[43028,43211]},{"content":"The first overload requires that the iterator's <ph id=\"ph1\">`value_type`</ph>, <ph id=\"ph2\">`T`</ph>, be the same as the identity value type as well as the reduction result type.","pos":[43218,43361],"source":"The first overload requires that the iterator's `value_type`, `T`, be the same as the identity value type as well as the reduction result type."},{"content":"The element type T must provide the operator <ph id=\"ph1\">`T T::operator + (T)`</ph> to reduce elements in each chunk.","pos":[43362,43462],"source":" The element type T must provide the operator `T T::operator + (T)` to reduce elements in each chunk."},{"content":"The same operator is used in the second phase as well.","pos":[43463,43517]},{"content":"The second overload also requires that the iterator's <ph id=\"ph1\">`value_type`</ph> be the same as the identity value type as well as the reduction result type.","pos":[43524,43667],"source":"The second overload also requires that the iterator's `value_type` be the same as the identity value type as well as the reduction result type."},{"content":"The supplied binary operator <ph id=\"ph1\">`_Sym_fun`</ph> is used in both reduction phases, with the identity value as the initial value for the first phase.","pos":[43668,43807],"source":" The supplied binary operator `_Sym_fun` is used in both reduction phases, with the identity value as the initial value for the first phase."},{"content":"For the third overload, the identity value type must be the same as the reduction result type, but the iterator's <ph id=\"ph1\">`value_type`</ph> may be different from both.","pos":[43814,43968],"source":"For the third overload, the identity value type must be the same as the reduction result type, but the iterator's `value_type` may be different from both."},{"content":"The range reduction function <ph id=\"ph1\">`_Range_fun`</ph> is used in the first phase with the identity value as the initial value, and the binary function <ph id=\"ph2\">`_Sym_reduce_fun`</ph> is applied to sub results in the second phase.","pos":[43969,44172],"source":" The range reduction function `_Range_fun` is used in the first phase with the identity value as the initial value, and the binary function `_Sym_reduce_fun` is applied to sub results in the second phase."},{"pos":[44212,44225],"content":"parallel_sort"},{"content":"Arranges the elements in a specified range into a nondescending order, or according to an ordering criterion specified by a binary predicate, in parallel.","pos":[44229,44383]},{"content":"This function is semantically similar to <ph id=\"ph1\">`std::sort`</ph> in that it is a compare-based, unstable, in-place sort.","pos":[44384,44492],"source":" This function is semantically similar to `std::sort` in that it is a compare-based, unstable, in-place sort."},{"content":"Parameters","pos":[44868,44878]},{"content":"The iterator type of the input range.","pos":[44904,44941]},{"content":"The type of the binary comparison functor.","pos":[44963,45005]},{"content":"A random-access iterator addressing the position of the first element in the range to be sorted.","pos":[45024,45120]},{"content":"A random-access iterator addressing the position one past the final element in the range to be sorted.","pos":[45137,45239]},{"content":"A user-defined predicate function object that defines the comparison criterion to be satisfied by successive elements in the ordering.","pos":[45257,45391]},{"content":"A binary predicate takes two arguments and returns <ph id=\"ph1\">`true`</ph> when satisfied and <ph id=\"ph2\">`false`</ph> when not satisfied.","pos":[45392,45496],"source":" A binary predicate takes two arguments and returns `true` when satisfied and `false` when not satisfied."},{"content":"This comparator function must impose a strict weak ordering on pairs of elements from the sequence.","pos":[45497,45596]},{"content":"The mimimum size of a chunk that will be split into two for parallel execution.","pos":[45620,45699]},{"content":"Remarks","pos":[45709,45716]},{"pos":[45720,45782],"content":"The first overload uses the the binary comparator <ph id=\"ph1\">`std::less`</ph>.","source":"The first overload uses the the binary comparator `std::less`."},{"pos":[45789,45954],"content":"The second overloaded uses the supplied binary comparator that should have the signature <ph id=\"ph1\">`bool _Func(T, T)`</ph> where <ph id=\"ph2\">`T`</ph> is the type of the elements in the input range.","source":"The second overloaded uses the supplied binary comparator that should have the signature `bool _Func(T, T)` where `T` is the type of the elements in the input range."},{"content":"The algorithm divides the input range into two chunks and successively divides each chunk into two sub-chunks for execution in parallel.","pos":[45961,46097]},{"content":"The optional argument <ph id=\"ph1\">`_Chunk_size`</ph> can be used to indicate to the algorithm that it should handles chunks of size &lt; <ph id=\"ph2\">`_Chunk_size`</ph> serially.","pos":[46098,46238],"source":" The optional argument `_Chunk_size` can be used to indicate to the algorithm that it should handles chunks of size < `_Chunk_size` serially."},{"pos":[46283,46301],"content":"parallel_transform"},{"content":"Applies a specified function object to each element in a source range, or to a pair of elements from two source ranges, and copies the return values of the function object into a destination range, in parallel.","pos":[46305,46515]},{"content":"This functional is semantically equivalent to <ph id=\"ph1\">`std::transform`</ph>.","pos":[46516,46579],"source":" This functional is semantically equivalent to `std::transform`."},{"content":"Parameters","pos":[48517,48527]},{"content":"The type of the first or only input iterator.","pos":[48553,48598]},{"content":"The type of the output iterator.","pos":[48627,48659]},{"content":"The type of the unary functor to be executed on each element in the input range.","pos":[48687,48767]},{"content":"The type of second input iterator.","pos":[48796,48830]},{"content":"The type of the binary functor executed pairwise on elements from the two source ranges.","pos":[48859,48947]},{"content":"An input iterator addressing the position of the first element in the first or only source range to be operated on.","pos":[48984,49099]},{"content":"An input iterator addressing the position one past the final element in the first or only source range to be operated on.","pos":[49117,49238]},{"content":"An output iterator addressing the position of the first element in the destination range.","pos":[49258,49347]},{"content":"A user-defined unary function object that is applied to each element in the source range.","pos":[49369,49458]},{"content":"A reference to the partitioner object.","pos":[49476,49514]},{"content":"The argument can be one of <ph id=\"ph1\">`const`</ph><bpt id=\"p1\">[</bpt>auto_partitioner<ept id=\"p1\">](auto-partitioner-class.md)</ept><ph id=\"ph2\">`&amp;`</ph>, <ph id=\"ph3\">`const`</ph><bpt id=\"p2\">[</bpt>static_partitioner<ept id=\"p2\">](static-partitioner-class.md)</ept><ph id=\"ph4\">`&amp;`</ph>, <ph id=\"ph5\">`const`</ph><bpt id=\"p3\">[</bpt>simple_partitioner<ept id=\"p3\">](simple-partitioner-class.md)</ept><ph id=\"ph6\">`&amp;`</ph> or <bpt id=\"p4\">[</bpt>affinity_partitioner<ept id=\"p4\">](affinity-partitioner-class.md)</ept><ph id=\"ph7\">`&amp;`</ph> If an <bpt id=\"p5\">[</bpt>affinity_partitioner<ept id=\"p5\">](affinity-partitioner-class.md)</ept> object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use.","pos":[49515,49974],"source":" The argument can be one of `const`[auto_partitioner](auto-partitioner-class.md)`&`, `const`[static_partitioner](static-partitioner-class.md)`&`, `const`[simple_partitioner](simple-partitioner-class.md)`&` or [affinity_partitioner](affinity-partitioner-class.md)`&` If an [affinity_partitioner](affinity-partitioner-class.md) object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use."},{"content":"An input iterator addressing the position of the first element in the second source range to be operated on.","pos":[49993,50101]},{"content":"A user-defined binary function object that is applied pairwise, in a forward order, to the two source ranges.","pos":[50124,50233]},{"content":"Return Value","pos":[50243,50255]},{"content":"An output iterator addressing the position one past the final element in the destination range that is receiving the output elements transformed by the function object.","pos":[50259,50427]},{"content":"Remarks","pos":[50437,50444]},{"pos":[50448,50566],"content":"<bpt id=\"p1\">[</bpt>auto_partitioner<ept id=\"p1\">](auto-partitioner-class.md)</ept> will be used for the overloads without an explicit partitioner argument.","source":"[auto_partitioner](auto-partitioner-class.md) will be used for the overloads without an explicit partitioner argument."},{"pos":[50573,50686],"content":"For iterators that do not support random access, only <bpt id=\"p1\">[</bpt>auto_partitioner<ept id=\"p1\">](auto-partitioner-class.md)</ept> is supported.","source":"For iterators that do not support random access, only [auto_partitioner](auto-partitioner-class.md) is supported."},{"content":"The overloads that take the argument <ph id=\"ph1\">`_Unary_op`</ph> transform the input range into the output range by applying the unary functor to each element in the input range.","pos":[50693,50855],"source":"The overloads that take the argument `_Unary_op` transform the input range into the output range by applying the unary functor to each element in the input range."},{"content":"must support the function call operator with signature <ph id=\"ph1\">`operator()(T)`</ph> where <ph id=\"ph2\">`T`</ph> is the value type of the range being iterated over.","pos":[50868,51000],"source":" must support the function call operator with signature `operator()(T)` where `T` is the value type of the range being iterated over."},{"content":"The overloads that take the argument <ph id=\"ph1\">`_Binary_op`</ph> transform two input ranges into the output range by applying the binary functor to one element from the first input range and one element from the second input range.","pos":[51007,51223],"source":"The overloads that take the argument `_Binary_op` transform two input ranges into the output range by applying the binary functor to one element from the first input range and one element from the second input range."},{"content":"must support the function call operator with signature <ph id=\"ph1\">`operator()(T, U)`</ph> where <ph id=\"ph2\">`T`</ph>, <ph id=\"ph3\">`U`</ph> are value types of the two input iterators.","pos":[51237,51369],"source":" must support the function call operator with signature `operator()(T, U)` where `T`, `U` are value types of the two input iterators."},{"pos":[51376,51473],"content":"For more information, see <bpt id=\"p1\">[</bpt>Parallel Algorithms<ept id=\"p1\">](../../../parallel/concrt/parallel-algorithms.md)</ept>.","source":"For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md)."},{"pos":[51507,51514],"content":"receive"},{"content":"A general receive implementation, allowing a context to wait for data from exactly one source and filter the values that are accepted.","pos":[51518,51652]},{"content":"Parameters","pos":[52258,52268]},{"content":"The payload type.","pos":[52279,52296]},{"content":"A pointer or reference to the source from which data is expected.","pos":[52313,52378]},{"content":"The maximum time for which the method should for the data, in milliseconds.","pos":[52399,52474]},{"content":"A filter function which determines whether messages should be accepted.","pos":[52499,52570]},{"content":"Return Value","pos":[52580,52592]},{"content":"A value from the source, of the payload type.","pos":[52596,52641]},{"content":"Remarks","pos":[52651,52658]},{"content":"If the parameter <ph id=\"ph1\">`_Timeout`</ph> has a value other than the constant <ph id=\"ph2\">`COOPERATIVE_TIMEOUT_INFINITE`</ph>, the exception <bpt id=\"p1\">[</bpt>operation_timed_out<ept id=\"p1\">](operation-timed-out-class.md)</ept> is thrown if the specified amount of time expires before a message is received.","pos":[52662,52903],"source":"If the parameter `_Timeout` has a value other than the constant `COOPERATIVE_TIMEOUT_INFINITE`, the exception [operation_timed_out](operation-timed-out-class.md) is thrown if the specified amount of time expires before a message is received."},{"content":"If you want a zero length timeout, you should use the <bpt id=\"p1\">[</bpt>try_receive<ept id=\"p1\">](concurrency-namespace-functions.md)</ept> function, as opposed to calling <ph id=\"ph1\">`receive`</ph> with a timeout of <ph id=\"ph2\">`0`</ph> (zero), as it is more efficient and does not throw exceptions on timeouts.","pos":[52904,53146],"source":" If you want a zero length timeout, you should use the [try_receive](concurrency-namespace-functions.md) function, as opposed to calling `receive` with a timeout of `0` (zero), as it is more efficient and does not throw exceptions on timeouts."},{"pos":[53153,53262],"content":"For more information, see <bpt id=\"p1\">[</bpt>Message Passing Functions<ept id=\"p1\">](../../../parallel/concrt/message-passing-functions.md)</ept>.","source":"For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md)."},{"pos":[53316,53343],"content":"run_with_cancellation_token"},{"content":"Executes a function object immediately and synchronously in the context of a given cancellation token.","pos":[53347,53449]},{"content":"Parameters","pos":[53592,53602]},{"content":"The type of the function object that will be invoked.","pos":[53621,53674]},{"content":"The function object which will be executed.","pos":[53692,53735]},{"content":"This object must support the function call operator with a signature of void(void).","pos":[53736,53819]},{"content":"The cancellation token which will control implicit cancellation of the function object.","pos":[53835,53922]},{"content":"Use <ph id=\"ph1\">`cancellation_token::none()`</ph> if you want the function execute without any possibility of implicit cancellation from a parent task group being canceled.","pos":[53923,54078],"source":" Use `cancellation_token::none()` if you want the function execute without any possibility of implicit cancellation from a parent task group being canceled."},{"content":"Remarks","pos":[54088,54095]},{"content":"Any interruption points in the function object will be triggered when the <ph id=\"ph1\">`cancellation_token`</ph> is canceled.","pos":[54099,54206],"source":"Any interruption points in the function object will be triggered when the `cancellation_token` is canceled."},{"content":"The explicit token <ph id=\"ph1\">`_Ct`</ph> will isolate this <ph id=\"ph2\">`_Func`</ph> from parent cancellation if the parent has a different token or no token.","pos":[54207,54331],"source":" The explicit token `_Ct` will isolate this `_Func` from parent cancellation if the parent has a different token or no token."},{"pos":[54362,54366],"content":"send"},{"content":"A synchronous send operation, which waits until the target either accepts or declines the message.","pos":[54370,54468]},{"content":"Parameters","pos":[54646,54656]},{"content":"The payload type.","pos":[54667,54684]},{"content":"A pointer or reference to the target to which data is sent.","pos":[54701,54760]},{"content":"A reference to the data to be sent.","pos":[54778,54813]},{"content":"Return Value","pos":[54823,54835]},{"pos":[54846,54893],"content":"if the message was accepted, <ph id=\"ph1\">`false`</ph> otherwise.","source":" if the message was accepted, `false` otherwise."},{"content":"Remarks","pos":[54903,54910]},{"pos":[54914,55023],"content":"For more information, see <bpt id=\"p1\">[</bpt>Message Passing Functions<ept id=\"p1\">](../../../parallel/concrt/message-passing-functions.md)</ept>.","source":"For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md)."},{"pos":[55071,55092],"content":"set_ambient_scheduler"},{"content":"Parameters","pos":[55214,55224]},{"pos":[55295,55323],"content":"set_task_execution_resources"},{"content":"Restricts the execution resources used by the Concurrency Runtime internal worker threads to the affinity set specified.","pos":[55327,55447]},{"content":"It is valid to call this method only before the Resource Manager has been created, or between two Resource Manager lifetimes.","pos":[55454,55579]},{"content":"It can be invoked multiple times as long as the Resource Manager does not exist at the time of invocation.","pos":[55580,55686]},{"content":"After an affinity limit has been set, it remains in effect until the next valid call to the <ph id=\"ph1\">`set_task_execution_resources`</ph> method.","pos":[55687,55817],"source":" After an affinity limit has been set, it remains in effect until the next valid call to the `set_task_execution_resources` method."},{"content":"The affinity mask provided need not be a subset of the process affinity mask.","pos":[55824,55901]},{"content":"The process affinity will be updated if necessary.","pos":[55902,55952]},{"content":"Parameters","pos":[56163,56173]},{"content":"The affinity mask that the Concurrency Runtime worker threads are to be restricted to.","pos":[56203,56289]},{"content":"Use this method on a system with greater than 64 hardware threads only if you want to limit the Concurrency Runtime to a subset of the current processor group.","pos":[56290,56449]},{"content":"In general, you should use the version of the method that accepts an array of group affinities as a parameter, to restrict affinity on machines with greater than 64 hardware threads.","pos":[56450,56632]},{"content":"The number of <ph id=\"ph1\">`GROUP_AFFINITY`</ph> entries in the array specified by the parameter <ph id=\"ph2\">`_PGroupAffinity`</ph>.","pos":[56650,56747],"source":" The number of `GROUP_AFFINITY` entries in the array specified by the parameter `_PGroupAffinity`."},{"content":"An array of <ph id=\"ph1\">`GROUP_AFFINITY`</ph> entries.","pos":[56775,56812],"source":" An array of `GROUP_AFFINITY` entries."},{"content":"Remarks","pos":[56822,56829]},{"pos":[56833,57128],"content":"The method will throw an <bpt id=\"p1\">[</bpt>invalid_operation<ept id=\"p1\">](invalid-operation-class.md)</ept> exception if a Resource Manager is present at the time it is invoked, and an <bpt id=\"p2\">[</bpt>invalid_argument<ept id=\"p2\">](../../../standard-library/invalid-argument-class.md)</ept> exception if the affinity specified results in an empty set of resources.","source":"The method will throw an [invalid_operation](invalid-operation-class.md) exception if a Resource Manager is present at the time it is invoked, and an [invalid_argument](../../../standard-library/invalid-argument-class.md) exception if the affinity specified results in an empty set of resources."},{"content":"The version of the method that takes an array of group affinities as a parameter should only be used on operating systems with version Windows 7 or higher.","pos":[57135,57290]},{"content":"Otherwise, an <bpt id=\"p1\">[</bpt>invalid_operation<ept id=\"p1\">](invalid-operation-class.md)</ept> exception is thrown.","pos":[57291,57373],"source":" Otherwise, an [invalid_operation](invalid-operation-class.md) exception is thrown."},{"content":"Programatically modifying the process affinity after this method has been invoked will not cause the Resource Manager to re-evaluate the affinity it is restricted to.","pos":[57380,57546]},{"content":"Therefore, all changes to process affinity should be made before calling this method.","pos":[57547,57632]},{"pos":[57663,57667],"content":"swap"},{"pos":[57671,57729],"content":"Exchanges the elements of two <ph id=\"ph1\">`concurrent_vector`</ph> objects.","source":"Exchanges the elements of two `concurrent_vector` objects."},{"content":"Parameters","pos":[57873,57883]},{"content":"The data type of the elements stored in the concurrent vectors.","pos":[57894,57957]},{"content":"The allocator type of the concurrent vectors.","pos":[57973,58018]},{"content":"The concurrent vector whose elements are to be exchanged with those of the concurrent vector <ph id=\"ph1\">`_B`</ph>.","pos":[58033,58131],"source":" The concurrent vector whose elements are to be exchanged with those of the concurrent vector `_B`."},{"content":"The concurrent vector providing the elements to be swapped, or the vector whose elements are to be exchanged with those of the concurrent vector <ph id=\"ph1\">`_A`</ph>.","pos":[58146,58296],"source":" The concurrent vector providing the elements to be swapped, or the vector whose elements are to be exchanged with those of the concurrent vector `_A`."},{"content":"Remarks","pos":[58306,58313]},{"content":"The template function is an algorithm specialized on the container class <ph id=\"ph1\">`concurrent_vector`</ph> to execute the member function <ph id=\"ph2\">`_A`</ph>.","pos":[58317,58446],"source":"The template function is an algorithm specialized on the container class `concurrent_vector` to execute the member function `_A`."},{"content":"<bpt id=\"p1\">[</bpt>concurrent_vector::swap<ept id=\"p1\">](concurrent-vector-class.md#swap)</ept>( <ph id=\"ph1\">`_B`</ph>).","pos":[58447,58513],"source":"[concurrent_vector::swap](concurrent-vector-class.md#swap)( `_B`)."},{"content":"These are instances of the partial ordering of function templates by the compiler.","pos":[58514,58596]},{"content":"When template functions are overloaded in such a way that the match of the template with the function call is not unique, then the compiler will select the most specialized version of the template function.","pos":[58597,58803]},{"content":"The general version of the template function, <ph id=\"ph1\">`template &lt;class T&gt; void swap(T&amp;, T&amp;)`</ph>, in the algorithm class works by assignment and is a slow operation.","pos":[58804,58957],"source":" The general version of the template function, `template <class T> void swap(T&, T&)`, in the algorithm class works by assignment and is a slow operation."},{"content":"The specialized version in each container is much faster as it can work with the internal representation of the container class.","pos":[58958,59086]},{"content":"This method is not concurrency-safe.","pos":[59093,59129]},{"content":"You must ensure that no other threads are performing operations on either of the concurrent vectors when you call this method.","pos":[59130,59256]},{"pos":[59302,59321],"content":"task_from_exception"},{"content":"Parameters","pos":[59508,59518]},{"content":"Return Value","pos":[59590,59602]},{"pos":[59645,59661],"content":"task_from_result"},{"content":"Parameters","pos":[59943,59953]},{"content":"Return Value","pos":[60000,60012]},{"pos":[60065,60091],"content":"Trace_agents_register_name"},{"content":"Associates the given name to the message block or agent in the ETW trace.","pos":[60095,60168]},{"content":"Parameters","pos":[60302,60312]},{"content":"The type of the object.","pos":[60323,60346]},{"content":"This is typically a message block or an agent.","pos":[60347,60393]},{"content":"A pointer to the message block or agent that is being named in the trace.","pos":[60414,60487]},{"content":"The name for the given object.","pos":[60505,60535]},{"pos":[60573,60584],"content":"try_receive"},{"content":"A general try-receive implementation, allowing a context to look for data from exactly one source and filter the values that are accepted.","pos":[60588,60726]},{"content":"If the data is not ready, the method will return false.","pos":[60727,60782]},{"content":"Parameters","pos":[61245,61255]},{"content":"The payload type","pos":[61266,61282]},{"content":"A pointer or reference to the source from which data is expected.","pos":[61299,61364]},{"content":"A reference to a location where the result will be placed.","pos":[61383,61441]},{"content":"A filter function which determines whether messages should be accepted.","pos":[61466,61537]},{"content":"Return Value","pos":[61547,61559]},{"pos":[61563,61637],"content":"A <ph id=\"ph1\">`bool`</ph> value indicating whether or not a payload was placed in <ph id=\"ph2\">`_value`</ph>.","source":"A `bool` value indicating whether or not a payload was placed in `_value`."},{"content":"Remarks","pos":[61647,61654]},{"pos":[61658,61767],"content":"For more information, see <bpt id=\"p1\">[</bpt>Message Passing Functions<ept id=\"p1\">](../../../parallel/concrt/message-passing-functions.md)</ept>.","source":"For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md)."},{"pos":[61798,61802],"content":"wait"},{"content":"Pauses the current context for a specified amount of time.","pos":[61806,61864]},{"content":"Parameters","pos":[61934,61944]},{"content":"The number of milliseconds the current context should be paused for.","pos":[61967,62035]},{"content":"If the <ph id=\"ph1\">`_Milliseconds`</ph> parameter is set to the value <ph id=\"ph2\">`0`</ph>, the current context should yield execution to other runnable contexts before continuing.","pos":[62036,62182],"source":" If the `_Milliseconds` parameter is set to the value `0`, the current context should yield execution to other runnable contexts before continuing."},{"content":"Remarks","pos":[62192,62199]},{"content":"If this method is called on a Concurrency Runtime scheduler context, the scheduler will find a different context to run on the underlying resource.","pos":[62203,62350]},{"content":"Because the scheduler is cooperative in nature, this context cannot resume exactly after the number of milliseconds specified.","pos":[62351,62477]},{"content":"If the scheduler is busy executing other tasks that do not cooperatively yield to the scheduler, the wait period could be indefinite.","pos":[62478,62611]},{"pos":[62646,62654],"content":"when_all"},{"content":"Creates a task that will complete successfully when all of the tasks supplied as arguments complete successfully.","pos":[62658,62771]},{"content":"Parameters","pos":[63104,63114]},{"content":"The type of the input iterator.","pos":[63133,63164]},{"content":"The position of the first element in the range of elements to be combined into the resulting task.","pos":[63183,63281]},{"content":"The position of the first element beyond the range of elements to be combined into the resulting task.","pos":[63298,63400]},{"content":"Return Value","pos":[63431,63443]},{"content":"A task that completes sucessfully when all of the input tasks have completed successfully.","pos":[63447,63537]},{"content":"If the input tasks are of type <ph id=\"ph1\">`T`</ph>, the output of this function will be a <ph id=\"ph2\">`task&lt;std::vector&lt;T&gt;&gt;`</ph>.","pos":[63538,63635],"source":" If the input tasks are of type `T`, the output of this function will be a `task<std::vector<T>>`."},{"content":"If the input tasks are of type <ph id=\"ph1\">`void`</ph> the output task will also be a <ph id=\"ph2\">`task&lt;void&gt;`</ph>.","pos":[63636,63718],"source":" If the input tasks are of type `void` the output task will also be a `task<void>`."},{"content":"Remarks","pos":[63728,63735]},{"content":"is a non-blocking function that produces a <ph id=\"ph1\">`task`</ph> as its result.","pos":[63750,63814],"source":" is a non-blocking function that produces a `task` as its result."},{"content":"Unlike <bpt id=\"p1\">[</bpt>task::wait<ept id=\"p1\">](task-class.md#wait)</ept>, it is safe to call this function in a <ph id=\"ph1\">[!INCLUDE[win8_appname_long](../../../build/includes/win8_appname_long_md.md)]</ph> app on the ASTA (Application STA) thread.","pos":[63815,64014],"source":" Unlike [task::wait](task-class.md#wait), it is safe to call this function in a [!INCLUDE[win8_appname_long](../../../build/includes/win8_appname_long_md.md)] app on the ASTA (Application STA) thread."},{"pos":[64021,64267],"content":"If one of the tasks is canceled or throws an exception, the returned task will complete early, in the canceled state, and the exception, if one is encoutered, will be thrown if you call <bpt id=\"p1\">[</bpt>task::get<ept id=\"p1\">](task-class.md#get)</ept> or <ph id=\"ph1\">`task::wait`</ph> on that task.","source":"If one of the tasks is canceled or throws an exception, the returned task will complete early, in the canceled state, and the exception, if one is encoutered, will be thrown if you call [task::get](task-class.md#get) or `task::wait` on that task."},{"pos":[64274,64385],"content":"For more information, see <bpt id=\"p1\">[</bpt>Task Parallelism<ept id=\"p1\">](../../../parallel/concrt/task-parallelism-concurrency-runtime.md)</ept>.","source":"For more information, see [Task Parallelism](../../../parallel/concrt/task-parallelism-concurrency-runtime.md)."},{"pos":[64420,64428],"content":"when_any"},{"content":"Creates a task that will complete successfully when any of the tasks supplied as arguments completes successfully.","pos":[64432,64546]},{"content":"Parameters","pos":[65187,65197]},{"content":"The type of the input iterator.","pos":[65216,65247]},{"content":"The position of the first element in the range of elements to be combined into the resulting task.","pos":[65266,65364]},{"content":"The position of the first element beyond the range of elements to be combined into the resulting task.","pos":[65381,65483]},{"content":"The cancellation token which controls cancellation of the returned task.","pos":[65532,65604]},{"content":"If you do not provide a cancellation token, the resulting task will receive the cancellation token of the task that causes it to complete.","pos":[65605,65743]},{"content":"Return Value","pos":[65753,65765]},{"content":"A task that completes successfully when any one of the input tasks has completed successfully.","pos":[65769,65863]},{"content":"If the input tasks are of type <ph id=\"ph1\">`T`</ph>, the output of this function will be a <ph id=\"ph2\">`task&lt;std::pair&lt;T, size_t&gt;&gt;&gt;`</ph>, where the first element of the pair is the result of the completing task, and the second element is the index of the task that finished.","pos":[65864,66105],"source":" If the input tasks are of type `T`, the output of this function will be a `task<std::pair<T, size_t>>>`, where the first element of the pair is the result of the completing task, and the second element is the index of the task that finished."},{"content":"If the input tasks are of type <ph id=\"ph1\">`void`</ph> the output is a <ph id=\"ph2\">`task&lt;size_t&gt;`</ph>, where the result is the index of the completing task.","pos":[66106,66229],"source":" If the input tasks are of type `void` the output is a `task<size_t>`, where the result is the index of the completing task."},{"content":"Remarks","pos":[66239,66246]},{"content":"is a non-blocking function that produces a <ph id=\"ph1\">`task`</ph> as its result.","pos":[66261,66325],"source":" is a non-blocking function that produces a `task` as its result."},{"content":"Unlike <bpt id=\"p1\">[</bpt>task::wait<ept id=\"p1\">](task-class.md#wait)</ept>, it is safe to call this function in a <ph id=\"ph1\">[!INCLUDE[win8_appname_long](../../../build/includes/win8_appname_long_md.md)]</ph> app on the ASTA (Application STA) thread.","pos":[66326,66525],"source":" Unlike [task::wait](task-class.md#wait), it is safe to call this function in a [!INCLUDE[win8_appname_long](../../../build/includes/win8_appname_long_md.md)] app on the ASTA (Application STA) thread."},{"pos":[66532,66643],"content":"For more information, see <bpt id=\"p1\">[</bpt>Task Parallelism<ept id=\"p1\">](../../../parallel/concrt/task-parallelism-concurrency-runtime.md)</ept>.","source":"For more information, see [Task Parallelism](../../../parallel/concrt/task-parallelism-concurrency-runtime.md)."},{"content":"See Also","pos":[66652,66660]},{"content":"concurrency Namespace","pos":[66665,66686]}],"content":"---\ntitle: \"concurrency namespace functions | Microsoft Docs\"\nms.custom: \"\"\nms.date: \"11/04/2016\"\nms.reviewer: \"\"\nms.suite: \"\"\nms.tgt_pltfrm: \"\"\nms.topic: \"article\"\nms.assetid: 520a6dff-9324-4df2-990d-302e3050af6a\ncaps.latest.revision: 6\nauthor: \"mikeblome\"\nms.author: \"mblome\"\nmanager: \"ghogen\"\n---\n# concurrency namespace functions\n||||  \n|-|-|-|  \n|[Alloc](#alloc)|[CreateResourceManager](#createresourcemanager)|[DisableTracing](#disabletracing)|  \n|[EnableTracing](#enabletracing)|[Free](#free)|[GetExecutionContextId](#getexecutioncontextid)|  \n|[GetOSVersion](#getosversion)|[GetProcessorCount](#getprocessorcount)|[GetProcessorNodeCount](#getprocessornodecount)|  \n|[GetSchedulerId](#getschedulerid)|[Trace_agents_register_name](#trace_agents_register_name)|[asend](#asend)|  \n|[cancel_current_task](#cancel_current_task)|[clear](#clear)|[create_async](#create_async)|  \n|[create_task](#create_task)|[get_ambient_scheduler](#get_ambient_scheduler)|[internal_assign_iterators](#internal_assign_iterators)|  \n|[interruption_point](#interruption_point)|[is_current_task_group_canceling](#is_current_task_group_canceling)|[make_choice](#make_choice)|  \n|[make_greedy_join](#make_greedy_join)|[make_join](#make_join)|[make_task](#make_task)|  \n|[parallel_buffered_sort](#parallel_buffered_sort)|[parallel_for](#parallel_for)|[parallel_for_each](#parallel_for_each)|  \n|[parallel_invoke](#parallel_invoke)|[parallel_radixsort](#parallel_radixsort)|[parallel_reduce](#parallel_reduce)|  \n|[parallel_sort](#parallel_sort)|[parallel_transform](#parallel_transform)|[receive](#receive)|  \n|[run_with_cancellation_token](#run_with_cancellation_token)|[send](#send)|[set_ambient_scheduler](#set_ambient_scheduler)|  \n|[set_task_execution_resources](#set_task_execution_resources)|[swap](#swap)|[task_from_exception](#task_from_exception)|  \n|[task_from_result](#task_from_result)|[try_receive](#try_receive)|[wait](#wait)|  \n|[when_all](#when_all)|[when_any](#when_any)|  \n  \n##  <a name=\"alloc\"></a>  Alloc  \n Allocates a block of memory of the size specified from the Concurrency Runtime Caching Suballocator.  \n  \n```\nvoid* __cdecl Alloc(size_t _NumBytes);\n```  \n  \n### Parameters  \n `_NumBytes`  \n The number of bytes of memory to allocate.  \n  \n### Return Value  \n A pointer to newly allocated memory.  \n  \n### Remarks  \n For more information about which scenarios in your application could benefit from using the Caching Suballocator, see [Task Scheduler](../../../parallel/concrt/task-scheduler-concurrency-runtime.md).  \n  \n##  <a name=\"asend\"></a>  asend  \n An asynchronous send operation, which schedules a task to propagate the data to the target block.  \n  \n```\ntemplate <class T>\nbool asend(\n    _Inout_ ITarget<T>* _Trg,\n    const T& _Data);\n\ntemplate <class T>\nbool asend(\n    ITarget<T>& _Trg,\n    const T& _Data);\n```  \n  \n### Parameters  \n `T`  \n The type of the data to be sent.  \n  \n `_Trg`  \n A pointer or reference to the target to which data is sent.  \n  \n `_Data`  \n A reference to the data to be sent.  \n  \n### Return Value  \n `true` if the message was accepted before the method returned, `false` otherwise.  \n  \n### Remarks  \n For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md).  \n  \n##  <a name=\"cancel_current_task\"></a>  cancel_current_task  \n Cancels the currently executing task. This function can be called from within the body of a task to abort the task's execution and cause it to enter the `canceled` state.  \n  \n It is not a supported scenario to call this function if you are not within the body of a `task`. Doing so will result in undefined behavior such as a crash or a hang in your application.  \n  \n```\ninline __declspec(noreturn) void __cdecl cancel_current_task();\n```  \n  \n##  <a name=\"clear\"></a>  clear  \n Clears the concurrent queue, destroying any currently enqueued elements. This method is not concurrency-safe.  \n  \n```\ntemplate<typename T, class _Ax>\nvoid concurrent_queue<T,\n    _Ax>::clear();\n```   \n  \n### Parameters  \n `T`  \n `_Ax`  \n  \n##  <a name=\"create_async\"></a>  create_async  \n Creates a Windows Runtime asynchronous construct based on a user supplied lambda or function object. The return type of `create_async` is one of either `IAsyncAction^`, `IAsyncActionWithProgress<TProgress>^`, `IAsyncOperation<TResult>^`, or `IAsyncOperationWithProgress<TResult, TProgress>^` based on the signature of the lambda passed to the method.  \n  \n```\ntemplate<typename _Function>\n__declspec(noinline) auto create_async(const _Function& _Func) -> decltype(ref new details::_AsyncTaskGeneratorThunk<_Function>(_Func));\n```  \n  \n### Parameters  \n `_Function`  \n `_Func`  \n The lambda or function object from which to create a Windows Runtime asynchronous construct.  \n  \n### Return Value  \n An asynchronous construct represented by an IAsyncAction^, IAsyncActionWithProgress\\<TProgress>^, IAsyncOperation\\<TResult>^, or an IAsyncOperationWithProgress\\<TResult, TProgress>^. The interface returned depends on the signature of the lambda passed into the function.  \n  \n### Remarks  \n The return type of the lambda determines whether the construct is an action or an operation.  \n  \n Lambdas that return void cause the creation of actions. Lambdas that return a result of type `TResult` cause the creation of operations of TResult.  \n  \n The lambda may also return a `task<TResult>` which encapsulates the aysnchronous work within itself or is the continuation of a chain of tasks that represent the asynchronous work. In this case, the lambda itself is executed inline, since the tasks are the ones that execute asynchronously, and the return type of the lambda is unwrapped to produce the asynchronous construct returned by `create_async`. This implies that a lambda that returns a task\\<void> will cause the creation of actions, and a lambda that returns a task\\<TResult> will cause the creation of operations of TResult.  \n  \n The lambda may take either zero, one or two arguments. The valid arguments are `progress_reporter<TProgress>` and `cancellation_token`, in that order if both are used. A lambda without arguments causes the creation of an asynchronous construct without the capability for progress reporting. A lambda that takes a progress_reporter\\<TProgress> will cause `create_async` to return an asynchronous construct which reports progress of type TProgress each time the `report` method of the progress_reporter object is called. A lambda that takes a cancellation_token may use that token to check for cancellation, or pass it to tasks that it creates so that cancellation of the asynchronous construct causes cancellation of those tasks.  \n  \n If the body of the lambda or function object returns a result (and not a task\\<TResult>), the lamdba will be executed asynchronously within the process MTA in the context of a task the Runtime implicitly creates for it. The `IAsyncInfo::Cancel` method will cause cancellation of the implicit task.  \n  \n If the body of the lambda returns a task, the lamba executes inline, and by declaring the lambda to take an argument of type `cancellation_token` you can trigger cancellation of any tasks you create within the lambda by passing that token in when you create them. You may also use the `register_callback` method on the token to cause the Runtime to invoke a callback when you call `IAsyncInfo::Cancel` on the async operation or action produced..  \n  \n This function is only available to Windows Store apps.  \n  \n##  <a name=\"createresourcemanager\"></a>  CreateResourceManager  \n Returns an interface that represents the singleton instance of the Concurrency Runtime's Resource Manager. The Resource Manager is responsible for assigning resources to schedulers that want to cooperate with each other.  \n  \n```\nIResourceManager* __cdecl CreateResourceManager();\n```  \n  \n### Return Value  \n An `IResourceManager` interface.  \n  \n### Remarks  \n Multiple subsequent calls to this method will return the same instance of the Resource Manager. Each call to the method increments a reference count on the Resource Manager, and must be matched with a call to the [IResourceManager::Release](http://msdn.microsoft.com/en-us/5d1356ec-fbd3-4284-a361-1e9e20bbb522) method when your scheduler is done communicating with the Resource Manager.  \n  \n [unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime.  \n  \n##  <a name=\"create_task\"></a>  create_task  \n Creates a PPL [task](http://msdn.microsoft.com/en-us/5389e8a5-5038-40b6-844a-55e9b58ad35f) object. `create_task` can be used anywhere you would have used a task constructor. It is provided mainly for convenience, because it allows use of the `auto` keyword while creating tasks.  \n  \n```\ntemplate<typename T>\n__declspec(\n    noinline) auto create_task(T _Param, const task_options& _TaskOptions = task_options()) -> task<typename details::_TaskTypeFromParam<T>::T>;\n\ntemplate<typename _ReturnType>\n__declspec(\n    noinline) task<_ReturnType> create_task(const task<_ReturnType>& _Task);\n```  \n  \n### Parameters  \n `T`  \n The type of the parameter from which the task is to be constructed.  \n  \n `_ReturnType`  \n `_Param`  \n The parameter from which the task is to be constructed. This could be a lambda or function object, a `task_completion_event` object, a different `task` object, or a Windows::Foundation::IAsyncInfo interface if you are using tasks in your Windows Store app.  \n  \n `_TaskOptions`  \n `_Task`  \n  \n### Return Value  \n A new task of type `T`, that is inferred from `_Param`.  \n  \n### Remarks  \n The first overload behaves like a task constructor that takes a single parameter.  \n  \n The second overload associates the cancellation token provided with the newly created task. If you use this overload you are not allowed to pass in a different `task` object as the first parameter.  \n  \n The type of the returned task is inferred from the first parameter to the function. If `_Param` is a `task_completion_event<T>`, a `task<T>`, or a functor that returns either type `T` or `task<T>`, the type of the created task is `task<T>`.  \n  \n In a Windows Store app, if `_Param` is of type Windows::Foundation::IAsyncOperation\\<T>^ or Windows::Foundation::IAsyncOperationWithProgress\\<T,P>^, or a functor that returns either of those types, the created task will be of type `task<T>`. If `_Param` is of type Windows::Foundation::IAsyncAction^ or Windows::Foundation::IAsyncActionWithProgress\\<P>^, or a functor that returns either of those types, the created task will have type `task<void>`.  \n  \n##  <a name=\"disabletracing\"></a>  DisableTracing  \n Disables tracing in the Concurrency Runtime. This function is deprecated because ETW tracing is unregistered by default.  \n  \n```\n__declspec(deprecated(\"Concurrency::DisableTracing is a deprecated function.\")) _CRTIMP HRESULT __cdecl DisableTracing();\n```  \n  \n### Return Value  \n If tracing was correctly disabled, `S_OK` is returned. If tracing was not previously initiated, `E_NOT_STARTED` is returned  \n  \n##  <a name=\"enabletracing\"></a>  EnableTracing  \n Enables tracing in the Concurrency Runtime. This function is deprecated because ETW tracing is now on by default.  \n  \n```\n__declspec(deprecated(\"Concurrency::EnableTracing is a deprecated function.\")) _CRTIMP HRESULT __cdecl EnableTracing();\n```  \n  \n### Return Value  \n If tracing was correctly initiated, `S_OK` is returned; otherwise, `E_NOT_STARTED` is returned.  \n  \n##  <a name=\"free\"></a>  Free  \n Releases a block of memory previously allocated by the `Alloc` method to the Concurrency Runtime Caching Suballocator.  \n  \n```\nvoid __cdecl Free(_Pre_maybenull_ _Post_invalid_ void* _PAllocation);\n```  \n  \n### Parameters  \n `_PAllocation`  \n A pointer to memory previously allocated by the `Alloc` method which is to be freed. If the parameter `_PAllocation` is set to the value `NULL`, this method will ignore it and return immediately.  \n  \n### Remarks  \n For more information about which scenarios in your application could benefit from using the Caching Suballocator, see [Task Scheduler](../../../parallel/concrt/task-scheduler-concurrency-runtime.md).  \n  \n##  <a name=\"get_ambient_scheduler\"></a>  get_ambient_scheduler  \n  \n```\ninline std::shared_ptr<::Concurrency::scheduler_interface> get_ambient_scheduler();\n```  \n  \n### Return Value  \n  \n##  <a name=\"getexecutioncontextid\"></a>  GetExecutionContextId  \n Returns a unique identifier that can be assigned to an execution context that implements the `IExecutionContext` interface.  \n  \n```\nunsigned int __cdecl GetExecutionContextId();\n```  \n  \n### Return Value  \n A unique identifier for an execution context.  \n  \n### Remarks  \n Use this method to obtain an identifier for your execution context before you pass an `IExecutionContext` interface as a parameter to any of the methods offered by the Resource Manager.  \n  \n##  <a name=\"getosversion\"></a>  GetOSVersion  \n Returns the operating system version.  \n  \n```\nIResourceManager::OSVersion __cdecl GetOSVersion();\n```  \n  \n### Return Value  \n An enumerated value representing the operating system.  \n  \n### Remarks  \n [unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime.  \n  \n##  <a name=\"getprocessorcount\"></a>  GetProcessorCount  \n Returns the number of hardware threads on the underlying system.  \n  \n```\nunsigned int __cdecl GetProcessorCount();\n```  \n  \n### Return Value  \n The number of hardware threads.  \n  \n### Remarks  \n [unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime.  \n  \n##  <a name=\"getprocessornodecount\"></a>  GetProcessorNodeCount  \n Returns the number of NUMA nodes or processor packages on the underlying system.  \n  \n```\nunsigned int __cdecl GetProcessorNodeCount();\n```  \n  \n### Return Value  \n The number of NUMA nodes or processor packages.  \n  \n### Remarks  \n If the system contains more NUMA nodes than processor packages, the number of NUMA nodes is returned, otherwise, the number of processor packages is returned.  \n  \n [unsupported_os](unsupported-os-class.md) is thrown if the operating system is not supported by the Concurrency Runtime.  \n  \n##  <a name=\"getschedulerid\"></a>  GetSchedulerId  \n Returns a unique identifier that can be assigned to a scheduler that implements the `IScheduler` interface.  \n  \n```\nunsigned int __cdecl GetSchedulerId();\n```  \n  \n### Return Value  \n A unique identifier for a scheduler.  \n  \n### Remarks  \n Use this method to obtain an identifier for your scheduler before you pass an `IScheduler` interface as a parameter to any of the methods offered by the Resource Manager.  \n  \n##  <a name=\"internal_assign_iterators\"></a>  internal_assign_iterators  \n  \n```\ntemplate<typename T, class _Ax>\ntemplate<class _I> void concurrent_vector<T,\n    _Ax>::internal_assign_iterators(\n _I\n    first,\n _I\n    last);\n```   \n  \n### Parameters  \n `T`  \n `_Ax`  \n `_I`  \n `first`  \n `last`  \n  \n##  <a name=\"interruption_point\"></a>  interruption_point  \n Creates an interruption point for cancellation. If a cancellation is in progress in the context where this function is called, this will throw an internal exception that aborts the execution of the currently executing parallel work. If cancellation is not in progress, the function does nothing.  \n  \n```\ninline void interruption_point();\n```  \n  \n### Remarks  \n You should not catch the internal cancellation exception thrown by the `interruption_point()` function. The exception will be caught and handled by the runtime, and catching it may cause your program to behave abnormally.  \n  \n##  <a name=\"is_current_task_group_canceling\"></a>  is_current_task_group_canceling  \n Returns an indication of whether the task group which is currently executing inline on the current context is in the midst of an active cancellation (or will be shortly). Note that if there is no task group currently executing inline on the current context, `false` will be returned.  \n  \n```\nbool __cdecl is_current_task_group_canceling();\n```  \n  \n### Return Value  \n `true` if the task group which is currently executing is canceling, `false` otherwise.  \n  \n### Remarks  \n For more information, see [Cancellation](../../../parallel/concrt/exception-handling-in-the-concurrency-runtime.md#cancellation).  \n  \n##  <a name=\"make_choice\"></a>  make_choice  \n Constructs a `choice` messaging block from an optional `Scheduler` or `ScheduleGroup` and two or more input sources.  \n  \n```\ntemplate<typename T1,\n    typename T2,\n    typename... Ts>\nchoice<std::tuple<T1,\n    T2,\n Ts...>> make_choice(\n    Scheduler& _PScheduler,\n    T1\n _Item1,\n    T2\n _Item2,\n    Ts... _Items);\n\ntemplate<typename T1,\n    typename T2,\n    typename... Ts>\nchoice<std::tuple<T1,\n    T2,\n Ts...>> make_choice(\n    ScheduleGroup& _PScheduleGroup,\n    T1\n _Item1,\n    T2\n _Item2,\n    Ts... _Items);\n\ntemplate<typename T1,\n    typename T2,\n    typename... Ts>\nchoice<std::tuple<T1,\n    T2,\n Ts...>> make_choice(\n    T1\n _Item1,\n    T2\n _Item2,\n    Ts... _Items);\n```  \n  \n### Parameters  \n `T1`  \n The message block type of the first source.  \n  \n `T2`  \n The message block type of the second source.  \n  \n `_PScheduler`  \n The `Scheduler` object within which the propagation task for the `choice` messaging block is scheduled.  \n  \n `_Item1`  \n The first source.  \n  \n `_Item2`  \n The second source.  \n  \n `_Items`  \n Additional sources.  \n  \n `_PScheduleGroup`  \n The `ScheduleGroup` object within which the propagation task for the `choice` messaging block is scheduled. The `Scheduler` object used is implied by the schedule group.  \n  \n### Return Value  \n A `choice` message block with two or more input sources.  \n  \n##  <a name=\"make_greedy_join\"></a>  make_greedy_join  \n Constructs a `greedy multitype_join` messaging block from an optional `Scheduler` or `ScheduleGroup` and two or more input sources.  \n  \n```\ntemplate<typename T1,\n    typename T2,\n    typename... Ts>\nmultitype_join<std::tuple<T1,\n    T2,\n Ts...>,\n    greedy> make_greedy_join(\n    Scheduler& _PScheduler,\n    T1\n _Item1,\n    T2\n _Item2,\n    Ts... _Items);\n\ntemplate<typename T1,\n    typename T2,\n    typename... Ts>\nmultitype_join<std::tuple<T1,\n    T2,\n Ts...>,\n    greedy> make_greedy_join(\n    ScheduleGroup& _PScheduleGroup,\n    T1\n _Item1,\n    T2\n _Item2,\n    Ts... _Items);\n\ntemplate<typename T1,\n    typename T2,\n    typename... Ts>\nmultitype_join<std::tuple<T1,\n    T2,\n Ts...>,\n    greedy> make_greedy_join(\n    T1\n _Item1,\n    T2\n _Item2,\n    Ts... _Items);\n```  \n  \n### Parameters  \n `T1`  \n The message block type of the first source.  \n  \n `T2`  \n The message block type of the second source.  \n  \n `_PScheduler`  \n The `Scheduler` object within which the propagation task for the `multitype_join` messaging block is scheduled.  \n  \n `_Item1`  \n The first source.  \n  \n `_Item2`  \n The second source.  \n  \n `_Items`  \n Additional sources.  \n  \n `_PScheduleGroup`  \n The `ScheduleGroup` object within which the propagation task for the `multitype_join` messaging block is scheduled. The `Scheduler` object used is implied by the schedule group.  \n  \n### Return Value  \n A `greedy multitype_join` message block with two or more input sources.  \n  \n##  <a name=\"make_join\"></a>  make_join  \n Constructs a `non_greedy multitype_join` messaging block from an optional `Scheduler` or `ScheduleGroup` and two or more input sources.  \n  \n```\ntemplate<typename T1, typename T2, typename... Ts>\nmultitype_join<std::tuple<T1, T2, Ts...>> \n    make_join(\n Scheduler& _PScheduler,\n    T1 _Item1,\n    T2 _Item2,\n    Ts... _Items);\n\ntemplate<typename T1, typename T2, typename... Ts>\nmultitype_join<std::tuple<T1, T2, Ts...>>\nmake_join(\n ScheduleGroup& _PScheduleGroup,\n    T1 _Item1,\n    T2 _Item2,\n    Ts... _Items);\n\ntemplate<typename T1, typename T2, typename... Ts>\nmultitype_join<std::tuple<T1, T2, Ts...>>\nmake_join(\n T1 _Item1,\n    T2 _Item2,\n    Ts... _Items);\n```  \n  \n### Parameters  \n `T1`  \n The message block type of the first source.  \n  \n `T2`  \n The message block type of the second source.  \n  \n `_PScheduler`  \n The `Scheduler` object within which the propagation task for the `multitype_join` messaging block is scheduled.  \n  \n `_Item1`  \n The first source.  \n  \n `_Item2`  \n The second source.  \n  \n `_Items`  \n Additional sources.  \n  \n `_PScheduleGroup`  \n The `ScheduleGroup` object within which the propagation task for the `multitype_join` messaging block is scheduled. The `Scheduler` object used is implied by the schedule group.  \n  \n### Return Value  \n A `non_greedy multitype_join` message block with two or more input sources.  \n  \n##  <a name=\"make_task\"></a>  make_task  \n A factory method for creating a `task_handle` object.  \n  \n```\ntemplate <class _Function>\ntask_handle<_Function> make_task(const _Function& _Func);\n```  \n  \n### Parameters  \n `_Function`  \n The type of the function object that will be invoked to execute the work represented by the `task_handle` object.  \n  \n `_Func`  \n The function that will be invoked to execute the work represented by the `task_handle` object. This may be a lambda functor, a pointer to a function, or any object that supports a version of the function call operator with the signature `void operator()()`.  \n  \n### Return Value  \n A `task_handle` object.  \n  \n### Remarks  \n This function is useful when you need to create a `task_handle` object with a lambda expression, because it allows you to create the object without knowing the true type of the lambda functor.  \n  \n##  <a name=\"parallel_buffered_sort\"></a>  parallel_buffered_sort  \n Arranges the elements in a specified range into a nondescending order, or according to an ordering criterion specified by a binary predicate, in parallel. This function is semantically similar to `std::sort` in that it is a compare-based, unstable, in-place sort except that it needs `O(n)` additional space, and requires default initialization for the elements being sorted.  \n  \n```\ntemplate<typename _Random_iterator>\ninline void parallel_buffered_sort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End);\n\ntemplate<typename _Allocator,\n    typename _Random_iterator>\ninline void parallel_buffered_sort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End);\n\ntemplate<typename _Allocator,\n    typename _Random_iterator>\ninline void parallel_buffered_sort(\n    const _Allocator& _Alloc,\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End);\n\ntemplate<typename _Random_iterator,\n    typename _Function>\ninline void parallel_buffered_sort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End,\n    const _Function& _Func,\n    const size_t _Chunk_size = 2048);\n\ntemplate<typename _Allocator,\n    typename _Random_iterator,\n    typename _Function>\ninline void parallel_buffered_sort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End,\n    const _Function& _Func,\n    const size_t _Chunk_size = 2048);\n\ntemplate<typename _Allocator,\n    typename _Random_iterator,\n    typename _Function>\ninline void parallel_buffered_sort(\n    const _Allocator& _Alloc,\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End,\n    const _Function& _Func,\n    const size_t _Chunk_size = 2048);\n```  \n  \n### Parameters  \n `_Random_iterator`  \n The iterator type of the input range.  \n  \n `_Allocator`  \n The type of an STL compatible memory allocator.  \n  \n `_Function`  \n The type of the binary comparator.  \n  \n `_Begin`  \n A random-access iterator addressing the position of the first element in the range to be sorted.  \n  \n `_End`  \n A random-access iterator addressing the position one past the final element in the range to be sorted.  \n  \n `_Alloc`  \n An instance of an STL compatible memory allocator.  \n  \n `_Func`  \n A user-defined predicate function object that defines the comparison criterion to be satisfied by successive elements in the ordering. A binary predicate takes two arguments and returns `true` when satisfied and `false` when not satisfied. This comparator function must impose a strict weak ordering on pairs of elements from the sequence.  \n  \n `_Chunk_size`  \n The mimimum size of a chunk that will be split into two for parallel execution.  \n  \n### Remarks  \n All overloads require `n * sizeof(T)` additional space, where `n` is the number of elements to be sorted, and `T` is the element type. In most cases parallel_buffered_sort will show an improvement in performance over [parallel_sort](concurrency-namespace-functions.md), and you should use it over parallel_sort if you have the memory available.  \n  \n If you do not supply a binary comparator `std::less` is used as the default, which requires the element type to provide the operator `operator<()`.  \n  \n If you do not supply an allocator type or instance, the STL memory allocator `std::allocator<T>` is used to allocate the buffer.  \n  \n The algorithm divides the input range into two chunks and successively divides each chunk into two sub-chunks for execution in parallel. The optional argument `_Chunk_size` can be used to indicate to the algorithm that it should handles chunks of size < `_Chunk_size` serially.  \n  \n##  <a name=\"parallel_for\"></a>  parallel_for  \n `parallel_for` iterates over a range of indices and executes a user-supplied function at each iteration, in parallel.  \n  \n```\ntemplate <typename _Index_type, typename _Function, typename _Partitioner>\nvoid parallel_for(\n    _Index_type first,\n    _Index_type last,\n    _Index_type _Step,\n    const _Function& _Func,\n    _Partitioner&& _Part);\n\ntemplate <typename _Index_type, typename _Function>\nvoid parallel_for(\n    _Index_type first,\n    _Index_type last,\n    _Index_type _Step,\n    const _Function& _Func);\n\ntemplate <typename _Index_type, typename _Function>\nvoid parallel_for(\n    _Index_type first,\n    _Index_type last,\n    const _Function& _Func,\n    const auto_partitioner& _Part = auto_partitioner());\n\ntemplate <typename _Index_type, typename _Function>\nvoid parallel_for(\n    _Index_type first,\n    _Index_type last,\n    const _Function& _Func,\n    const static_partitioner& _Part);\n\ntemplate <typename _Index_type, typename _Function>\nvoid parallel_for(\n    _Index_type first,\n    _Index_type last,\n    const _Function& _Func,\n    const simple_partitioner& _Part);\n\ntemplate <typename _Index_type, typename _Function>\nvoid parallel_for(\n    _Index_type first,\n    _Index_type last,\n    const _Function& _Func,\n    affinity_partitioner& _Part);\n```  \n  \n### Parameters  \n `_Index_type`  \n The type of the index being used for the iteration.  \n  \n `_Function`  \n The type of the function that will be executed at each iteration.  \n  \n `_Partitioner`  \n The type of the partitioner that is used to partition the supplied range.  \n  \n `first`  \n The first index to be included in the iteration.  \n  \n `last`  \n The index one past the last index to be included in the iteration.  \n  \n `_Step`  \n The value by which to step when iterating from `first` to `last`. The step must be positive. [invalid_argument](../../../standard-library/invalid-argument-class.md) is thrown if the step is less than 1.  \n  \n `_Func`  \n The function to be executed at each iteration. This may be a lambda expression, a function pointer, or any object that supports a version of the function call operator with the signature `void operator()(``_Index_type``)`.  \n  \n `_Part`  \n A reference to the partitioner object. The argument can be one of `const`[auto_partitioner](auto-partitioner-class.md)`&`, `const`[static_partitioner](static-partitioner-class.md)`&`, `const`[simple_partitioner](simple-partitioner-class.md)`&` or [affinity_partitioner](affinity-partitioner-class.md)`&` If an [affinity_partitioner](affinity-partitioner-class.md) object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use.  \n  \n### Remarks  \n For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md).  \n  \n##  <a name=\"parallel_for_each\"></a>  parallel_for_each  \n `parallel_for_each` applies a specified function to each element within a range, in parallel. It is semantically equivalent to the `for_each` function in the `std` namespace, except that iteration over the elements is performed in parallel, and the order of iteration is unspecified. The argument `_Func` must support a function call operator of the form `operator()(T)` where the parameter `T` is the item type of the container being iterated over.  \n  \n```\ntemplate <typename _Iterator, typename _Function>\nvoid parallel_for_each(\n    _Iterator first,\n    _Iterator last,\n    const _Function& _Func);\n\ntemplate <typename _Iterator, typename _Function, typename _Partitioner>\nvoid parallel_for_each(\n    _Iterator first,\n    _Iterator last,\n    const _Function& _Func,\n    _Partitioner&& _Part);\n```  \n  \n### Parameters  \n `_Iterator`  \n The type of the iterator being used to iterate over the container.  \n  \n `_Function`  \n The type of the function that will be applied to each element within the range.  \n  \n `_Partitioner`  \n `first`  \n An iterator addressing the position of the first element to be included in parallel iteration.  \n  \n `last`  \n An iterator addressing the position one past the final element to be included in parallel iteration.  \n  \n `_Func`  \n A user-defined function object that is applied to each element in the range.  \n  \n `_Part`  \n A reference to the partitioner object. The argument can be one of `const`[auto_partitioner](auto-partitioner-class.md)`&`, `const`[static_partitioner](static-partitioner-class.md)`&`, `const`[simple_partitioner](simple-partitioner-class.md)`&` or [affinity_partitioner](affinity-partitioner-class.md)`&` If an [affinity_partitioner](affinity-partitioner-class.md) object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use.  \n  \n### Remarks  \n [auto_partitioner](auto-partitioner-class.md) will be used for the overload without an explicit partitioner.  \n  \n For iterators that do not support random access, only [auto_partitioner](auto-partitioner-class.md) is supported.  \n  \n For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md).  \n  \n##  <a name=\"parallel_invoke\"></a>  parallel_invoke  \n Executes the function objects supplied as parameters in parallel, and blocks until they have finished executing. Each function object could be a lambda expression, a pointer to function, or any object that supports the function call operator with the signature `void operator()()`.  \n  \n```\ntemplate <typename _Function1, typename _Function2>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2);\n\ntemplate <typename _Function1, typename _Function2, typename _Function3>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3);\n\ntemplate <typename _Function1,\n    typename _Function2,\n    typename _Function3,\n    typename _Function4>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3,\n    const _Function4& _Func4);\n\ntemplate <typename _Function1,\n    typename _Function2,\n    typename _Function3,\n    typename _Function4,\n    typename _Function5>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3,\n    const _Function4& _Func4,\n    const _Function5& _Func5);\n\ntemplate <typename _Function1,\n    typename _Function2,\n    typename _Function3,\n    typename _Function4,\n    typename _Function5,\n    typename _Function6>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3,\n    const _Function4& _Func4,\n    const _Function5& _Func5,\n    const _Function6& _Func6);\n\ntemplate <typename _Function1,\n    typename _Function2,\n    typename _Function3,\n    typename _Function4,\n    typename _Function5,\n    typename _Function6,\n    typename _Function7>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3,\n    const _Function4& _Func4,\n    const _Function5& _Func5,\n    const _Function6& _Func6,\n    const _Function7& _Func7);\n\ntemplate <typename _Function1,\n    typename _Function2,\n    typename _Function3,\n    typename _Function4,\n    typename _Function5,\n    typename _Function6,\n    typename _Function7,\n    typename _Function8>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3,\n    const _Function4& _Func4,\n    const _Function5& _Func5,\n    const _Function6& _Func6,\n    const _Function7& _Func7,\n    const _Function8& _Func8);\n\ntemplate <typename _Function1,\n    typename _Function2,\n    typename _Function3,\n    typename _Function4,\n    typename _Function5,\n    typename _Function6,\n    typename _Function7,\n    typename _Function8,\n    typename _Function9>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3,\n    const _Function4& _Func4,\n    const _Function5& _Func5,\n    const _Function6& _Func6,\n    const _Function7& _Func7,\n    const _Function8& _Func8,\n    const _Function9& _Func9);\n\ntemplate <typename _Function1,\n    typename _Function2,\n    typename _Function3,\n    typename _Function4,\n    typename _Function5,\n    typename _Function6,\n    typename _Function7,\n    typename _Function8,\n    typename _Function9,\n    typename _Function10>\nvoid parallel_invoke(\n    const _Function1& _Func1,\n    const _Function2& _Func2,\n    const _Function3& _Func3,\n    const _Function4& _Func4,\n    const _Function5& _Func5,\n    const _Function6& _Func6,\n    const _Function7& _Func7,\n    const _Function8& _Func8,\n    const _Function9& _Func9,\n    const _Function10& _Func10);\n```  \n  \n### Parameters  \n `_Function1`  \n The type of the first function object to be executed in parallel.  \n  \n `_Function2`  \n The type of the second function object to be executed in parallel.  \n  \n `_Function3`  \n The type of the third function object to be executed in parallel.  \n  \n `_Function4`  \n The type of the fourth function object to be executed in parallel.  \n  \n `_Function5`  \n The type of the fifth function object to be executed in parallel.  \n  \n `_Function6`  \n The type of the sixth function object to be executed in parallel.  \n  \n `_Function7`  \n The type of the seventh function object to be executed in parallel.  \n  \n `_Function8`  \n The type of the eighth function object to be executed in parallel.  \n  \n `_Function9`  \n The type of the ninth function object to be executed in parallel.  \n  \n `_Function10`  \n The type of the tenth function object to be executed in parallel.  \n  \n `_Func1`  \n The first function object to be executed in parallel.  \n  \n `_Func2`  \n The second function object to be executed in parallel.  \n  \n `_Func3`  \n The third function object to be executed in parallel.  \n  \n `_Func4`  \n The fourth function object to be executed in parallel.  \n  \n `_Func5`  \n The fifth function object to be executed in parallel.  \n  \n `_Func6`  \n The sixth function object to be executed in parallel.  \n  \n `_Func7`  \n The seventh function object to be executed in parallel.  \n  \n `_Func8`  \n The eighth function object to be executed in parallel.  \n  \n `_Func9`  \n The ninth function object to be executed in parallel.  \n  \n `_Func10`  \n The tenth function object to be executed in parallel.  \n  \n### Remarks  \n Note that one or more of the function objects supplied as parameters may execute inline on the calling context.  \n  \n If one or more of the function objects passed as parameters to this function throws an exception, the runtime will select one such exception of its choosing and propagate it out of the call to `parallel_invoke`.  \n  \n For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md).  \n  \n##  <a name=\"parallel_radixsort\"></a>  parallel_radixsort  \n Arranges elements in a specified range into an non descending order using a radix sorting algorithm. This is a stable sort function which requires a projection function that can project elements to be sorted into unsigned integer-like keys. Default initialization is required for the elements being sorted.  \n  \n```\ntemplate<typename _Random_iterator>\ninline void parallel_radixsort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End);\n\ntemplate<typename _Allocator, typename _Random_iterator>\ninline void parallel_radixsort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End);\n\ntemplate<typename _Allocator, typename _Random_iterator>\ninline void parallel_radixsort(\n    const _Allocator& _Alloc,\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End);\n\ntemplate<typename _Random_iterator, typename _Function>\ninline void parallel_radixsort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End,\n    const _Function& _Proj_func,\n    const size_t _Chunk_size = 256* 256);\n\ntemplate<typename _Allocator, typename _Random_iterator,\n    typename _Function>\ninline void parallel_radixsort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End,\n    const _Function& _Proj_func,\n    const size_t _Chunk_size = 256* 256);\n\ntemplate<typename _Allocator,\n    typename _Random_iterator,\n    typename _Function>\ninline void parallel_radixsort(\n    const _Allocator& _Alloc,\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End,\n    const _Function& _Proj_func,\n    const size_t _Chunk_size = 256* 256);\n```  \n  \n### Parameters  \n `_Random_iterator`  \n The iterator type of the input range.  \n  \n `_Allocator`  \n The type of an STL compatible memory allocator.  \n  \n `_Function`  \n The type of the projection function.  \n  \n `_Begin`  \n A random-access iterator addressing the position of the first element in the range to be sorted.  \n  \n `_End`  \n A random-access iterator addressing the position one past the final element in the range to be sorted.  \n  \n `_Alloc`  \n An instance of an STL compatible memory allocator.  \n  \n `_Proj_func`  \n A user-defined projection function object that converts an element into an integral value.  \n  \n `_Chunk_size`  \n The mimimum size of a chunk that will be split into two for parallel execution.  \n  \n### Remarks  \n All overloads require `n * sizeof(T)` additional space, where `n` is the number of elements to be sorted, and `T` is the element type. An unary projection functor with the signature `I _Proj_func(T)` is required to return a key when given an element, where `T` is the element type and `I` is an unsigned integer-like type.  \n  \n If you do not supply a projection function, a default projection function which simply returns the element is used for integral types. The function will fail to compile if the element is not an integral type in the absence of a projection function.  \n  \n If you do not supply an allocator type or instance, the STL memory allocator `std::allocator<T>` is used to allocate the buffer.  \n  \n The algorithm divides the input range into two chunks and successively divides each chunk into two sub-chunks for execution in parallel. The optional argument `_Chunk_size` can be used to indicate to the algorithm that it should handles chunks of size < `_Chunk_size` serially.  \n  \n##  <a name=\"parallel_reduce\"></a>  parallel_reduce  \n Computes the sum of all elements in a specified range by computing successive partial sums, or computes the result of successive partial results similarly obtained from using a specified binary operation other than sum, in parallel. `parallel_reduce` is semantically similar to `std::accumulate`, except that it requires the binary operation to be associative, and requires an identity value instead of an initial value.  \n  \n```\ntemplate<typename _Forward_iterator>\ninline typename std::iterator_traits<_Forward_iterator>::value_type parallel_reduce(\n    _Forward_iterator _Begin,\n    _Forward_iterator _End,\n    const typename std::iterator_traits<_Forward_iterator>::value_type& _Identity);\n\ntemplate<typename _Forward_iterator, typename _Sym_reduce_fun>\ninline typename std::iterator_traits<_Forward_iterator>::value_type parallel_reduce(\n    _Forward_iterator _Begin,\n    _Forward_iterator _End,\n    const typename std::iterator_traits<_Forward_iterator>::value_type& _Identity,\n    _Sym_reduce_fun\n _Sym_fun);\n\ntemplate<typename _Reduce_type,\n    typename _Forward_iterator,\n    typename _Range_reduce_fun,\n    typename _Sym_reduce_fun>\ninline _Reduce_type parallel_reduce(\n    _Forward_iterator _Begin,\n    _Forward_iterator _End,\n    const _Reduce_type& _Identity,\n    const _Range_reduce_fun& _Range_fun,\n    const _Sym_reduce_fun& _Sym_fun);\n```  \n  \n### Parameters  \n `_Forward_iterator`  \n The iterator type of input range.  \n  \n `_Sym_reduce_fun`  \n The type of the symmetric reduction function. This must be a function type with signature `_Reduce_type _Sym_fun(_Reduce_type, _Reduce_type)`, where _Reduce_type is the same as the identity type and the result type of the reduction. For the third overload, this should be consistent with the output type of `_Range_reduce_fun`.  \n  \n `_Reduce_type`  \n The type that the input will reduce to, which can be different from the input element type. The return value and identity value will has this type.  \n  \n `_Range_reduce_fun`  \n The type of the range reduction function. This must be a function type with signature `_Reduce_type _Range_fun(_Forward_iterator, _Forward_iterator, _Reduce_type)`, _Reduce_type is the same as the identity type and the result type of the reduction.  \n  \n `_Begin`  \n An input iterator addressing the first element in the range to be reduced.  \n  \n `_End`  \n An input iterator addressing the element that is one position beyond the final element in the range to be reduced.  \n  \n `_Identity`  \n The identity value `_Identity` is of the same type as the result type of the reduction and also the `value_type` of the iterator for the first and second overloads. For the third overload, the identity value must have the same type as the result type of the reduction, but can be different from the `value_type` of the iterator. It must have an appropriate value such that the range reduction operator `_Range_fun`, when applied to a range of a single element of type `value_type` and the identity value, behaves like a type cast of the value from type `value_type` to the identity type.  \n  \n `_Sym_fun`  \n The symmetric function that will be used in the second of the reduction. Refer to Remarks for more information.  \n  \n `_Range_fun`  \n The function that will be used in the first phase of the reduction. Refer to Remarks for more information.  \n  \n### Return Value  \n The result of the reduction.  \n  \n### Remarks  \n To perform a parallel reduction, the function divides the range into chunks based on the number of workers available to the underlying scheduler. The reduction takes place in two phases, the first phase performs a reduction within each chunk, and the second phase performs a reduction between the partial results from each chunk.  \n  \n The first overload requires that the iterator's `value_type`, `T`, be the same as the identity value type as well as the reduction result type. The element type T must provide the operator `T T::operator + (T)` to reduce elements in each chunk. The same operator is used in the second phase as well.  \n  \n The second overload also requires that the iterator's `value_type` be the same as the identity value type as well as the reduction result type. The supplied binary operator `_Sym_fun` is used in both reduction phases, with the identity value as the initial value for the first phase.  \n  \n For the third overload, the identity value type must be the same as the reduction result type, but the iterator's `value_type` may be different from both. The range reduction function `_Range_fun` is used in the first phase with the identity value as the initial value, and the binary function `_Sym_reduce_fun` is applied to sub results in the second phase.  \n  \n##  <a name=\"parallel_sort\"></a>  parallel_sort  \n Arranges the elements in a specified range into a nondescending order, or according to an ordering criterion specified by a binary predicate, in parallel. This function is semantically similar to `std::sort` in that it is a compare-based, unstable, in-place sort.  \n  \n```\ntemplate<typename _Random_iterator>\ninline void parallel_sort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End);\n\ntemplate<typename _Random_iterator,typename _Function>\ninline void parallel_sort(\n    const _Random_iterator& _Begin,\n    const _Random_iterator& _End,\n    const _Function& _Func,\n    const size_t _Chunk_size = 2048);\n```  \n  \n### Parameters  \n `_Random_iterator`  \n The iterator type of the input range.  \n  \n `_Function`  \n The type of the binary comparison functor.  \n  \n `_Begin`  \n A random-access iterator addressing the position of the first element in the range to be sorted.  \n  \n `_End`  \n A random-access iterator addressing the position one past the final element in the range to be sorted.  \n  \n `_Func`  \n A user-defined predicate function object that defines the comparison criterion to be satisfied by successive elements in the ordering. A binary predicate takes two arguments and returns `true` when satisfied and `false` when not satisfied. This comparator function must impose a strict weak ordering on pairs of elements from the sequence.  \n  \n `_Chunk_size`  \n The mimimum size of a chunk that will be split into two for parallel execution.  \n  \n### Remarks  \n The first overload uses the the binary comparator `std::less`.  \n  \n The second overloaded uses the supplied binary comparator that should have the signature `bool _Func(T, T)` where `T` is the type of the elements in the input range.  \n  \n The algorithm divides the input range into two chunks and successively divides each chunk into two sub-chunks for execution in parallel. The optional argument `_Chunk_size` can be used to indicate to the algorithm that it should handles chunks of size < `_Chunk_size` serially.  \n  \n##  <a name=\"parallel_transform\"></a>  parallel_transform  \n Applies a specified function object to each element in a source range, or to a pair of elements from two source ranges, and copies the return values of the function object into a destination range, in parallel. This functional is semantically equivalent to `std::transform`.  \n  \n```\ntemplate <typename _Input_iterator1,\n    typename _Output_iterator,\n    typename _Unary_operator>\n_Output_iterator parallel_transform(\n    _Input_iterator1 first1,\n    _Input_iterator1 last1,\n    _Output_iterator _Result,\n    const _Unary_operator& _Unary_op,\n    const auto_partitioner& _Part = auto_partitioner());\n\ntemplate <typename _Input_iterator1,\n    typename _Output_iterator,\n    typename _Unary_operator>\n_Output_iterator parallel_transform(\n    _Input_iterator1 first1,\n    _Input_iterator1 last1,\n    _Output_iterator _Result,\n    const _Unary_operator& _Unary_op,\n    const static_partitioner& _Part);\n\ntemplate <typename _Input_iterator1,\n    typename _Output_iterator,\n    typename _Unary_operator>\n_Output_iterator parallel_transform(\n    _Input_iterator1 first1,\n    _Input_iterator1 last1,\n    _Output_iterator _Result,\n    const _Unary_operator& _Unary_op,\n    const simple_partitioner& _Part);\n\ntemplate <typename _Input_iterator1,\n    typename _Output_iterator,\n    typename _Unary_operator>\n_Output_iterator parallel_transform(\n    _Input_iterator1 first1,\n    _Input_iterator1 last1,\n    _Output_iterator _Result,\n    const _Unary_operator& _Unary_op,\n    affinity_partitioner& _Part);\n\ntemplate <typename _Input_iterator1,\n    typename _Input_iterator2,\n    typename _Output_iterator,\n    typename _Binary_operator,\n    typename _Partitioner>\n_Output_iterator parallel_transform(\n    _Input_iterator1 first1,\n    _Input_iterator1 last1,\n    _Input_iterator2\n first2,\n    _Output_iterator _Result,\n    const _Binary_operator& _Binary_op,\n    _Partitioner&& _Part);\n\ntemplate <typename _Input_iterator1,\n    typename _Input_iterator2,\n    typename _Output_iterator,\n    typename _Binary_operator>\n_Output_iterator parallel_transform(\n    _Input_iterator1 first1,\n    _Input_iterator1 last1,\n    _Input_iterator2\n first2,\n    _Output_iterator _Result,\n    const _Binary_operator& _Binary_op);\n```  \n  \n### Parameters  \n `_Input_iterator1`  \n The type of the first or only input iterator.  \n  \n `_Output_iterator`  \n The type of the output iterator.  \n  \n `_Unary_operator`  \n The type of the unary functor to be executed on each element in the input range.  \n  \n `_Input_iterator2`  \n The type of second input iterator.  \n  \n `_Binary_operator`  \n The type of the binary functor executed pairwise on elements from the two source ranges.  \n  \n `_Partitioner`  \n `first1`  \n An input iterator addressing the position of the first element in the first or only source range to be operated on.  \n  \n `last1`  \n An input iterator addressing the position one past the final element in the first or only source range to be operated on.  \n  \n `_Result`  \n An output iterator addressing the position of the first element in the destination range.  \n  \n `_Unary_op`  \n A user-defined unary function object that is applied to each element in the source range.  \n  \n `_Part`  \n A reference to the partitioner object. The argument can be one of `const`[auto_partitioner](auto-partitioner-class.md)`&`, `const`[static_partitioner](static-partitioner-class.md)`&`, `const`[simple_partitioner](simple-partitioner-class.md)`&` or [affinity_partitioner](affinity-partitioner-class.md)`&` If an [affinity_partitioner](affinity-partitioner-class.md) object is used, the reference must be a non-const l-value reference, so that the algorithm can store state for future loops to re-use.  \n  \n `first2`  \n An input iterator addressing the position of the first element in the second source range to be operated on.  \n  \n `_Binary_op`  \n A user-defined binary function object that is applied pairwise, in a forward order, to the two source ranges.  \n  \n### Return Value  \n An output iterator addressing the position one past the final element in the destination range that is receiving the output elements transformed by the function object.  \n  \n### Remarks  \n [auto_partitioner](auto-partitioner-class.md) will be used for the overloads without an explicit partitioner argument.  \n  \n For iterators that do not support random access, only [auto_partitioner](auto-partitioner-class.md) is supported.  \n  \n The overloads that take the argument `_Unary_op` transform the input range into the output range by applying the unary functor to each element in the input range. `_Unary_op` must support the function call operator with signature `operator()(T)` where `T` is the value type of the range being iterated over.  \n  \n The overloads that take the argument `_Binary_op` transform two input ranges into the output range by applying the binary functor to one element from the first input range and one element from the second input range. `_Binary_op` must support the function call operator with signature `operator()(T, U)` where `T`, `U` are value types of the two input iterators.  \n  \n For more information, see [Parallel Algorithms](../../../parallel/concrt/parallel-algorithms.md).  \n  \n##  <a name=\"receive\"></a>  receive  \n A general receive implementation, allowing a context to wait for data from exactly one source and filter the values that are accepted.  \n  \n```\ntemplate <class T>\nT receive(\n    _Inout_ ISource<T>* _Src,\n    unsigned int _Timeout = COOPERATIVE_TIMEOUT_INFINITE);\n\ntemplate <class T>\nT receive(\n    _Inout_ ISource<T>* _Src,\n    typename ITarget<T>::filter_method const& _Filter_proc,\n    unsigned int _Timeout = COOPERATIVE_TIMEOUT_INFINITE);\n\ntemplate <class T>\nT receive(\n    ISource<T>& _Src,\n    unsigned int _Timeout = COOPERATIVE_TIMEOUT_INFINITE);\n\ntemplate <class T>\nT receive(\n    ISource<T>& _Src,\n    typename ITarget<T>::filter_method const& _Filter_proc,\n    unsigned int _Timeout = COOPERATIVE_TIMEOUT_INFINITE);\n```  \n  \n### Parameters  \n `T`  \n The payload type.  \n  \n `_Src`  \n A pointer or reference to the source from which data is expected.  \n  \n `_Timeout`  \n The maximum time for which the method should for the data, in milliseconds.  \n  \n `_Filter_proc`  \n A filter function which determines whether messages should be accepted.  \n  \n### Return Value  \n A value from the source, of the payload type.  \n  \n### Remarks  \n If the parameter `_Timeout` has a value other than the constant `COOPERATIVE_TIMEOUT_INFINITE`, the exception [operation_timed_out](operation-timed-out-class.md) is thrown if the specified amount of time expires before a message is received. If you want a zero length timeout, you should use the [try_receive](concurrency-namespace-functions.md) function, as opposed to calling `receive` with a timeout of `0` (zero), as it is more efficient and does not throw exceptions on timeouts.  \n  \n For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md).  \n  \n##  <a name=\"run_with_cancellation_token\"></a>  run_with_cancellation_token  \n Executes a function object immediately and synchronously in the context of a given cancellation token.  \n  \n```\ntemplate<typename _Function>\nvoid run_with_cancellation_token(\n    const _Function& _Func,\n    cancellation_token _Ct);\n```  \n  \n### Parameters  \n `_Function`  \n The type of the function object that will be invoked.  \n  \n `_Func`  \n The function object which will be executed. This object must support the function call operator with a signature of void(void).  \n  \n `_Ct`  \n The cancellation token which will control implicit cancellation of the function object. Use `cancellation_token::none()` if you want the function execute without any possibility of implicit cancellation from a parent task group being canceled.  \n  \n### Remarks  \n Any interruption points in the function object will be triggered when the `cancellation_token` is canceled. The explicit token `_Ct` will isolate this `_Func` from parent cancellation if the parent has a different token or no token.  \n  \n##  <a name=\"send\"></a>  send  \n A synchronous send operation, which waits until the target either accepts or declines the message.  \n  \n```\ntemplate <class T>\nbool send(\n    _Inout_ ITarget<T>* _Trg,\n    const T& _Data);\n\ntemplate <class T>\nbool send(\n    ITarget<T>& _Trg,\n    const T& _Data);\n```  \n  \n### Parameters  \n `T`  \n The payload type.  \n  \n `_Trg`  \n A pointer or reference to the target to which data is sent.  \n  \n `_Data`  \n A reference to the data to be sent.  \n  \n### Return Value  \n `true` if the message was accepted, `false` otherwise.  \n  \n### Remarks  \n For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md).  \n  \n##  <a name=\"set_ambient_scheduler\"></a>  set_ambient_scheduler  \n  \n```\ninline void set_ambient_scheduler(std::shared_ptr<::Concurrency::scheduler_interface> _Scheduler);\n```  \n  \n### Parameters  \n `_Scheduler`  \n  \n##  <a name=\"set_task_execution_resources\"></a>  set_task_execution_resources  \n Restricts the execution resources used by the Concurrency Runtime internal worker threads to the affinity set specified.  \n  \n It is valid to call this method only before the Resource Manager has been created, or between two Resource Manager lifetimes. It can be invoked multiple times as long as the Resource Manager does not exist at the time of invocation. After an affinity limit has been set, it remains in effect until the next valid call to the `set_task_execution_resources` method.  \n  \n The affinity mask provided need not be a subset of the process affinity mask. The process affinity will be updated if necessary.  \n  \n```\nvoid __cdecl set_task_execution_resources(\n    DWORD_PTR _ProcessAffinityMask);\n\nvoid __cdecl set_task_execution_resources(\n    unsigned short count,\n    PGROUP_AFFINITY _PGroupAffinity);\n```  \n  \n### Parameters  \n `_ProcessAffinityMask`  \n The affinity mask that the Concurrency Runtime worker threads are to be restricted to. Use this method on a system with greater than 64 hardware threads only if you want to limit the Concurrency Runtime to a subset of the current processor group. In general, you should use the version of the method that accepts an array of group affinities as a parameter, to restrict affinity on machines with greater than 64 hardware threads.  \n  \n `count`  \n The number of `GROUP_AFFINITY` entries in the array specified by the parameter `_PGroupAffinity`.  \n  \n `_PGroupAffinity`  \n An array of `GROUP_AFFINITY` entries.  \n  \n### Remarks  \n The method will throw an [invalid_operation](invalid-operation-class.md) exception if a Resource Manager is present at the time it is invoked, and an [invalid_argument](../../../standard-library/invalid-argument-class.md) exception if the affinity specified results in an empty set of resources.  \n  \n The version of the method that takes an array of group affinities as a parameter should only be used on operating systems with version Windows 7 or higher. Otherwise, an [invalid_operation](invalid-operation-class.md) exception is thrown.  \n  \n Programatically modifying the process affinity after this method has been invoked will not cause the Resource Manager to re-evaluate the affinity it is restricted to. Therefore, all changes to process affinity should be made before calling this method.  \n  \n##  <a name=\"swap\"></a>  swap  \n Exchanges the elements of two `concurrent_vector` objects.  \n  \n```\ntemplate<typename T, class _Ax>\ninline void swap(\n    concurrent_vector<T, _Ax>& _A,\n    concurrent_vector<T, _Ax>& _B);\n```  \n  \n### Parameters  \n `T`  \n The data type of the elements stored in the concurrent vectors.  \n  \n `_Ax`  \n The allocator type of the concurrent vectors.  \n  \n `_A`  \n The concurrent vector whose elements are to be exchanged with those of the concurrent vector `_B`.  \n  \n `_B`  \n The concurrent vector providing the elements to be swapped, or the vector whose elements are to be exchanged with those of the concurrent vector `_A`.  \n  \n### Remarks  \n The template function is an algorithm specialized on the container class `concurrent_vector` to execute the member function `_A`. [concurrent_vector::swap](concurrent-vector-class.md#swap)( `_B`). These are instances of the partial ordering of function templates by the compiler. When template functions are overloaded in such a way that the match of the template with the function call is not unique, then the compiler will select the most specialized version of the template function. The general version of the template function, `template <class T> void swap(T&, T&)`, in the algorithm class works by assignment and is a slow operation. The specialized version in each container is much faster as it can work with the internal representation of the container class.  \n  \n This method is not concurrency-safe. You must ensure that no other threads are performing operations on either of the concurrent vectors when you call this method.  \n  \n##  <a name=\"task_from_exception\"></a>  task_from_exception  \n  \n```\ntemplate<typename _TaskType, typename _ExType>\ntask<_TaskType> task_from_exception(\n    _ExType _Exception,\n    const task_options& _TaskOptions = task_options());\n```  \n  \n### Parameters  \n `_TaskType`  \n `_ExType`  \n `_Exception`  \n `_TaskOptions`  \n  \n### Return Value  \n  \n##  <a name=\"task_from_result\"></a>  task_from_result  \n  \n```\ntemplate<typename T>\ntask<T> task_from_result(\n    T _Param,\n    const task_options& _TaskOptions = task_options());\n\ninline task<bool> task_from_result(ool _Param);\n\ninline task<void> task_from_result(\n    const task_options& _TaskOptions = task_options());\n```  \n  \n### Parameters  \n `T`  \n `_Param`  \n `_TaskOptions`  \n  \n### Return Value  \n  \n##  <a name=\"trace_agents_register_name\"></a>  Trace_agents_register_name  \n Associates the given name to the message block or agent in the ETW trace.  \n  \n```\ntemplate <class T>\nvoid Trace_agents_register_name(\n    _Inout_ T* _PObject,\n    _In_z_ const wchar_t* _Name);\n```  \n  \n### Parameters  \n `T`  \n The type of the object. This is typically a message block or an agent.  \n  \n `_PObject`  \n A pointer to the message block or agent that is being named in the trace.  \n  \n `_Name`  \n The name for the given object.  \n  \n##  <a name=\"try_receive\"></a>  try_receive  \n A general try-receive implementation, allowing a context to look for data from exactly one source and filter the values that are accepted. If the data is not ready, the method will return false.  \n  \n``` \ntemplate <class T>\nbool try_receive(\n    _Inout_ ISource<T>* _Src,\n    T& _value);\n\ntemplate <class T>\nbool try_receive(\n    _Inout_ ISource<T>* _Src,\n    T& _value,\n    typename ITarget<T>::filter_method const& _Filter_proc);\n\ntemplate <class T>\nbool try_receive(\n    ISource<T>& _Src,\n    T& _value);\n\ntemplate <class T>\nbool try_receive(\n    ISource<T>& _Src,\n    T& _value,\n    typename ITarget<T>::filter_method const& _Filter_proc);\n```  \n  \n### Parameters  \n `T`  \n The payload type  \n  \n `_Src`  \n A pointer or reference to the source from which data is expected.  \n  \n `_value`  \n A reference to a location where the result will be placed.  \n  \n `_Filter_proc`  \n A filter function which determines whether messages should be accepted.  \n  \n### Return Value  \n A `bool` value indicating whether or not a payload was placed in `_value`.  \n  \n### Remarks  \n For more information, see [Message Passing Functions](../../../parallel/concrt/message-passing-functions.md).  \n  \n##  <a name=\"wait\"></a>  wait  \n Pauses the current context for a specified amount of time.  \n  \n```\nvoid __cdecl wait(unsigned int _Milliseconds);\n```  \n  \n### Parameters  \n `_Milliseconds`  \n The number of milliseconds the current context should be paused for. If the `_Milliseconds` parameter is set to the value `0`, the current context should yield execution to other runnable contexts before continuing.  \n  \n### Remarks  \n If this method is called on a Concurrency Runtime scheduler context, the scheduler will find a different context to run on the underlying resource. Because the scheduler is cooperative in nature, this context cannot resume exactly after the number of milliseconds specified. If the scheduler is busy executing other tasks that do not cooperatively yield to the scheduler, the wait period could be indefinite.  \n  \n##  <a name=\"when_all\"></a>  when_all  \n Creates a task that will complete successfully when all of the tasks supplied as arguments complete successfully.  \n  \n```\ntemplate <typename _Iterator>\nauto when_all(\n    _Iterator _Begin,\n    _Iterator _End,\n    const task_options& _TaskOptions = task_options()) -> \n    decltype (details::_WhenAllImpl<typename std::iterator_traits<_Iterator>::value_type::result_type,\n    _Iterator>::_Perform(_TaskOptions,\n _Begin,\n    _End));\n```   \n  \n### Parameters  \n `_Iterator`  \n The type of the input iterator.  \n  \n `_Begin`  \n The position of the first element in the range of elements to be combined into the resulting task.  \n  \n `_End`  \n The position of the first element beyond the range of elements to be combined into the resulting task.  \n  \n `_TaskOptions`  \n  \n### Return Value  \n A task that completes sucessfully when all of the input tasks have completed successfully. If the input tasks are of type `T`, the output of this function will be a `task<std::vector<T>>`. If the input tasks are of type `void` the output task will also be a `task<void>`.  \n  \n### Remarks  \n `when_all` is a non-blocking function that produces a `task` as its result. Unlike [task::wait](task-class.md#wait), it is safe to call this function in a [!INCLUDE[win8_appname_long](../../../build/includes/win8_appname_long_md.md)] app on the ASTA (Application STA) thread.  \n  \n If one of the tasks is canceled or throws an exception, the returned task will complete early, in the canceled state, and the exception, if one is encoutered, will be thrown if you call [task::get](task-class.md#get) or `task::wait` on that task.  \n  \n For more information, see [Task Parallelism](../../../parallel/concrt/task-parallelism-concurrency-runtime.md).  \n  \n##  <a name=\"when_any\"></a>  when_any  \n Creates a task that will complete successfully when any of the tasks supplied as arguments completes successfully.  \n  \n```\ntemplate<typename _Iterator>\nauto when_any(\n    _Iterator _Begin,\n    _Iterator _End,\n    const task_options& _TaskOptions = task_options()) -> decltype (details::_WhenAnyImpl<typename std::iterator_traits<_Iterator>::value_type::result_type,\n    _Iterator>::_Perform(_TaskOptions,\n _Begin,\n    _End));\n\ntemplate<typename _Iterator>\nauto when_any(\n    _Iterator _Begin,\n    _Iterator _End,\n    cancellation_token _CancellationToken) -> decltype (details::_WhenAnyImpl<typename std::iterator_traits<_Iterator>::value_type::result_type,\n    _Iterator>::_Perform(_CancellationToken._GetImplValue(),\n _Begin,\n    _End));\n```   \n  \n### Parameters  \n `_Iterator`  \n The type of the input iterator.  \n  \n `_Begin`  \n The position of the first element in the range of elements to be combined into the resulting task.  \n  \n `_End`  \n The position of the first element beyond the range of elements to be combined into the resulting task.  \n  \n `_TaskOptions`  \n `_CancellationToken`  \n The cancellation token which controls cancellation of the returned task. If you do not provide a cancellation token, the resulting task will receive the cancellation token of the task that causes it to complete.  \n  \n### Return Value  \n A task that completes successfully when any one of the input tasks has completed successfully. If the input tasks are of type `T`, the output of this function will be a `task<std::pair<T, size_t>>>`, where the first element of the pair is the result of the completing task, and the second element is the index of the task that finished. If the input tasks are of type `void` the output is a `task<size_t>`, where the result is the index of the completing task.  \n  \n### Remarks  \n `when_any` is a non-blocking function that produces a `task` as its result. Unlike [task::wait](task-class.md#wait), it is safe to call this function in a [!INCLUDE[win8_appname_long](../../../build/includes/win8_appname_long_md.md)] app on the ASTA (Application STA) thread.  \n  \n For more information, see [Task Parallelism](../../../parallel/concrt/task-parallelism-concurrency-runtime.md).  \n  \n## See Also  \n [concurrency Namespace](concurrency-namespace.md)\n"}