{"nodes":[{"pos":[12,45],"content":"C++ AMP Overview | Microsoft Docs","needQuote":false,"needEscape":true,"nodes":[{"content":"C++ AMP Overview | Microsoft Docs","pos":[0,33]}]},{"content":"C++ AMP Overview","pos":[768,784]},{"content":"C++ Accelerated Massive Parallelism (C++ AMP) accelerates execution of C++ code by taking advantage of data-parallel hardware such as a graphics processing unit (GPU) on a discrete graphics card.","pos":[785,980]},{"content":"By using C++ AMP, you can code multi-dimensional data algorithms so that execution can be accelerated by using parallelism on heterogeneous hardware.","pos":[981,1130]},{"content":"The C++ AMP programming model includes multidimensional arrays, indexing, memory transfer, tiling, and a mathematical function library.","pos":[1131,1266]},{"content":"You can use C++ AMP language extensions to control how data is moved from the CPU to the GPU and back, so that you can improve performance.","pos":[1267,1406]},{"content":"System Requirements","pos":[1415,1434]},{"pos":[1491,1628],"content":", <ph id=\"ph1\">[!INCLUDE[win8](../../build/reference/includes/win8_md.md)]</ph>, <ph id=\"ph2\">[!INCLUDE[winsvr08_r2](../../parallel/amp/includes/winsvr08_r2_md.md)]</ph>, or","source":", [!INCLUDE[win8](../../build/reference/includes/win8_md.md)], [!INCLUDE[winsvr08_r2](../../parallel/amp/includes/winsvr08_r2_md.md)], or "},{"content":"DirectX 11 Feature Level 11.0 or later hardware","pos":[1710,1757]},{"content":"For debugging on the software emulator, <ph id=\"ph1\">[!INCLUDE[win8](../../build/reference/includes/win8_md.md)]</ph> or <ph id=\"ph2\">[!INCLUDE[winserver8](../../build/reference/includes/winserver8_md.md)]</ph> is required.","pos":[1767,1954],"source":"For debugging on the software emulator, [!INCLUDE[win8](../../build/reference/includes/win8_md.md)] or [!INCLUDE[winserver8](../../build/reference/includes/winserver8_md.md)] is required."},{"content":"For debugging on the hardware, you must install the drivers for your graphics card.","pos":[1955,2038]},{"content":"For more information, see <bpt id=\"p1\">[</bpt>Debugging GPU Code<ept id=\"p1\">](/visualstudio/debugger/debugging-gpu-code)</ept>.","pos":[2039,2129],"source":" For more information, see [Debugging GPU Code](/visualstudio/debugger/debugging-gpu-code)."},{"content":"Introduction","pos":[2138,2150]},{"content":"The following two examples illustrate the primary components of C++ AMP.","pos":[2154,2226]},{"content":"Assume that you want to add the corresponding elements of two one-dimensional arrays.","pos":[2227,2312]},{"content":"For example, you might want to add <ph id=\"ph1\">`{1, 2, 3, 4, 5}`</ph> and <ph id=\"ph2\">`{6, 7, 8, 9, 10}`</ph> to obtain <ph id=\"ph3\">`{7, 9, 11, 13, 15}`</ph>.","pos":[2313,2420],"source":" For example, you might want to add `{1, 2, 3, 4, 5}` and `{6, 7, 8, 9, 10}` to obtain `{7, 9, 11, 13, 15}`."},{"content":"Without using C++ AMP, you might write the following code to add the numbers and display the results.","pos":[2421,2522]},{"content":"The important parts of the code are as follows:","pos":[2914,2961]},{"content":"Data: The data consists of three arrays.","pos":[2971,3011]},{"content":"All have the same rank (one) and length (five).","pos":[3012,3059]},{"content":"Iteration: The first <ph id=\"ph1\">`for`</ph> loop provides a mechanism for iterating through the elements in the arrays.","pos":[3069,3171],"source":"Iteration: The first `for` loop provides a mechanism for iterating through the elements in the arrays."},{"content":"The code that you want to execute to compute the sums is contained in the first <ph id=\"ph1\">`for`</ph> block.","pos":[3172,3264],"source":" The code that you want to execute to compute the sums is contained in the first `for` block."},{"pos":[3274,3347],"content":"Index: The <ph id=\"ph1\">`idx`</ph> variable accesses the individual elements of the arrays.","source":"Index: The `idx` variable accesses the individual elements of the arrays."},{"content":"Using C++ AMP, you might write the following code instead.","pos":[3354,3412]},{"content":"The same basic elements are present, but C++ AMP constructs are used:","pos":[4333,4402]},{"content":"Data: You use C++ arrays to construct three C++ AMP <bpt id=\"p1\">[</bpt>array_view<ept id=\"p1\">](../../parallel/amp/reference/array-view-class.md)</ept> objects.","pos":[4412,4535],"source":"Data: You use C++ arrays to construct three C++ AMP [array_view](../../parallel/amp/reference/array-view-class.md) objects."},{"content":"You supply four values to construct an <ph id=\"ph1\">`array_view`</ph> object: the data values, the rank, the element type, and the length of the <ph id=\"ph2\">`array_view`</ph> object in each dimension.","pos":[4536,4701],"source":" You supply four values to construct an `array_view` object: the data values, the rank, the element type, and the length of the `array_view` object in each dimension."},{"content":"The rank and type are passed as type parameters.","pos":[4702,4750]},{"content":"The data and length are passed as constructor parameters.","pos":[4751,4808]},{"content":"In this example, the C++ array that is passed to the constructor is one-dimensional.","pos":[4809,4893]},{"content":"The rank and length are used to construct the rectangular shape of the data in the <ph id=\"ph1\">`array_view`</ph> object, and the data values are used to fill the array.","pos":[4894,5045],"source":" The rank and length are used to construct the rectangular shape of the data in the `array_view` object, and the data values are used to fill the array."},{"content":"The runtime library also includes the <bpt id=\"p1\">[</bpt>array Class<ept id=\"p1\">](../../parallel/amp/reference/array-class.md)</ept>, which has an interface that resembles the <ph id=\"ph1\">`array_view`</ph> class and is discussed later in this article.","pos":[5046,5244],"source":" The runtime library also includes the [array Class](../../parallel/amp/reference/array-class.md), which has an interface that resembles the `array_view` class and is discussed later in this article."},{"content":"Iteration: The <bpt id=\"p1\">[</bpt>parallel_for_each Function (C++ AMP)<ept id=\"p1\">](reference/concurrency-namespace-functions-amp.md#parallel_for_each)</ept> provides a mechanism for iterating through the data elements, or <bpt id=\"p2\">*</bpt>compute domain<ept id=\"p2\">*</ept>.","pos":[5254,5458],"source":"Iteration: The [parallel_for_each Function (C++ AMP)](reference/concurrency-namespace-functions-amp.md#parallel_for_each) provides a mechanism for iterating through the data elements, or *compute domain*."},{"content":"In this example, the compute domain is specified by <ph id=\"ph1\">`sum.extent`</ph>.","pos":[5459,5524],"source":" In this example, the compute domain is specified by `sum.extent`."},{"content":"The code that you want to execute is contained in a lambda expression, or <bpt id=\"p1\">*</bpt>kernel function<ept id=\"p1\">*</ept>.","pos":[5525,5617],"source":" The code that you want to execute is contained in a lambda expression, or *kernel function*."},{"content":"The <ph id=\"ph1\">`restrict(amp)`</ph> indicates that only the subset of the C++ language that C++ AMP can accelerate is used.","pos":[5618,5725],"source":" The `restrict(amp)` indicates that only the subset of the C++ language that C++ AMP can accelerate is used."},{"content":"Index: The <bpt id=\"p1\">[</bpt>index Class<ept id=\"p1\">](../../parallel/amp/reference/index-class.md)</ept> variable, <ph id=\"ph1\">`idx`</ph>, is declared with a rank of one to match the rank of the <ph id=\"ph2\">`array_view`</ph> object.","pos":[5735,5898],"source":"Index: The [index Class](../../parallel/amp/reference/index-class.md) variable, `idx`, is declared with a rank of one to match the rank of the `array_view` object."},{"content":"By using the index, you can access the individual elements of the <ph id=\"ph1\">`array_view`</ph> objects.","pos":[5899,5986],"source":" By using the index, you can access the individual elements of the `array_view` objects."},{"content":"Shaping and Indexing Data: index and extent","pos":[5995,6038]},{"content":"You must define the data values and declare the shape of the data before you can run the kernel code.","pos":[6042,6143]},{"content":"All data is defined to be an array (rectangular), and you can define the array to have any rank (number of dimensions).","pos":[6144,6263]},{"content":"The data can be any size in any of the dimensions.","pos":[6264,6314]},{"content":"index Class","pos":[6324,6335]},{"content":"The <bpt id=\"p1\">[</bpt>index Class<ept id=\"p1\">](../../parallel/amp/reference/index-class.md)</ept> specifies a location in the <ph id=\"ph1\">`array`</ph> or <ph id=\"ph2\">`array_view`</ph> object by encapsulating the offset from the origin in each dimension into one object.","pos":[6339,6539],"source":"The [index Class](../../parallel/amp/reference/index-class.md) specifies a location in the `array` or `array_view` object by encapsulating the offset from the origin in each dimension into one object."},{"content":"When you access a location in the array, you pass an <ph id=\"ph1\">`index`</ph> object to the indexing operator, <ph id=\"ph2\">`[]`</ph>, instead of a list of integer indexes.","pos":[6540,6677],"source":" When you access a location in the array, you pass an `index` object to the indexing operator, `[]`, instead of a list of integer indexes."},{"content":"You can access the elements in each dimension by using the <bpt id=\"p1\">[</bpt>array::operator() Operator<ept id=\"p1\">](reference/array-class.md#array__operator_call)</ept> or the <bpt id=\"p2\">[</bpt>array_view::operator() Operator<ept id=\"p2\">](reference/array-view-class.md#array_view__operator_call)</ept>.","pos":[6678,6911],"source":" You can access the elements in each dimension by using the [array::operator() Operator](reference/array-class.md#array__operator_call) or the [array_view::operator() Operator](reference/array-view-class.md#array_view__operator_call)."},{"content":"The following example creates a one-dimensional index that specifies the third element in a one-dimensional <ph id=\"ph1\">`array_view`</ph> object.","pos":[6918,7046],"source":"The following example creates a one-dimensional index that specifies the third element in a one-dimensional `array_view` object."},{"content":"The index is used to print the third element in the <ph id=\"ph1\">`array_view`</ph> object.","pos":[7047,7119],"source":" The index is used to print the third element in the `array_view` object."},{"content":"The output is 3.","pos":[7120,7136]},{"content":"The following example creates a two-dimensional index that specifies the element where the row = 1 and the column = 2 in a two-dimensional <ph id=\"ph1\">`array_view`</ph> object.","pos":[7293,7452],"source":"The following example creates a two-dimensional index that specifies the element where the row = 1 and the column = 2 in a two-dimensional `array_view` object."},{"content":"The first parameter in the <ph id=\"ph1\">`index`</ph> constructor is the row component, and the second parameter is the column component.","pos":[7453,7571],"source":" The first parameter in the `index` constructor is the row component, and the second parameter is the column component."},{"content":"The output is 6.","pos":[7572,7588]},{"content":"The following example creates a three-dimensional index that specifies the element  where the depth = 0, the row = 1, and the column = 3 in a three-dimensional <ph id=\"ph1\">`array_view`</ph> object.","pos":[7758,7938],"source":"The following example creates a three-dimensional index that specifies the element  where the depth = 0, the row = 1, and the column = 3 in a three-dimensional `array_view` object."},{"content":"Notice that the first parameter is the depth component, the second parameter is the row component, and the third parameter is the column component.","pos":[7939,8086]},{"content":"The output is 8.","pos":[8087,8103]},{"content":"extent Class","pos":[8393,8405]},{"content":"The <bpt id=\"p1\">[</bpt>extent Class<ept id=\"p1\">](../../parallel/amp/reference/extent-class.md)</ept> specifies the length of the data in each dimension of the <ph id=\"ph1\">`array`</ph> or <ph id=\"ph2\">`array_view`</ph> object.","pos":[8409,8563],"source":"The [extent Class](../../parallel/amp/reference/extent-class.md) specifies the length of the data in each dimension of the `array` or `array_view` object."},{"content":"You can create an extent and use it to create an <ph id=\"ph1\">`array`</ph> or <ph id=\"ph2\">`array_view`</ph> object.","pos":[8564,8644],"source":" You can create an extent and use it to create an `array` or `array_view` object."},{"content":"You can also retrieve the extent of an existing <ph id=\"ph1\">`array`</ph> or <ph id=\"ph2\">`array_view`</ph> object.","pos":[8645,8724],"source":" You can also retrieve the extent of an existing `array` or `array_view` object."},{"content":"The following example prints the length of the extent in each dimension of an <ph id=\"ph1\">`array_view`</ph> object.","pos":[8725,8823],"source":" The following example prints the length of the extent in each dimension of an `array_view` object."},{"pos":[9313,9544],"content":"The following example creates an <ph id=\"ph1\">`array_view`</ph> object that has the same dimensions as the object in the previous example, but this example uses an <ph id=\"ph2\">`extent`</ph> object instead of using explicit parameters in the <ph id=\"ph3\">`array_view`</ph> constructor.","source":"The following example creates an `array_view` object that has the same dimensions as the object in the previous example, but this example uses an `extent` object instead of using explicit parameters in the `array_view` constructor."},{"content":"Moving Data to the Accelerator: array and array_view","pos":[9911,9963]},{"content":"Two data containers used to move data to the accelerator are defined in the runtime library.","pos":[9967,10059]},{"content":"They are the <bpt id=\"p1\">[</bpt>array Class<ept id=\"p1\">](../../parallel/amp/reference/array-class.md)</ept> and the <bpt id=\"p2\">[</bpt>array_view Class<ept id=\"p2\">](../../parallel/amp/reference/array-view-class.md)</ept>.","pos":[10060,10209],"source":" They are the [array Class](../../parallel/amp/reference/array-class.md) and the [array_view Class](../../parallel/amp/reference/array-view-class.md)."},{"content":"The <ph id=\"ph1\">`array`</ph> class is a container class that creates a deep copy of the data when the object is constructed.","pos":[10210,10317],"source":" The `array` class is a container class that creates a deep copy of the data when the object is constructed."},{"content":"The <ph id=\"ph1\">`array_view`</ph> class is a wrapper class that copies the data when the kernel function accesses the data.","pos":[10318,10424],"source":" The `array_view` class is a wrapper class that copies the data when the kernel function accesses the data."},{"content":"When the data is needed on the source device the data is copied back.","pos":[10425,10494]},{"content":"array Class","pos":[10504,10515]},{"content":"When an <ph id=\"ph1\">`array`</ph> object is constructed, a deep copy of the data is created on the accelerator if you use a constructor that includes a pointer to the data set.","pos":[10519,10677],"source":"When an `array` object is constructed, a deep copy of the data is created on the accelerator if you use a constructor that includes a pointer to the data set."},{"content":"The kernel function modifies the copy on the accelerator.","pos":[10678,10735]},{"content":"When the execution of the kernel function is finished, you must copy the data back to the source data structure.","pos":[10736,10848]},{"content":"The following example multiplies each element in a vector by 10.","pos":[10849,10913]},{"content":"After the kernel function is finished, the <ph id=\"ph1\">`vector conversion operator`</ph> is used to copy the data back into the vector object.","pos":[10914,11039],"source":" After the kernel function is finished, the `vector conversion operator` is used to copy the data back into the vector object."},{"content":"array_view Class","pos":[11423,11439]},{"content":"The <ph id=\"ph1\">`array_view`</ph> has nearly the same members as the <ph id=\"ph2\">`array`</ph> class, but the underlying behavior is not the same.","pos":[11443,11554],"source":"The `array_view` has nearly the same members as the `array` class, but the underlying behavior is not the same."},{"content":"Data passed to the <ph id=\"ph1\">`array_view`</ph> constructor is not replicated on the GPU as it is with an <ph id=\"ph2\">`array`</ph> constructor.","pos":[11555,11665],"source":" Data passed to the `array_view` constructor is not replicated on the GPU as it is with an `array` constructor."},{"content":"Instead, the data is copied to the accelerator when the kernel function is executed.","pos":[11666,11750]},{"content":"Therefore, if you create two <ph id=\"ph1\">`array_view`</ph> objects that use the same data, both <ph id=\"ph2\">`array_view`</ph> objects refer to the same memory space.","pos":[11751,11882],"source":" Therefore, if you create two `array_view` objects that use the same data, both `array_view` objects refer to the same memory space."},{"content":"When you do this, you have to synchronize any multithreaded access.","pos":[11883,11950]},{"content":"The main advantage of using the <ph id=\"ph1\">`array_view`</ph> class is that data is moved only if it is necessary.","pos":[11951,12048],"source":" The main advantage of using the `array_view` class is that data is moved only if it is necessary."},{"content":"Comparison of array and array_view","pos":[12058,12092]},{"pos":[12096,12205],"content":"The following table summarizes the similarities and differences between the <ph id=\"ph1\">`array`</ph> and <ph id=\"ph2\">`array_view`</ph> classes.","source":"The following table summarizes the similarities and differences between the `array` and `array_view` classes."},{"content":"Description","pos":[12212,12223]},{"content":"array class","pos":[12224,12235]},{"content":"array_view class","pos":[12236,12252]},{"content":"When rank is determined","pos":[12321,12344]},{"content":"At compile time.","pos":[12345,12361]},{"content":"At compile time.","pos":[12362,12378]},{"content":"When extent is determined","pos":[12383,12408]},{"content":"At run time.","pos":[12409,12421]},{"content":"At run time.","pos":[12422,12434]},{"content":"Shape","pos":[12439,12444]},{"content":"Rectangular.","pos":[12445,12457]},{"content":"Rectangular.","pos":[12458,12470]},{"content":"Data storage","pos":[12475,12487]},{"content":"Is a data container.","pos":[12488,12508]},{"content":"Is a data wrapper.","pos":[12509,12527]},{"content":"Copy","pos":[12532,12536]},{"content":"Explicit and deep copy at definition.","pos":[12537,12574]},{"content":"Implicit copy when it is accessed by the kernel function.","pos":[12575,12632]},{"content":"Data retrieval","pos":[12637,12651]},{"content":"By copying the array data back to an object on the CPU thread.","pos":[12652,12714]},{"pos":[12715,12910],"content":"By direct access of the <ph id=\"ph1\">`array_view`</ph> object or by calling the <bpt id=\"p1\">[</bpt>array_view::synchronize Method<ept id=\"p1\">](reference/array-view-class.md#synchronize)</ept> to continue accessing the data on the original container.","source":"By direct access of the `array_view` object or by calling the [array_view::synchronize Method](reference/array-view-class.md#synchronize) to continue accessing the data on the original container."},{"content":"Shared memory with array and array_view","pos":[12923,12962]},{"content":"Shared memory is memory that can be accessed by both the CPU and the accelerator.","pos":[12966,13047]},{"content":"The use of shared memory eliminates or significantly reduces the overhead of copying data between the CPU and the accelerator.","pos":[13048,13174]},{"content":"Although the memory is shared, it cannot be accessed concurrently by both the CPU and the accelerator, and doing so causes undefined behavior.","pos":[13175,13317]},{"content":"objects can be used to specify fine-grained control over the use of shared memory if the associated accelerator supports it.","pos":[13332,13456]},{"content":"Whether an accelerator supports shared memory is determined by the accelerator’s <bpt id=\"p1\">[</bpt>supports_cpu_shared_memory<ept id=\"p1\">](reference/accelerator-class.md#supports_cpu_shared_memory)</ept> property, which returns <ph id=\"ph1\">`true`</ph> when shared memory is supported.","pos":[13457,13689],"source":" Whether an accelerator supports shared memory is determined by the accelerator’s [supports_cpu_shared_memory](reference/accelerator-class.md#supports_cpu_shared_memory) property, which returns `true` when shared memory is supported."},{"content":"If shared memory is supported, the default <bpt id=\"p1\">[</bpt>access_type Enumeration<ept id=\"p1\">](reference/concurrency-namespace-enums-amp.md#access_type)</ept> for memory allocations on the accelerator is determined by the <ph id=\"ph1\">`default_cpu_access_type`</ph> property.","pos":[13690,13915],"source":" If shared memory is supported, the default [access_type Enumeration](reference/concurrency-namespace-enums-amp.md#access_type) for memory allocations on the accelerator is determined by the `default_cpu_access_type` property."},{"content":"By default, <ph id=\"ph1\">`array`</ph> and <ph id=\"ph2\">`array_view`</ph> objects take on the same <ph id=\"ph3\">`access_type`</ph> as the primary associated <ph id=\"ph4\">`accelerator`</ph>.","pos":[13916,14032],"source":" By default, `array` and `array_view` objects take on the same `access_type` as the primary associated `accelerator`."},{"content":"By setting the <bpt id=\"p1\">[</bpt>array::cpu_access_type Data Member<ept id=\"p1\">](reference/array-class.md#cpu_access_type)</ept> property of an <ph id=\"ph1\">`array`</ph> explicitly, you can exercise fine-grained control over how shared memory is used, so that you can optimize the app for the hardware’s performance characteristics, based on the memory access patterns of its computation kernels.","pos":[14039,14382],"source":"By setting the [array::cpu_access_type Data Member](reference/array-class.md#cpu_access_type) property of an `array` explicitly, you can exercise fine-grained control over how shared memory is used, so that you can optimize the app for the hardware’s performance characteristics, based on the memory access patterns of its computation kernels."},{"content":"An <ph id=\"ph1\">`array_view`</ph> reflects the same <ph id=\"ph2\">`cpu_access_type`</ph> as the <ph id=\"ph3\">`array`</ph> that it’s associated with; or, if the array_view is constructed without a data source, its <ph id=\"ph4\">`access_type`</ph> reflects the environment that first causes it to allocate storage.","pos":[14383,14621],"source":" An `array_view` reflects the same `cpu_access_type` as the `array` that it’s associated with; or, if the array_view is constructed without a data source, its `access_type` reflects the environment that first causes it to allocate storage."},{"content":"That is, if it’s first accessed by the host (CPU), then it behaves as if it were created over a CPU data source and shares the <ph id=\"ph1\">`access_type`</ph> of the <ph id=\"ph2\">`accelerator_view`</ph> associated by capture; however, if it's first accessed by an <ph id=\"ph3\">`accelerator_view`</ph>, then it behaves as if it were created over an <ph id=\"ph4\">`array`</ph> created on that <ph id=\"ph5\">`accelerator_view`</ph> and shares the <ph id=\"ph6\">`array`</ph>’s <ph id=\"ph7\">`access_type`</ph>.","pos":[14622,14998],"source":" That is, if it’s first accessed by the host (CPU), then it behaves as if it were created over a CPU data source and shares the `access_type` of the `accelerator_view` associated by capture; however, if it's first accessed by an `accelerator_view`, then it behaves as if it were created over an `array` created on that `accelerator_view` and shares the `array`’s `access_type`."},{"content":"The following code example shows how to determine whether the default accelerator supports shared memory, and then creates several arrays that have different cpu_access_type configurations.","pos":[15005,15194]},{"content":"Executing Code over Data: parallel_for_each","pos":[16356,16399]},{"content":"The <bpt id=\"p1\">[</bpt>parallel_for_each<ept id=\"p1\">](reference/concurrency-namespace-functions-amp.md#parallel_for_each)</ept> function defines the code that you want to run on the accelerator against the data in the <ph id=\"ph1\">`array`</ph> or <ph id=\"ph2\">`array_view`</ph> object.","pos":[16403,16616],"source":"The [parallel_for_each](reference/concurrency-namespace-functions-amp.md#parallel_for_each) function defines the code that you want to run on the accelerator against the data in the `array` or `array_view` object."},{"content":"Consider the following code from the introduction of this topic.","pos":[16617,16681]},{"pos":[17289,17382],"content":"The <ph id=\"ph1\">`parallel_for_each`</ph> method takes two arguments, a compute domain and a lambda expression.","source":"The `parallel_for_each` method takes two arguments, a compute domain and a lambda expression."},{"content":"The <bpt id=\"p1\">*</bpt>compute domain<ept id=\"p1\">*</ept> is an <ph id=\"ph1\">`extent`</ph> object or a <ph id=\"ph2\">`tiled_extent`</ph> object that defines the set of threads to create for parallel execution.","pos":[17389,17524],"source":"The *compute domain* is an `extent` object or a `tiled_extent` object that defines the set of threads to create for parallel execution."},{"content":"One thread is generated for each element in the compute domain.","pos":[17525,17588]},{"content":"In this case, the <ph id=\"ph1\">`extent`</ph> object is one-dimensional and has five elements.","pos":[17589,17664],"source":" In this case, the `extent` object is one-dimensional and has five elements."},{"content":"Therefore, five threads are started.","pos":[17665,17701]},{"content":"The <bpt id=\"p1\">*</bpt>lambda expression<ept id=\"p1\">*</ept> defines the code to run on each thread.","pos":[17708,17771],"source":"The *lambda expression* defines the code to run on each thread."},{"content":"The capture clause, <ph id=\"ph1\">`[=]`</ph>, specifies that the body of the lambda expression accesses all captured variables by value, which in this case are <ph id=\"ph2\">`a`</ph>, <ph id=\"ph3\">`b`</ph>, and <ph id=\"ph4\">`sum`</ph>.","pos":[17772,17933],"source":" The capture clause, `[=]`, specifies that the body of the lambda expression accesses all captured variables by value, which in this case are `a`, `b`, and `sum`."},{"content":"In this example, the parameter list creates a one-dimensional <ph id=\"ph1\">`index`</ph> variable named <ph id=\"ph2\">`idx`</ph>.","pos":[17934,18025],"source":" In this example, the parameter list creates a one-dimensional `index` variable named `idx`."},{"content":"The value of the <ph id=\"ph1\">`idx[0]`</ph> is 0 in the first thread and increases by one in each subsequent thread.","pos":[18026,18124],"source":" The value of the `idx[0]` is 0 in the first thread and increases by one in each subsequent thread."},{"content":"The <ph id=\"ph1\">`restrict(amp)`</ph> indicates that only the subset of the C++ language that C++ AMP can accelerate is used.","pos":[18125,18232],"source":" The `restrict(amp)` indicates that only the subset of the C++ language that C++ AMP can accelerate is used."},{"content":"The limitations on functions that have the restrict modifier are described in <bpt id=\"p1\">[</bpt>restrict (C++ AMP)<ept id=\"p1\">](../../cpp/restrict-cpp-amp.md)</ept>.","pos":[18234,18364],"source":"  The limitations on functions that have the restrict modifier are described in [restrict (C++ AMP)](../../cpp/restrict-cpp-amp.md)."},{"content":"For more information, see, <bpt id=\"p1\">[</bpt>Lambda Expression Syntax<ept id=\"p1\">](../../cpp/lambda-expression-syntax.md)</ept>.","pos":[18365,18458],"source":" For more information, see, [Lambda Expression Syntax](../../cpp/lambda-expression-syntax.md)."},{"content":"The lambda expression can include the code to execute or it can call a separate kernel function.","pos":[18465,18561]},{"content":"The kernel function must include the <ph id=\"ph1\">`restrict(amp)`</ph> modifier.","pos":[18562,18624],"source":" The kernel function must include the `restrict(amp)` modifier."},{"content":"The following example is equivalent to the previous example, but it calls a separate kernel function.","pos":[18625,18726]},{"content":"Accelerating Code: Tiles and Barriers","pos":[19512,19549]},{"content":"You can gain additional acceleration by using tiling.","pos":[19554,19607]},{"content":"Tiling divides the threads into equal rectangular subsets or <bpt id=\"p1\">*</bpt>tiles<ept id=\"p1\">*</ept>.","pos":[19608,19677],"source":" Tiling divides the threads into equal rectangular subsets or *tiles*."},{"content":"You determine the appropriate tile size based on your data set and the algorithm that you are coding.","pos":[19678,19779]},{"content":"For each thread, you have access to the <bpt id=\"p1\">*</bpt>global<ept id=\"p1\">*</ept> location of a data element relative to the whole <ph id=\"ph1\">`array`</ph> or <ph id=\"ph2\">`array_view`</ph> and access to the <bpt id=\"p2\">*</bpt>local<ept id=\"p2\">*</ept> location relative to the tile.","pos":[19780,19958],"source":" For each thread, you have access to the *global* location of a data element relative to the whole `array` or `array_view` and access to the *local* location relative to the tile."},{"content":"Using the local index value simplifies your code because you don't have to write the code to translate index values from global to local.","pos":[19959,20096]},{"content":"To use tiling, call the <bpt id=\"p1\">[</bpt>extent::tile Method<ept id=\"p1\">](reference/extent-class.md#tile)</ept> on the compute domain in the <ph id=\"ph1\">`parallel_for_each`</ph> method, and use a <bpt id=\"p2\">[</bpt>tiled_index<ept id=\"p2\">](../../parallel/amp/reference/tiled-index-class.md)</ept> object in the lambda expression.","pos":[20097,20339],"source":" To use tiling, call the [extent::tile Method](reference/extent-class.md#tile) on the compute domain in the `parallel_for_each` method, and use a [tiled_index](../../parallel/amp/reference/tiled-index-class.md) object in the lambda expression."},{"content":"In typical applications, the elements in a tile are related in some way, and the code has to access and keep track of values across the tile.","pos":[20346,20487]},{"content":"Use the <bpt id=\"p1\">[</bpt>tile_static Keyword<ept id=\"p1\">](../../cpp/tile-static-keyword.md)</ept> keyword and the <bpt id=\"p2\">[</bpt>tile_barrier::wait Method<ept id=\"p2\">](reference/tile-barrier-class.md#wait)</ept> to accomplish this.","pos":[20488,20653],"source":" Use the [tile_static Keyword](../../cpp/tile-static-keyword.md) keyword and the [tile_barrier::wait Method](reference/tile-barrier-class.md#wait) to accomplish this."},{"content":"A variable that has the <ph id=\"ph1\">`tile_static`</ph> keyword has a scope across an entire tile, and an instance of the variable is created for each tile.","pos":[20654,20792],"source":" A variable that has the `tile_static` keyword has a scope across an entire tile, and an instance of the variable is created for each tile."},{"content":"You must handle synchronization of tile-thread access to the variable.","pos":[20793,20863]},{"content":"The <bpt id=\"p1\">[</bpt>tile_barrier::wait Method<ept id=\"p1\">](reference/tile-barrier-class.md#wait)</ept> stops execution of the current thread until all the threads in the tile have reached the call to <ph id=\"ph1\">`tile_barrier::wait`</ph>.","pos":[20864,21052],"source":" The [tile_barrier::wait Method](reference/tile-barrier-class.md#wait) stops execution of the current thread until all the threads in the tile have reached the call to `tile_barrier::wait`."},{"content":"So you can accumulate values across the tile by using <ph id=\"ph1\">`tile_static`</ph> variables.","pos":[21053,21131],"source":" So you can accumulate values across the tile by using `tile_static` variables."},{"content":"Then you can finish any computations that require access to all the values.","pos":[21132,21207]},{"content":"The following diagram represents a two-dimensional array of sampling data that is arranged in tiles.","pos":[21215,21315]},{"content":"Index values in a tiled extent","pos":[21324,21354]},{"content":"The following code example uses the sampling data from the previous diagram.","pos":[21436,21512]},{"content":"The code replaces each value in the tile by the average of the values in the tile.","pos":[21513,21595]},{"content":"Math Libraries","pos":[22993,23007]},{"content":"C++ AMP includes two math libraries.","pos":[23011,23047]},{"content":"The double-precision library in the <bpt id=\"p1\">[</bpt>Concurrency::precise_math Namespace<ept id=\"p1\">](../../parallel/amp/reference/concurrency-precise-math-namespace.md)</ept> provides support for double-precision functions.","pos":[23048,23238],"source":" The double-precision library in the [Concurrency::precise_math Namespace](../../parallel/amp/reference/concurrency-precise-math-namespace.md) provides support for double-precision functions."},{"content":"It also provides support for single-precision functions, although double-precision support on the hardware is still required.","pos":[23239,23364]},{"content":"It complies with the <bpt id=\"p1\">[</bpt>C99 Specification (ISO/IEC 9899)<ept id=\"p1\">](http://go.microsoft.com/fwlink/linkid=225887)</ept>.","pos":[23365,23467],"source":" It complies with the [C99 Specification (ISO/IEC 9899)](http://go.microsoft.com/fwlink/linkid=225887)."},{"content":"The accelerator must support full double precision.","pos":[23468,23519]},{"content":"You can determine whether it does by checking the value of the <bpt id=\"p1\">[</bpt>accelerator::supports_double_precision Data Member<ept id=\"p1\">](reference/accelerator-class.md#supports_double_precision)</ept>.","pos":[23520,23694],"source":" You can determine whether it does by checking the value of the [accelerator::supports_double_precision Data Member](reference/accelerator-class.md#supports_double_precision)."},{"content":"The fast math library,  in the <bpt id=\"p1\">[</bpt>Concurrency::fast_math Namespace<ept id=\"p1\">](../../parallel/amp/reference/concurrency-fast-math-namespace.md)</ept>, contains another set of math functions.","pos":[23695,23866],"source":" The fast math library,  in the [Concurrency::fast_math Namespace](../../parallel/amp/reference/concurrency-fast-math-namespace.md), contains another set of math functions."},{"content":"These functions, which support only <ph id=\"ph1\">`float`</ph> operands, execute more quickly but aren’t as precise as those in the double-precision math library.","pos":[23867,24010],"source":" These functions, which support only `float` operands, execute more quickly but aren’t as precise as those in the double-precision math library."},{"content":"The functions are contained in the <ph id=\"ph1\">\\&lt;</ph>amp_math.h&gt; header file and all are declared with <ph id=\"ph2\">`restrict(amp)`</ph>.","pos":[24011,24114],"source":" The functions are contained in the \\<amp_math.h> header file and all are declared with `restrict(amp)`."},{"content":"The functions in the <ph id=\"ph1\">\\&lt;</ph>cmath&gt; header file are imported into both the <ph id=\"ph2\">`fast_math`</ph> and <ph id=\"ph3\">`precise_math`</ph> namespaces.","pos":[24115,24226],"source":" The functions in the \\<cmath> header file are imported into both the `fast_math` and `precise_math` namespaces."},{"content":"The <ph id=\"ph1\">`restrict`</ph> keyword is used to distinguish the <ph id=\"ph2\">\\&lt;</ph>cmath&gt; version and the C++ AMP version.","pos":[24227,24318],"source":" The `restrict` keyword is used to distinguish the \\<cmath> version and the C++ AMP version."},{"content":"The following code calculates the base-10 logarithm, using the fast method, of each value that is in the compute domain.","pos":[24319,24439]},{"content":"Graphics Library","pos":[24981,24997]},{"content":"C++ AMP includes a graphics library that is designed for accelerated graphics programming.","pos":[25001,25091]},{"content":"This library is used only on devices that support native graphics functionality.","pos":[25092,25172]},{"content":"The methods are in the <bpt id=\"p1\">[</bpt>Concurrency::graphics Namespace<ept id=\"p1\">](../../parallel/amp/reference/concurrency-graphics-namespace.md)</ept> and are contained in the <ph id=\"ph1\">\\&lt;</ph>amp_graphics.h&gt; header file.","pos":[25173,25349],"source":" The methods are in the [Concurrency::graphics Namespace](../../parallel/amp/reference/concurrency-graphics-namespace.md) and are contained in the \\<amp_graphics.h> header file."},{"content":"The key components of the graphics library are:","pos":[25350,25397]},{"content":"<bpt id=\"p1\">[</bpt>texture Class<ept id=\"p1\">](../../parallel/amp/reference/texture-class.md)</ept>: You can use the texture class to create textures from memory or from a file.","pos":[25405,25545],"source":"[texture Class](../../parallel/amp/reference/texture-class.md): You can use the texture class to create textures from memory or from a file."},{"content":"Textures resemble arrays because they contain data, and they resemble containers in the Standard Template Library (STL) with respect to assignment and copy construction.","pos":[25546,25715]},{"content":"For more information, see <bpt id=\"p1\">[</bpt>STL Containers<ept id=\"p1\">](../../standard-library/stl-containers.md)</ept>.","pos":[25716,25801],"source":" For more information, see [STL Containers](../../standard-library/stl-containers.md)."},{"content":"The template parameters for the <ph id=\"ph1\">`texture`</ph> class are the element type and the rank.","pos":[25802,25884],"source":" The template parameters for the `texture` class are the element type and the rank."},{"content":"The rank can be 1, 2, or 3.","pos":[25885,25912]},{"content":"The element type can be one of the short vector types that are described later in this article.","pos":[25913,26008]},{"pos":[26016,26152],"content":"<bpt id=\"p1\">[</bpt>writeonly_texture_view Class<ept id=\"p1\">](../../parallel/amp/reference/writeonly-texture-view-class.md)</ept>: Provides write-only access to any texture.","source":"[writeonly_texture_view Class](../../parallel/amp/reference/writeonly-texture-view-class.md): Provides write-only access to any texture."},{"pos":[26160,26472],"content":"<bpt id=\"p1\">[</bpt>Short Vector Library<ept id=\"p1\">](http://msdn.microsoft.com/en-us/4c4f5bed-c396-493b-a238-c347563f645f)</ept>: Defines a set of short vector types of length 2, 3, and 4 that are based on <ph id=\"ph1\">`int`</ph>, <ph id=\"ph2\">`uint`</ph>, <ph id=\"ph3\">`float`</ph>, <ph id=\"ph4\">`double`</ph>, <bpt id=\"p2\">[</bpt>norm<ept id=\"p2\">](../../parallel/amp/reference/norm-class.md)</ept>, or <bpt id=\"p3\">[</bpt>unorm<ept id=\"p3\">](../../parallel/amp/reference/unorm-class.md)</ept>.","source":"[Short Vector Library](http://msdn.microsoft.com/en-us/4c4f5bed-c396-493b-a238-c347563f645f): Defines a set of short vector types of length 2, 3, and 4 that are based on `int`, `uint`, `float`, `double`, [norm](../../parallel/amp/reference/norm-class.md), or [unorm](../../parallel/amp/reference/unorm-class.md)."},{"pos":[26557,26561],"content":"Apps"},{"content":"Like other C++ libraries, you can use C++ AMP in your <ph id=\"ph1\">[!INCLUDE[win8_appname_long](../../build/includes/win8_appname_long_md.md)]</ph> apps.","pos":[26565,26700],"source":"Like other C++ libraries, you can use C++ AMP in your [!INCLUDE[win8_appname_long](../../build/includes/win8_appname_long_md.md)] apps."},{"content":"These articles describe how to include C++ AMP code in apps that is created by using C++, C#, Visual Basic, or JavaScript:","pos":[26701,26823]},{"content":"Using C++ AMP in Windows Store Apps","pos":[26832,26867]},{"content":"Walkthrough: Creating a basic Windows Runtime component in C++ and calling it from JavaScript","pos":[26936,27029]},{"content":"Bing Maps Trip Optimizer, a Window Store app in JavaScript and C++","pos":[27087,27153]},{"content":"How to use C++ AMP from C# using the Windows Runtime","pos":[27211,27263]},{"content":"How to use C++ AMP from C","pos":[27321,27346]},{"content":"Calling Native Functions from Managed Code","pos":[27405,27447]},{"content":"C++ AMP and Concurrency Visualizer","pos":[27517,27551]},{"content":"The Concurrency Visualizer includes support for analyzing performance of C++ AMP code.","pos":[27555,27641]},{"content":"These articles describe these features:","pos":[27642,27681]},{"content":"GPU Activity Graph","pos":[27690,27708]},{"content":"GPU Activity (Paging)","pos":[27762,27783]},{"content":"GPU Activity (This Process)","pos":[27838,27865]},{"content":"GPU Activity (Other Processes)","pos":[27926,27956]},{"content":"Channels (Threads View)","pos":[28020,28043]},{"content":"Analyzing C++ AMP Code with the Concurrency Visualizer","pos":[28100,28154]},{"content":"Performance Recommendations","pos":[28222,28249]},{"content":"Modulus and division of unsigned integers have significantly better performance than modulus and division of signed integers.","pos":[28253,28378]},{"content":"We recommend that you use unsigned integers when possible.","pos":[28379,28437]},{"content":"See Also","pos":[28446,28454]},{"content":"C++ AMP (C++ Accelerated Massive Parallelism)","pos":[28459,28504]},{"content":"Lambda Expression Syntax","pos":[28578,28602]},{"content":"Reference (C++ AMP)","pos":[28648,28667]},{"content":"Parallel Programming in Native Code Blog","pos":[28725,28765]}],"content":"---\ntitle: \"C++ AMP Overview | Microsoft Docs\"\nms.custom: \"\"\nms.date: \"11/04/2016\"\nms.reviewer: \"\"\nms.suite: \"\"\nms.technology: \n  - \"devlang-cpp\"\nms.tgt_pltfrm: \"\"\nms.topic: \"article\"\ndev_langs: \n  - \"C++\"\nhelpviewer_keywords: \n  - \"C++ Accelerated Massive Parallelism, requirements\"\n  - \"C++ Accelerated Massive Parallelism, architecture\"\n  - \"C++ AMP\"\n  - \"C++ Accelerated Massive Parallelism, overview\"\n  - \"C++ Accelerated Massive Parallelism\"\nms.assetid: 9e593b06-6e3c-43e9-8bae-6d89efdd39fc\ncaps.latest.revision: 60\nauthor: \"mikeblome\"\nms.author: \"mblome\"\nmanager: \"ghogen\"\ntranslation.priority.ht: \n  - \"cs-cz\"\n  - \"de-de\"\n  - \"es-es\"\n  - \"fr-fr\"\n  - \"it-it\"\n  - \"ja-jp\"\n  - \"ko-kr\"\n  - \"pl-pl\"\n  - \"pt-br\"\n  - \"ru-ru\"\n  - \"tr-tr\"\n  - \"zh-cn\"\n  - \"zh-tw\"\n---\n# C++ AMP Overview\nC++ Accelerated Massive Parallelism (C++ AMP) accelerates execution of C++ code by taking advantage of data-parallel hardware such as a graphics processing unit (GPU) on a discrete graphics card. By using C++ AMP, you can code multi-dimensional data algorithms so that execution can be accelerated by using parallelism on heterogeneous hardware. The C++ AMP programming model includes multidimensional arrays, indexing, memory transfer, tiling, and a mathematical function library. You can use C++ AMP language extensions to control how data is moved from the CPU to the GPU and back, so that you can improve performance.  \n  \n## System Requirements  \n  \n- [!INCLUDE[win7](../../build/includes/win7_md.md)], [!INCLUDE[win8](../../build/reference/includes/win8_md.md)], [!INCLUDE[winsvr08_r2](../../parallel/amp/includes/winsvr08_r2_md.md)], or [!INCLUDE[winserver8](../../build/reference/includes/winserver8_md.md)]  \n  \n-   DirectX 11 Feature Level 11.0 or later hardware  \n  \n-   For debugging on the software emulator, [!INCLUDE[win8](../../build/reference/includes/win8_md.md)] or [!INCLUDE[winserver8](../../build/reference/includes/winserver8_md.md)] is required. For debugging on the hardware, you must install the drivers for your graphics card. For more information, see [Debugging GPU Code](/visualstudio/debugger/debugging-gpu-code).  \n  \n## Introduction  \n The following two examples illustrate the primary components of C++ AMP. Assume that you want to add the corresponding elements of two one-dimensional arrays. For example, you might want to add `{1, 2, 3, 4, 5}` and `{6, 7, 8, 9, 10}` to obtain `{7, 9, 11, 13, 15}`. Without using C++ AMP, you might write the following code to add the numbers and display the results.  \n  \n```cpp  \n  \n#include <iostream>  \n  \nvoid StandardMethod() {  \n  \n    int aCPP[] = {1, 2, 3, 4, 5};  \n    int bCPP[] = {6, 7, 8, 9, 10};  \n    int sumCPP[5];  \n  \n    for (int idx = 0; idx < 5; idx++)  \n    {  \n        sumCPP[idx] = aCPP[idx] + bCPP[idx];  \n    }  \n  \n    for (int idx = 0; idx < 5; idx++)  \n    {  \n        std::cout << sumCPP[idx] << \"\\n\";  \n    }  \n}  \n  \n```  \n  \n The important parts of the code are as follows:  \n  \n-   Data: The data consists of three arrays. All have the same rank (one) and length (five).  \n  \n-   Iteration: The first `for` loop provides a mechanism for iterating through the elements in the arrays. The code that you want to execute to compute the sums is contained in the first `for` block.  \n  \n-   Index: The `idx` variable accesses the individual elements of the arrays.  \n  \n Using C++ AMP, you might write the following code instead.  \n  \n```cpp  \n  \n#include <amp.h>  \n#include <iostream>  \nusing namespace concurrency;  \n  \nconst int size = 5;  \n  \nvoid CppAmpMethod() {  \n    int aCPP[] = {1, 2, 3, 4, 5};  \n    int bCPP[] = {6, 7, 8, 9, 10};  \n    int sumCPP[size];  \n  \n    // Create C++ AMP objects.  \n    array_view<const int, 1> a(size, aCPP);  \n    array_view<const int, 1> b(size, bCPP);  \n    array_view<int, 1> sum(size, sumCPP);  \n    sum.discard_data();  \n  \n    parallel_for_each(   \n        // Define the compute domain, which is the set of threads that are created.  \n        sum.extent,   \n        // Define the code to run on each thread on the accelerator.  \n [=](index<1> idx) restrict(amp)  \n    {  \n        sum[idx] = a[idx] + b[idx];  \n    }  \n    );  \n  \n    // Print the results. The expected output is \"7, 9, 11, 13, 15\".  \n    for (int i = 0; i < size; i++) {  \n        std::cout << sum[i] << \"\\n\";  \n    }  \n}  \n  \n```  \n  \n The same basic elements are present, but C++ AMP constructs are used:  \n  \n-   Data: You use C++ arrays to construct three C++ AMP [array_view](../../parallel/amp/reference/array-view-class.md) objects. You supply four values to construct an `array_view` object: the data values, the rank, the element type, and the length of the `array_view` object in each dimension. The rank and type are passed as type parameters. The data and length are passed as constructor parameters. In this example, the C++ array that is passed to the constructor is one-dimensional. The rank and length are used to construct the rectangular shape of the data in the `array_view` object, and the data values are used to fill the array. The runtime library also includes the [array Class](../../parallel/amp/reference/array-class.md), which has an interface that resembles the `array_view` class and is discussed later in this article.  \n  \n-   Iteration: The [parallel_for_each Function (C++ AMP)](reference/concurrency-namespace-functions-amp.md#parallel_for_each) provides a mechanism for iterating through the data elements, or *compute domain*. In this example, the compute domain is specified by `sum.extent`. The code that you want to execute is contained in a lambda expression, or *kernel function*. The `restrict(amp)` indicates that only the subset of the C++ language that C++ AMP can accelerate is used.  \n  \n-   Index: The [index Class](../../parallel/amp/reference/index-class.md) variable, `idx`, is declared with a rank of one to match the rank of the `array_view` object. By using the index, you can access the individual elements of the `array_view` objects.  \n  \n## Shaping and Indexing Data: index and extent  \n You must define the data values and declare the shape of the data before you can run the kernel code. All data is defined to be an array (rectangular), and you can define the array to have any rank (number of dimensions). The data can be any size in any of the dimensions.  \n  \n### index Class  \n The [index Class](../../parallel/amp/reference/index-class.md) specifies a location in the `array` or `array_view` object by encapsulating the offset from the origin in each dimension into one object. When you access a location in the array, you pass an `index` object to the indexing operator, `[]`, instead of a list of integer indexes. You can access the elements in each dimension by using the [array::operator() Operator](reference/array-class.md#array__operator_call) or the [array_view::operator() Operator](reference/array-view-class.md#array_view__operator_call).  \n  \n The following example creates a one-dimensional index that specifies the third element in a one-dimensional `array_view` object. The index is used to print the third element in the `array_view` object. The output is 3.  \n  \n```cpp  \n \nint aCPP[] = {1, 2, 3, 4, 5};  \narray_view<int, 1> a(5, aCPP);\n\nindex<1> idx(2);\n\nstd::cout <<a[idx] <<\"\\n\";    \n// Output: 3  \n \n```  \n  \n The following example creates a two-dimensional index that specifies the element where the row = 1 and the column = 2 in a two-dimensional `array_view` object. The first parameter in the `index` constructor is the row component, and the second parameter is the column component. The output is 6.  \n  \n```cpp  \n \nint aCPP[] = {1, 2, 3,  \n    4, 5, 6};  \narray_view<int, 2> a(2, 3, aCPP);\n\nindex<2> idx(1, 2);\n\nstd::cout <<a[idx] <<\"\\n\";  \n// Output: 6  \n \n```  \n  \n The following example creates a three-dimensional index that specifies the element  where the depth = 0, the row = 1, and the column = 3 in a three-dimensional `array_view` object. Notice that the first parameter is the depth component, the second parameter is the row component, and the third parameter is the column component. The output is 8.  \n  \n```cpp  \n \nint aCPP[] = {  \n    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,   \n    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};  \n \narray_view<int, 3> a(2, 3, 4, aCPP);\n\n// Specifies the element at 3, 1, 0.  \nindex<3> idx(0, 1, 3);\n\nstd::cout <<a[idx] <<\"\\n\";  \n \n// Output: 8  \n \n```  \n  \n### extent Class  \n The [extent Class](../../parallel/amp/reference/extent-class.md) specifies the length of the data in each dimension of the `array` or `array_view` object. You can create an extent and use it to create an `array` or `array_view` object. You can also retrieve the extent of an existing `array` or `array_view` object. The following example prints the length of the extent in each dimension of an `array_view` object.  \n  \n```cpp  \n \nint aCPP[] = {  \n    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,   \n    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};  \n// There are 3 rows and 4 columns, and the depth is two.  \narray_view<int, 3> a(2, 3, 4, aCPP);\n\nstd::cout <<\"The number of columns is \" <<a.extent[2] <<\"\\n\";  \nstd::cout <<\"The number of rows is \" <<a.extent[1] <<\"\\n\";  \nstd::cout <<\"The depth is \" <<a.extent[0]<<\"\\n\";  \nstd::cout <<\"Length in most significant dimension is \" <<a.extent[0] <<\"\\n\";  \n \n```  \n  \n The following example creates an `array_view` object that has the same dimensions as the object in the previous example, but this example uses an `extent` object instead of using explicit parameters in the `array_view` constructor.  \n  \n```cpp  \n \nint aCPP[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24};  \nextent<3> e(2, 3, 4);\n\narray_view<int, 3> a(e, aCPP);\n\nstd::cout <<\"The number of columns is \" <<a.extent[2] <<\"\\n\";  \nstd::cout <<\"The number of rows is \" <<a.extent[1] <<\"\\n\";  \nstd::cout <<\"The depth is \" <<a.extent[0] <<\"\\n\";  \n \n```  \n  \n## Moving Data to the Accelerator: array and array_view  \n Two data containers used to move data to the accelerator are defined in the runtime library. They are the [array Class](../../parallel/amp/reference/array-class.md) and the [array_view Class](../../parallel/amp/reference/array-view-class.md). The `array` class is a container class that creates a deep copy of the data when the object is constructed. The `array_view` class is a wrapper class that copies the data when the kernel function accesses the data. When the data is needed on the source device the data is copied back.  \n  \n### array Class  \n When an `array` object is constructed, a deep copy of the data is created on the accelerator if you use a constructor that includes a pointer to the data set. The kernel function modifies the copy on the accelerator. When the execution of the kernel function is finished, you must copy the data back to the source data structure. The following example multiplies each element in a vector by 10. After the kernel function is finished, the `vector conversion operator` is used to copy the data back into the vector object.  \n  \n```cpp  \n \nstd::vector<int> data(5);\n\nfor (int count = 0; count <5; count++)   \n{  \n    data[count] = count;  \n}  \n \narray<int, 1> a(5, data.begin(), data.end());\n\n \nparallel_for_each(\n    a.extent, \n [=, &a](index<1> idx) restrict(amp)  \n {  \n    a[idx] = a[idx]* 10;  \n });\n\n \ndata = a;  \nfor (int i = 0; i <5; i++)   \n{  \n    std::cout <<data[i] <<\"\\n\";  \n}  \n \n```  \n  \n### array_view Class  \n The `array_view` has nearly the same members as the `array` class, but the underlying behavior is not the same. Data passed to the `array_view` constructor is not replicated on the GPU as it is with an `array` constructor. Instead, the data is copied to the accelerator when the kernel function is executed. Therefore, if you create two `array_view` objects that use the same data, both `array_view` objects refer to the same memory space. When you do this, you have to synchronize any multithreaded access. The main advantage of using the `array_view` class is that data is moved only if it is necessary.  \n  \n### Comparison of array and array_view  \n The following table summarizes the similarities and differences between the `array` and `array_view` classes.  \n  \n|Description|array class|array_view class|  \n|-----------------|-----------------|-----------------------|  \n|When rank is determined|At compile time.|At compile time.|  \n|When extent is determined|At run time.|At run time.|  \n|Shape|Rectangular.|Rectangular.|  \n|Data storage|Is a data container.|Is a data wrapper.|  \n|Copy|Explicit and deep copy at definition.|Implicit copy when it is accessed by the kernel function.|  \n|Data retrieval|By copying the array data back to an object on the CPU thread.|By direct access of the `array_view` object or by calling the [array_view::synchronize Method](reference/array-view-class.md#synchronize) to continue accessing the data on the original container.|  \n\n\n  \n### Shared memory with array and array_view  \n Shared memory is memory that can be accessed by both the CPU and the accelerator. The use of shared memory eliminates or significantly reduces the overhead of copying data between the CPU and the accelerator. Although the memory is shared, it cannot be accessed concurrently by both the CPU and the accelerator, and doing so causes undefined behavior.  \n  \n `array` objects can be used to specify fine-grained control over the use of shared memory if the associated accelerator supports it. Whether an accelerator supports shared memory is determined by the accelerator’s [supports_cpu_shared_memory](reference/accelerator-class.md#supports_cpu_shared_memory) property, which returns `true` when shared memory is supported. If shared memory is supported, the default [access_type Enumeration](reference/concurrency-namespace-enums-amp.md#access_type) for memory allocations on the accelerator is determined by the `default_cpu_access_type` property. By default, `array` and `array_view` objects take on the same `access_type` as the primary associated `accelerator`.  \n  \n By setting the [array::cpu_access_type Data Member](reference/array-class.md#cpu_access_type) property of an `array` explicitly, you can exercise fine-grained control over how shared memory is used, so that you can optimize the app for the hardware’s performance characteristics, based on the memory access patterns of its computation kernels. An `array_view` reflects the same `cpu_access_type` as the `array` that it’s associated with; or, if the array_view is constructed without a data source, its `access_type` reflects the environment that first causes it to allocate storage. That is, if it’s first accessed by the host (CPU), then it behaves as if it were created over a CPU data source and shares the `access_type` of the `accelerator_view` associated by capture; however, if it's first accessed by an `accelerator_view`, then it behaves as if it were created over an `array` created on that `accelerator_view` and shares the `array`’s `access_type`.  \n  \n The following code example shows how to determine whether the default accelerator supports shared memory, and then creates several arrays that have different cpu_access_type configurations.  \n  \n```cpp  \n#include <amp.h>  \n#include <iostream>  \n  \nusing namespace Concurrency;  \n  \nint main()  \n{  \n  accelerator acc = accelerator(accelerator::default_accelerator);  \n  \n  // Early out if the default accelerator doesn’t support shared memory.  \n  if (!acc.supports_cpu_shared_memory)  \n  {  \n    std::cout << \"The default accelerator does not support shared memory\" << std::endl;  \n    return 1;  \n  }  \n  \n  // Override the default CPU access type.  \n  acc.default_cpu_access_type = access_type_read_write  \n  \n  // Create an accelerator_view from the default accelerator. The  \n  // accelerator_view inherits its default_cpu_access_type from acc.  \n  accelerator_view acc_v = acc.default_view;  \n  \n  // Create an extent object to size the arrays.  \n  extent<1> ex(10);  \n  \n  // Input array that can be written on the CPU.  \n  array<int, 1> arr_w(ex, acc_v, access_type_write);  \n  \n  // Output array that can be read on the CPU.  \n  array<int, 1> arr_r(ex, acc_v, access_type_read);  \n  \n  // Read-write array that can be both written to and read from on the CPU.  \n  array<int, 1> arr_rw(ex, acc_v, access_type_read_write);  \n}  \n  \n```  \n  \n## Executing Code over Data: parallel_for_each  \n The [parallel_for_each](reference/concurrency-namespace-functions-amp.md#parallel_for_each) function defines the code that you want to run on the accelerator against the data in the `array` or `array_view` object. Consider the following code from the introduction of this topic.  \n  \n```cpp  \n  \n#include <amp.h>  \n#include <iostream>  \nusing namespace concurrency;  \n  \nvoid AddArrays() {  \n    int aCPP[] = {1, 2, 3, 4, 5};  \n    int bCPP[] = {6, 7, 8, 9, 10};  \n    int sumCPP[5] = {0, 0, 0, 0, 0};  \n  \n    array_view<int, 1> a(5, aCPP);  \n    array_view<int, 1> b(5, bCPP);  \n    array_view<int, 1> sum(5, sumCPP);  \n  \n    parallel_for_each(  \n        sum.extent,   \n [=](index<1> idx) restrict(amp)  \n        {  \n            sum[idx] = a[idx] + b[idx];  \n        }  \n    );  \n  \n    for (int i = 0; i < 5; i++) {  \n        std::cout << sum[i] << \"\\n\";  \n    }  \n}  \n  \n```  \n  \n The `parallel_for_each` method takes two arguments, a compute domain and a lambda expression.  \n  \n The *compute domain* is an `extent` object or a `tiled_extent` object that defines the set of threads to create for parallel execution. One thread is generated for each element in the compute domain. In this case, the `extent` object is one-dimensional and has five elements. Therefore, five threads are started.  \n  \n The *lambda expression* defines the code to run on each thread. The capture clause, `[=]`, specifies that the body of the lambda expression accesses all captured variables by value, which in this case are `a`, `b`, and `sum`. In this example, the parameter list creates a one-dimensional `index` variable named `idx`. The value of the `idx[0]` is 0 in the first thread and increases by one in each subsequent thread. The `restrict(amp)` indicates that only the subset of the C++ language that C++ AMP can accelerate is used.  The limitations on functions that have the restrict modifier are described in [restrict (C++ AMP)](../../cpp/restrict-cpp-amp.md). For more information, see, [Lambda Expression Syntax](../../cpp/lambda-expression-syntax.md).  \n  \n The lambda expression can include the code to execute or it can call a separate kernel function. The kernel function must include the `restrict(amp)` modifier. The following example is equivalent to the previous example, but it calls a separate kernel function.  \n  \n```cpp  \n  \n#include <amp.h>  \n#include <iostream>  \nusing namespace concurrency;  \n  \nvoid AddElements(index<1> idx, array_view<int, 1> sum, array_view<int, 1> a, array_view<int, 1> b) restrict(amp)  \n{  \n    sum[idx] = a[idx] + b[idx];  \n}  \n  \nvoid AddArraysWithFunction() {  \n  \n    int aCPP[] = {1, 2, 3, 4, 5};  \n    int bCPP[] = {6, 7, 8, 9, 10};  \n    int sumCPP[5] = {0, 0, 0, 0, 0};  \n  \n    array_view<int, 1> a(5, aCPP);  \n    array_view<int, 1> b(5, bCPP);  \n    array_view<int, 1> sum(5, sumCPP);  \n  \n    parallel_for_each(  \n        sum.extent,   \n [=](index<1> idx) restrict(amp)  \n        {  \n            AddElements(idx, sum, a, b);  \n        }  \n    );  \n  \n    for (int i = 0; i < 5; i++) {  \n        std::cout << sum[i] << \"\\n\";  \n    }  \n}  \n  \n```  \n  \n## Accelerating Code: Tiles and Barriers  \n\n You can gain additional acceleration by using tiling. Tiling divides the threads into equal rectangular subsets or *tiles*. You determine the appropriate tile size based on your data set and the algorithm that you are coding. For each thread, you have access to the *global* location of a data element relative to the whole `array` or `array_view` and access to the *local* location relative to the tile. Using the local index value simplifies your code because you don't have to write the code to translate index values from global to local. To use tiling, call the [extent::tile Method](reference/extent-class.md#tile) on the compute domain in the `parallel_for_each` method, and use a [tiled_index](../../parallel/amp/reference/tiled-index-class.md) object in the lambda expression.  \n  \n In typical applications, the elements in a tile are related in some way, and the code has to access and keep track of values across the tile. Use the [tile_static Keyword](../../cpp/tile-static-keyword.md) keyword and the [tile_barrier::wait Method](reference/tile-barrier-class.md#wait) to accomplish this. A variable that has the `tile_static` keyword has a scope across an entire tile, and an instance of the variable is created for each tile. You must handle synchronization of tile-thread access to the variable. The [tile_barrier::wait Method](reference/tile-barrier-class.md#wait) stops execution of the current thread until all the threads in the tile have reached the call to `tile_barrier::wait`. So you can accumulate values across the tile by using `tile_static` variables. Then you can finish any computations that require access to all the values.  \n\n  \n The following diagram represents a two-dimensional array of sampling data that is arranged in tiles.  \n  \n ![Index values in a tiled extent](../../parallel/amp/media/camptiledgridexample.png \"camptiledgridexample\")  \n  \n The following code example uses the sampling data from the previous diagram. The code replaces each value in the tile by the average of the values in the tile.  \n  \n```cpp  \n \n// Sample data:  \nint sampledata[] = {  \n    2, 2, 9, 7, 1, 4,  \n    4, 4, 8, 8, 3, 4,  \n    1, 5, 1, 2, 5, 2,  \n    6, 8, 3, 2, 7, 2};  \n \n// The tiles:  \n// 2 2    9 7    1 4  \n// 4 4    8 8    3 4  \n//  \n// 1 5    1 2    5 2  \n// 6 8    3 2    7 2  \n \n// Averages:  \nint averagedata[] = {   \n    0, 0, 0, 0, 0, 0,   \n    0, 0, 0, 0, 0, 0,   \n    0, 0, 0, 0, 0, 0,   \n    0, 0, 0, 0, 0, 0,   \n};  \n \narray_view<int, 2> sample(4, 6, sampledata);\n\narray_view<int, 2> average(4, 6, averagedata);\n\n \nparallel_for_each(*// Create threads for sample.extent and divide the extent into 2 x 2 tiles.  \n    sample.extent.tile<2,2>(), \n [=](tiled_index<2,2> idx) restrict(amp)  \n { *// Create a 2 x 2 array to hold the values in this tile.  \n    tile_static int nums[2][2]; *// Copy the values for the tile into the 2 x 2 array.  \n    nums[idx.local[1]][idx.local[0]] = sample[idx.global]; *// When all the threads have executed and the 2 x 2 array is complete, find the average.  \n    idx.barrier.wait();\nint sum = nums[0][0] + nums[0][1] + nums[1][0] + nums[1][1]; *// Copy the average into the array_view.  \n    average[idx.global] = sum / 4;  \n });\n\n \nfor (int i = 0; i <4; i++) {  \n    for (int j = 0; j <6; j++) {  \n    std::cout <<average(i,j) <<\" \";  \n }  \n    std::cout <<\"\\n\";  \n}  \n \n// Output:  \n// 3 3 8 8 3 3  \n// 3 3 8 8 3 3  \n// 5 5 2 2 4 4  \n// 5 5 2 2 4 4  \n \n```  \n  \n## Math Libraries  \n C++ AMP includes two math libraries. The double-precision library in the [Concurrency::precise_math Namespace](../../parallel/amp/reference/concurrency-precise-math-namespace.md) provides support for double-precision functions. It also provides support for single-precision functions, although double-precision support on the hardware is still required. It complies with the [C99 Specification (ISO/IEC 9899)](http://go.microsoft.com/fwlink/linkid=225887). The accelerator must support full double precision. You can determine whether it does by checking the value of the [accelerator::supports_double_precision Data Member](reference/accelerator-class.md#supports_double_precision). The fast math library,  in the [Concurrency::fast_math Namespace](../../parallel/amp/reference/concurrency-fast-math-namespace.md), contains another set of math functions. These functions, which support only `float` operands, execute more quickly but aren’t as precise as those in the double-precision math library. The functions are contained in the \\<amp_math.h> header file and all are declared with `restrict(amp)`. The functions in the \\<cmath> header file are imported into both the `fast_math` and `precise_math` namespaces. The `restrict` keyword is used to distinguish the \\<cmath> version and the C++ AMP version. The following code calculates the base-10 logarithm, using the fast method, of each value that is in the compute domain.  \n\n  \n```cpp  \n  \n#include <amp.h>  \n#include <amp_math.h>  \n#include <iostream>  \nusing namespace concurrency;  \n  \nvoid MathExample() {  \n  \n    double numbers[] = { 1.0, 10.0, 60.0, 100.0, 600.0, 1000.0 };  \n    array_view<double, 1> logs(6, numbers);  \n  \n    parallel_for_each(  \n        logs.extent,  \n [=] (index<1> idx) restrict(amp) {  \n            logs[idx] = concurrency::fast_math::log10(logs[idx]);  \n        }  \n    );  \n  \n    for (int i = 0; i < 6; i++) {  \n        std::cout << logs[i] << \"\\n\";  \n    }  \n}  \n  \n```  \n  \n## Graphics Library  \n C++ AMP includes a graphics library that is designed for accelerated graphics programming. This library is used only on devices that support native graphics functionality. The methods are in the [Concurrency::graphics Namespace](../../parallel/amp/reference/concurrency-graphics-namespace.md) and are contained in the \\<amp_graphics.h> header file. The key components of the graphics library are:  \n  \n- [texture Class](../../parallel/amp/reference/texture-class.md): You can use the texture class to create textures from memory or from a file. Textures resemble arrays because they contain data, and they resemble containers in the Standard Template Library (STL) with respect to assignment and copy construction. For more information, see [STL Containers](../../standard-library/stl-containers.md). The template parameters for the `texture` class are the element type and the rank. The rank can be 1, 2, or 3. The element type can be one of the short vector types that are described later in this article.  \n  \n- [writeonly_texture_view Class](../../parallel/amp/reference/writeonly-texture-view-class.md): Provides write-only access to any texture.  \n  \n- [Short Vector Library](http://msdn.microsoft.com/en-us/4c4f5bed-c396-493b-a238-c347563f645f): Defines a set of short vector types of length 2, 3, and 4 that are based on `int`, `uint`, `float`, `double`, [norm](../../parallel/amp/reference/norm-class.md), or [unorm](../../parallel/amp/reference/unorm-class.md).  \n  \n## [!INCLUDE[win8_appname_long](../../build/includes/win8_appname_long_md.md)] Apps  \n Like other C++ libraries, you can use C++ AMP in your [!INCLUDE[win8_appname_long](../../build/includes/win8_appname_long_md.md)] apps. These articles describe how to include C++ AMP code in apps that is created by using C++, C#, Visual Basic, or JavaScript:  \n  \n- [Using C++ AMP in Windows Store Apps](../../parallel/amp/using-cpp-amp-in-windows-store-apps.md)  \n  \n- [Walkthrough: Creating a basic Windows Runtime component in C++ and calling it from JavaScript](http://go.microsoft.com/fwlink/p/linkid=249077)  \n  \n- [Bing Maps Trip Optimizer, a Window Store app in JavaScript and C++](http://go.microsoft.com/fwlink/p/linkid=249078)  \n  \n- [How to use C++ AMP from C# using the Windows Runtime](http://go.microsoft.com/fwlink/p/linkid=249080)  \n  \n- [How to use C++ AMP from C#](http://go.microsoft.com/fwlink/p/linkid=249081)  \n  \n- [Calling Native Functions from Managed Code](../../dotnet/calling-native-functions-from-managed-code.md)  \n  \n## C++ AMP and Concurrency Visualizer  \n The Concurrency Visualizer includes support for analyzing performance of C++ AMP code. These articles describe these features:  \n  \n- [GPU Activity Graph](/visualstudio/profiling/gpu-activity-graph)  \n  \n- [GPU Activity (Paging)](/visualstudio/profiling/gpu-activity-paging)  \n  \n- [GPU Activity (This Process)](/visualstudio/profiling/gpu-activity-this-process)  \n  \n- [GPU Activity (Other Processes)](/visualstudio/profiling/gpu-activity-other-processes)  \n  \n- [Channels (Threads View)](/visualstudio/profiling/channels-threads-view)  \n  \n- [Analyzing C++ AMP Code with the Concurrency Visualizer](http://go.microsoft.com/fwlink/linkid=253987&clcid=0x409)  \n  \n## Performance Recommendations  \n Modulus and division of unsigned integers have significantly better performance than modulus and division of signed integers. We recommend that you use unsigned integers when possible.  \n  \n## See Also  \n [C++ AMP (C++ Accelerated Massive Parallelism)](../../parallel/amp/cpp-amp-cpp-accelerated-massive-parallelism.md)   \n [Lambda Expression Syntax](../../cpp/lambda-expression-syntax.md)   \n [Reference (C++ AMP)](../../parallel/amp/reference/reference-cpp-amp.md)   \n [Parallel Programming in Native Code Blog](http://go.microsoft.com/fwlink/p/linkid=238472)\n"}