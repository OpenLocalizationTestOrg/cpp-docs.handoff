{"nodes":[{"pos":[12,78],"content":"Best Practices in the Asynchronous Agents Library | Microsoft Docs","needQuote":false,"needEscape":true,"nodes":[{"content":"Best Practices in the Asynchronous Agents Library | Microsoft Docs","pos":[0,66]}]},{"content":"Best Practices in the Asynchronous Agents Library","pos":[815,864]},{"content":"This document describes how to make effective use of the Asynchronous Agents Library.","pos":[865,950]},{"content":"The Agents Library promotes an actor-based programming model and in-process message passing for coarse-grained dataflow and pipelining tasks.","pos":[951,1092]},{"pos":[1099,1234],"content":"For more information about the Agents Library, see <bpt id=\"p1\">[</bpt>Asynchronous Agents Library<ept id=\"p1\">](../../parallel/concrt/asynchronous-agents-library.md)</ept>.","source":"For more information about the Agents Library, see [Asynchronous Agents Library](../../parallel/concrt/asynchronous-agents-library.md)."},{"pos":[1263,1271],"content":"Sections"},{"content":"This document contains the following sections:","pos":[1275,1321]},{"content":"Use Agents to Isolate State","pos":[1330,1357]},{"content":"Use a Throttling Mechanism to Limit the Number of Messages in a Data Pipeline","pos":[1379,1456]},{"content":"Do Not Perform Fine-Grained Work in a Data Pipeline","pos":[1479,1530]},{"content":"Do Not Pass Large Message Payloads by Value","pos":[1555,1598]},{"content":"Use shared_ptr in a Data Network When Ownership Is Undefined","pos":[1625,1685]},{"pos":[1733,1760],"content":"Use Agents to Isolate State"},{"content":"The Agents Library provides alternatives to shared state by letting you connect isolated components through an asynchronous message-passing mechanism.","pos":[1764,1914]},{"content":"Asynchronous agents are most effective when they isolate their internal state from other components.","pos":[1915,2015]},{"content":"By isolating state, multiple components do not typically act on shared data.","pos":[2016,2092]},{"content":"State isolation can enable your application to scale because it reduces contention on shared memory.","pos":[2093,2193]},{"content":"State isolation also reduces the chance of deadlock and race conditions because components do not have to synchronize access to shared data.","pos":[2194,2334]},{"content":"You typically isolate state in an agent by holding data members in the <ph id=\"ph1\">`private`</ph> or <ph id=\"ph2\">`protected`</ph> sections of the agent class and by using message buffers to communicate state changes.","pos":[2341,2523],"source":"You typically isolate state in an agent by holding data members in the `private` or `protected` sections of the agent class and by using message buffers to communicate state changes."},{"content":"The following example shows the <ph id=\"ph1\">`basic_agent`</ph> class, which derives from <bpt id=\"p1\">[</bpt>concurrency::agent<ept id=\"p1\">](../../parallel/concrt/reference/agent-class.md)</ept>.","pos":[2524,2665],"source":" The following example shows the `basic_agent` class, which derives from [concurrency::agent](../../parallel/concrt/reference/agent-class.md)."},{"content":"The <ph id=\"ph1\">`basic_agent`</ph> class uses two message buffers to communicate with external components.","pos":[2666,2755],"source":" The `basic_agent` class uses two message buffers to communicate with external components."},{"content":"One message buffer holds incoming messages; the other message buffer holds outgoing messages.","pos":[2756,2849]},{"pos":[2867,2888],"content":"concrt-simple-agent#1"},{"pos":[2992,3288],"content":"For complete examples about how to define and use agents, see <bpt id=\"p1\">[</bpt>Walkthrough: Creating an Agent-Based Application<ept id=\"p1\">](../../parallel/concrt/walkthrough-creating-an-agent-based-application.md)</ept> and <bpt id=\"p2\">[</bpt>Walkthrough: Creating a Dataflow Agent<ept id=\"p2\">](../../parallel/concrt/walkthrough-creating-a-dataflow-agent.md)</ept>.","source":"For complete examples about how to define and use agents, see [Walkthrough: Creating an Agent-Based Application](../../parallel/concrt/walkthrough-creating-an-agent-based-application.md) and [Walkthrough: Creating a Dataflow Agent](../../parallel/concrt/walkthrough-creating-a-dataflow-agent.md)."},{"pos":[3295,3308],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[3344,3421],"content":"Use a Throttling Mechanism to Limit the Number of Messages in a Data Pipeline"},{"content":"Many message-buffer types, such as <bpt id=\"p1\">[</bpt>concurrency::unbounded_buffer<ept id=\"p1\">](reference/unbounded-buffer-class.md)</ept>, can hold an unlimited number of messages.","pos":[3425,3571],"source":"Many message-buffer types, such as [concurrency::unbounded_buffer](reference/unbounded-buffer-class.md), can hold an unlimited number of messages."},{"content":"When a message producer sends messages to a data pipeline faster than the consumer can process these messages, the application can enter a low-memory or out-of-memory state.","pos":[3572,3745]},{"content":"You can use a throttling mechanism, for example, a semaphore, to limit the number of messages that are concurrently active in a data pipeline.","pos":[3746,3888]},{"content":"The following basic example demonstrates how to use a semaphore to limit the number of messages in a data pipeline.","pos":[3895,4010]},{"content":"The data pipeline uses the <bpt id=\"p1\">[</bpt>concurrency::wait<ept id=\"p1\">](reference/concurrency-namespace-functions.md#wait)</ept> function to simulate an operation that takes at least 100 milliseconds.","pos":[4011,4180],"source":" The data pipeline uses the [concurrency::wait](reference/concurrency-namespace-functions.md#wait) function to simulate an operation that takes at least 100 milliseconds."},{"content":"Because the sender produces messages faster than the consumer can process those messages, this example defines the <ph id=\"ph1\">`semaphore`</ph> class to enable the application to limit the number of active messages.","pos":[4181,4379],"source":" Because the sender produces messages faster than the consumer can process those messages, this example defines the `semaphore` class to enable the application to limit the number of active messages."},{"pos":[4397,4424],"content":"concrt-message-throttling#1"},{"pos":[4528,4620],"content":"The <ph id=\"ph1\">`semaphore`</ph> object limits the pipeline to process at most two messages at the same time.","source":"The `semaphore` object limits the pipeline to process at most two messages at the same time."},{"content":"The producer in this example sends relatively few messages to the consumer.","pos":[4627,4702]},{"content":"Therefore, this example does not demonstrate a potential low-memory or out-of-memory condition.","pos":[4703,4798]},{"content":"However, this mechanism is useful when a data pipeline contains a relatively high number of messages.","pos":[4799,4900]},{"pos":[4907,5163],"content":"For more information about how to create the semaphore class that is used in this example, see <bpt id=\"p1\">[</bpt>How to: Use the Context Class to Implement a Cooperative Semaphore<ept id=\"p1\">](../../parallel/concrt/how-to-use-the-context-class-to-implement-a-cooperative-semaphore.md)</ept>.","source":"For more information about how to create the semaphore class that is used in this example, see [How to: Use the Context Class to Implement a Cooperative Semaphore](../../parallel/concrt/how-to-use-the-context-class-to-implement-a-cooperative-semaphore.md)."},{"pos":[5170,5183],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[5221,5272],"content":"Do Not Perform Fine-Grained Work in a Data Pipeline"},{"content":"The Agents Library is most useful when the work that is performed by a data pipeline is fairly coarse-grained.","pos":[5276,5386]},{"content":"For example, one application component might read data from a file or a network connection and occasionally send that data to another component.","pos":[5387,5531]},{"content":"The protocol that the Agents Library uses to propagate messages causes the message-passing mechanism to have more overhead than the task parallel constructs that are provided by the <bpt id=\"p1\">[</bpt>Parallel Patterns Library<ept id=\"p1\">](../../parallel/concrt/parallel-patterns-library-ppl.md)</ept> (PPL).","pos":[5532,5804],"source":" The protocol that the Agents Library uses to propagate messages causes the message-passing mechanism to have more overhead than the task parallel constructs that are provided by the [Parallel Patterns Library](../../parallel/concrt/parallel-patterns-library-ppl.md) (PPL)."},{"content":"Therefore, make sure that the work that is performed by a data pipeline is long enough to offset this overhead.","pos":[5805,5916]},{"content":"Although a data pipeline is most effective when its tasks are coarse-grained, each stage of the data pipeline can use PPL constructs such as task groups and parallel algorithms to perform more fine-grained work.","pos":[5923,6134]},{"content":"For an example of a coarse-grained data network that uses fine-grained parallelism at each processing stage, see <bpt id=\"p1\">[</bpt>Walkthrough: Creating an Image-Processing Network<ept id=\"p1\">](../../parallel/concrt/walkthrough-creating-an-image-processing-network.md)</ept>.","pos":[6135,6375],"source":" For an example of a coarse-grained data network that uses fine-grained parallelism at each processing stage, see [Walkthrough: Creating an Image-Processing Network](../../parallel/concrt/walkthrough-creating-an-image-processing-network.md)."},{"pos":[6382,6395],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[6435,6478],"content":"Do Not Pass Large Message Payloads by Value"},{"content":"In some cases, the runtime creates a copy of every message that it passes from one message buffer to another message buffer.","pos":[6483,6607]},{"content":"For example, the <bpt id=\"p1\">[</bpt>concurrency::overwrite_buffer<ept id=\"p1\">](../../parallel/concrt/reference/overwrite-buffer-class.md)</ept> class offers a copy of every message that it receives to each of its targets.","pos":[6608,6793],"source":" For example, the [concurrency::overwrite_buffer](../../parallel/concrt/reference/overwrite-buffer-class.md) class offers a copy of every message that it receives to each of its targets."},{"content":"The runtime also creates a copy of the message data when you use message-passing functions such as <bpt id=\"p1\">[</bpt>concurrency::send<ept id=\"p1\">](reference/concurrency-namespace-functions.md#send)</ept> and <bpt id=\"p2\">[</bpt>concurrency::receive<ept id=\"p2\">](reference/concurrency-namespace-functions.md#receive)</ept> to write messages to and read messages from a message buffer.","pos":[6794,7106],"source":" The runtime also creates a copy of the message data when you use message-passing functions such as [concurrency::send](reference/concurrency-namespace-functions.md#send) and [concurrency::receive](reference/concurrency-namespace-functions.md#receive) to write messages to and read messages from a message buffer."},{"content":"Although this mechanism helps eliminate the risk of concurrently writing to shared data, it could lead to poor memory performance when the message payload is relatively large.","pos":[7107,7282]},{"content":"You can use pointers or references to improve memory performance when you pass messages that have a large payload.","pos":[7289,7403]},{"content":"The following example compares passing large messages by value to passing pointers to the same message type.","pos":[7404,7512]},{"content":"The example defines two agent types, <ph id=\"ph1\">`producer`</ph> and <ph id=\"ph2\">`consumer`</ph>, that act on <ph id=\"ph3\">`message_data`</ph> objects.","pos":[7513,7612],"source":" The example defines two agent types, `producer` and `consumer`, that act on `message_data` objects."},{"content":"The example compares the time that is required for the producer to send several <ph id=\"ph1\">`message_data`</ph> objects to the consumer to the time that is required for the producer agent to send several pointers to <ph id=\"ph2\">`message_data`</ph> objects to the consumer.","pos":[7613,7851],"source":" The example compares the time that is required for the producer to send several `message_data` objects to the consumer to the time that is required for the producer agent to send several pointers to `message_data` objects to the consumer."},{"pos":[7869,7894],"content":"concrt-message-payloads#1"},{"content":"This example produces the following sample output:","pos":[7998,8048]},{"pos":[8152,8355],"content":"The version that uses pointers performs better because it eliminates the requirement for the runtime to create a full copy of every <ph id=\"ph1\">`message_data`</ph> object that it passes from the producer to the consumer.","source":"The version that uses pointers performs better because it eliminates the requirement for the runtime to create a full copy of every `message_data` object that it passes from the producer to the consumer."},{"pos":[8362,8375],"content":"[<bpt id=\"p1\">[</bpt>Top<ept id=\"p1\">](#top)</ept>]","source":"[[Top](#top)]"},{"pos":[8410,8470],"content":"Use shared_ptr in a Data Network When Ownership Is Undefined"},{"content":"When you send messages by pointer through a message-passing pipeline or network, you typically allocate the memory for each message at the front of the network and free that memory at the end of the network.","pos":[8474,8681]},{"content":"Although this mechanism frequently works well, there are cases in which it is difficult or not possible to use it.","pos":[8682,8796]},{"content":"For example, consider the case in which the data network contains multiple end nodes.","pos":[8797,8882]},{"content":"In this case, there is no clear location to free the memory for the messages.","pos":[8883,8960]},{"content":"To solve this problem, you can use a mechanism, for example, <bpt id=\"p1\">[</bpt>std::shared_ptr<ept id=\"p1\">](../../standard-library/shared-ptr-class.md)</ept>, that enables a pointer to be owned by multiple components.","pos":[8967,9149],"source":"To solve this problem, you can use a mechanism, for example, [std::shared_ptr](../../standard-library/shared-ptr-class.md), that enables a pointer to be owned by multiple components."},{"content":"When the final <ph id=\"ph1\">`shared_ptr`</ph> object that owns a resource is destroyed, the resource is also freed.","pos":[9150,9247],"source":" When the final `shared_ptr` object that owns a resource is destroyed, the resource is also freed."},{"content":"The following example demonstrates how to use <ph id=\"ph1\">`shared_ptr`</ph> to share pointer values among multiple message buffers.","pos":[9254,9368],"source":"The following example demonstrates how to use `shared_ptr` to share pointer values among multiple message buffers."},{"content":"The example connects a <bpt id=\"p1\">[</bpt>concurrency::overwrite_buffer<ept id=\"p1\">](../../parallel/concrt/reference/overwrite-buffer-class.md)</ept> object to three <bpt id=\"p2\">[</bpt>concurrency::call<ept id=\"p2\">](../../parallel/concrt/reference/call-class.md)</ept> objects.","pos":[9369,9574],"source":" The example connects a [concurrency::overwrite_buffer](../../parallel/concrt/reference/overwrite-buffer-class.md) object to three [concurrency::call](../../parallel/concrt/reference/call-class.md) objects."},{"content":"The <ph id=\"ph1\">`overwrite_buffer`</ph> class offers messages to each of its targets.","pos":[9575,9643],"source":" The `overwrite_buffer` class offers messages to each of its targets."},{"content":"Because there are multiple owners of the data at the end of the data network, this example uses <ph id=\"ph1\">`shared_ptr`</ph> to enable each <ph id=\"ph2\">`call`</ph> object to share ownership of the messages.","pos":[9644,9817],"source":" Because there are multiple owners of the data at the end of the data network, this example uses `shared_ptr` to enable each `call` object to share ownership of the messages."},{"pos":[9835,9859],"content":"concrt-message-sharing#1"},{"content":"This example produces the following sample output:","pos":[9963,10013]},{"content":"See Also","pos":[10287,10295]},{"content":"Concurrency Runtime Best Practices","pos":[10300,10334]},{"content":"Asynchronous Agents Library","pos":[10402,10429]},{"content":"Walkthrough: Creating an Agent-Based Application","pos":[10490,10538]},{"content":"Walkthrough: Creating a Dataflow Agent","pos":[10619,10657]},{"content":"Walkthrough: Creating an Image-Processing Network","pos":[10728,10777]},{"content":"Best Practices in the Parallel Patterns Library","pos":[10859,10906]},{"content":"General Best Practices in the Concurrency Runtime","pos":[10987,11036]}],"content":"---\ntitle: \"Best Practices in the Asynchronous Agents Library | Microsoft Docs\"\nms.custom: \"\"\nms.date: \"11/04/2016\"\nms.reviewer: \"\"\nms.suite: \"\"\nms.technology: \n  - \"devlang-cpp\"\nms.tgt_pltfrm: \"\"\nms.topic: \"article\"\ndev_langs: \n  - \"C++\"\nhelpviewer_keywords: \n  - \"best practices, Asynchronous Agents Library\"\n  - \"Asynchronous Agents Library, best practices\"\n  - \"Asynchronous Agents Library, practices to avoid\"\n  - \"practices to avoid, Asynchronous Agents Library\"\nms.assetid: 85f52354-41eb-4b0d-98c5-f7344ee8a8cf\ncaps.latest.revision: 15\nauthor: \"mikeblome\"\nms.author: \"mblome\"\nmanager: \"ghogen\"\ntranslation.priority.ht: \n  - \"de-de\"\n  - \"es-es\"\n  - \"fr-fr\"\n  - \"it-it\"\n  - \"ja-jp\"\n  - \"ko-kr\"\n  - \"ru-ru\"\n  - \"zh-cn\"\n  - \"zh-tw\"\ntranslation.priority.mt: \n  - \"cs-cz\"\n  - \"pl-pl\"\n  - \"pt-br\"\n  - \"tr-tr\"\n---\n# Best Practices in the Asynchronous Agents Library\nThis document describes how to make effective use of the Asynchronous Agents Library. The Agents Library promotes an actor-based programming model and in-process message passing for coarse-grained dataflow and pipelining tasks.  \n  \n For more information about the Agents Library, see [Asynchronous Agents Library](../../parallel/concrt/asynchronous-agents-library.md).  \n  \n##  <a name=\"top\"></a> Sections  \n This document contains the following sections:  \n  \n- [Use Agents to Isolate State](#isolation)  \n  \n- [Use a Throttling Mechanism to Limit the Number of Messages in a Data Pipeline](#throttling)  \n  \n- [Do Not Perform Fine-Grained Work in a Data Pipeline](#fine-grained)  \n  \n- [Do Not Pass Large Message Payloads by Value](#large-payloads)  \n  \n- [Use shared_ptr in a Data Network When Ownership Is Undefined](#ownership)  \n  \n##  <a name=\"isolation\"></a> Use Agents to Isolate State  \n The Agents Library provides alternatives to shared state by letting you connect isolated components through an asynchronous message-passing mechanism. Asynchronous agents are most effective when they isolate their internal state from other components. By isolating state, multiple components do not typically act on shared data. State isolation can enable your application to scale because it reduces contention on shared memory. State isolation also reduces the chance of deadlock and race conditions because components do not have to synchronize access to shared data.  \n  \n You typically isolate state in an agent by holding data members in the `private` or `protected` sections of the agent class and by using message buffers to communicate state changes. The following example shows the `basic_agent` class, which derives from [concurrency::agent](../../parallel/concrt/reference/agent-class.md). The `basic_agent` class uses two message buffers to communicate with external components. One message buffer holds incoming messages; the other message buffer holds outgoing messages.  \n  \n [!code-cpp[concrt-simple-agent#1](../../parallel/concrt/codesnippet/cpp/best-practices-in-the-asynchronous-agents-library_1.cpp)]  \n  \n For complete examples about how to define and use agents, see [Walkthrough: Creating an Agent-Based Application](../../parallel/concrt/walkthrough-creating-an-agent-based-application.md) and [Walkthrough: Creating a Dataflow Agent](../../parallel/concrt/walkthrough-creating-a-dataflow-agent.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"throttling\"></a> Use a Throttling Mechanism to Limit the Number of Messages in a Data Pipeline  \n Many message-buffer types, such as [concurrency::unbounded_buffer](reference/unbounded-buffer-class.md), can hold an unlimited number of messages. When a message producer sends messages to a data pipeline faster than the consumer can process these messages, the application can enter a low-memory or out-of-memory state. You can use a throttling mechanism, for example, a semaphore, to limit the number of messages that are concurrently active in a data pipeline.  \n  \n The following basic example demonstrates how to use a semaphore to limit the number of messages in a data pipeline. The data pipeline uses the [concurrency::wait](reference/concurrency-namespace-functions.md#wait) function to simulate an operation that takes at least 100 milliseconds. Because the sender produces messages faster than the consumer can process those messages, this example defines the `semaphore` class to enable the application to limit the number of active messages.  \n  \n [!code-cpp[concrt-message-throttling#1](../../parallel/concrt/codesnippet/cpp/best-practices-in-the-asynchronous-agents-library_2.cpp)]  \n  \n The `semaphore` object limits the pipeline to process at most two messages at the same time.  \n  \n The producer in this example sends relatively few messages to the consumer. Therefore, this example does not demonstrate a potential low-memory or out-of-memory condition. However, this mechanism is useful when a data pipeline contains a relatively high number of messages.  \n  \n For more information about how to create the semaphore class that is used in this example, see [How to: Use the Context Class to Implement a Cooperative Semaphore](../../parallel/concrt/how-to-use-the-context-class-to-implement-a-cooperative-semaphore.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"fine-grained\"></a> Do Not Perform Fine-Grained Work in a Data Pipeline  \n The Agents Library is most useful when the work that is performed by a data pipeline is fairly coarse-grained. For example, one application component might read data from a file or a network connection and occasionally send that data to another component. The protocol that the Agents Library uses to propagate messages causes the message-passing mechanism to have more overhead than the task parallel constructs that are provided by the [Parallel Patterns Library](../../parallel/concrt/parallel-patterns-library-ppl.md) (PPL). Therefore, make sure that the work that is performed by a data pipeline is long enough to offset this overhead.  \n  \n Although a data pipeline is most effective when its tasks are coarse-grained, each stage of the data pipeline can use PPL constructs such as task groups and parallel algorithms to perform more fine-grained work. For an example of a coarse-grained data network that uses fine-grained parallelism at each processing stage, see [Walkthrough: Creating an Image-Processing Network](../../parallel/concrt/walkthrough-creating-an-image-processing-network.md).  \n  \n [[Top](#top)]  \n  \n##  <a name=\"large-payloads\"></a> Do Not Pass Large Message Payloads by Value  \n\n In some cases, the runtime creates a copy of every message that it passes from one message buffer to another message buffer. For example, the [concurrency::overwrite_buffer](../../parallel/concrt/reference/overwrite-buffer-class.md) class offers a copy of every message that it receives to each of its targets. The runtime also creates a copy of the message data when you use message-passing functions such as [concurrency::send](reference/concurrency-namespace-functions.md#send) and [concurrency::receive](reference/concurrency-namespace-functions.md#receive) to write messages to and read messages from a message buffer. Although this mechanism helps eliminate the risk of concurrently writing to shared data, it could lead to poor memory performance when the message payload is relatively large.  \n  \n You can use pointers or references to improve memory performance when you pass messages that have a large payload. The following example compares passing large messages by value to passing pointers to the same message type. The example defines two agent types, `producer` and `consumer`, that act on `message_data` objects. The example compares the time that is required for the producer to send several `message_data` objects to the consumer to the time that is required for the producer agent to send several pointers to `message_data` objects to the consumer.  \n  \n [!code-cpp[concrt-message-payloads#1](../../parallel/concrt/codesnippet/cpp/best-practices-in-the-asynchronous-agents-library_3.cpp)]  \n  \n This example produces the following sample output:  \n  \n```Output  \nUsing message_data...  \ntook 437ms.  \nUsing message_data*...  \ntook 47ms.  \n```  \n  \n The version that uses pointers performs better because it eliminates the requirement for the runtime to create a full copy of every `message_data` object that it passes from the producer to the consumer.  \n  \n [[Top](#top)]  \n  \n##  <a name=\"ownership\"></a> Use shared_ptr in a Data Network When Ownership Is Undefined  \n When you send messages by pointer through a message-passing pipeline or network, you typically allocate the memory for each message at the front of the network and free that memory at the end of the network. Although this mechanism frequently works well, there are cases in which it is difficult or not possible to use it. For example, consider the case in which the data network contains multiple end nodes. In this case, there is no clear location to free the memory for the messages.  \n  \n To solve this problem, you can use a mechanism, for example, [std::shared_ptr](../../standard-library/shared-ptr-class.md), that enables a pointer to be owned by multiple components. When the final `shared_ptr` object that owns a resource is destroyed, the resource is also freed.  \n  \n The following example demonstrates how to use `shared_ptr` to share pointer values among multiple message buffers. The example connects a [concurrency::overwrite_buffer](../../parallel/concrt/reference/overwrite-buffer-class.md) object to three [concurrency::call](../../parallel/concrt/reference/call-class.md) objects. The `overwrite_buffer` class offers messages to each of its targets. Because there are multiple owners of the data at the end of the data network, this example uses `shared_ptr` to enable each `call` object to share ownership of the messages.  \n  \n [!code-cpp[concrt-message-sharing#1](../../parallel/concrt/codesnippet/cpp/best-practices-in-the-asynchronous-agents-library_4.cpp)]  \n  \n This example produces the following sample output:  \n  \n```Output  \nCreating resource 42...  \nreceiver1: received resource 42  \nCreating resource 64...  \nreceiver2: received resource 42  \nreceiver1: received resource 64  \nDestroying resource 42...  \nreceiver2: received resource 64  \nDestroying resource 64...  \n```  \n  \n## See Also  \n [Concurrency Runtime Best Practices](../../parallel/concrt/concurrency-runtime-best-practices.md)   \n [Asynchronous Agents Library](../../parallel/concrt/asynchronous-agents-library.md)   \n [Walkthrough: Creating an Agent-Based Application](../../parallel/concrt/walkthrough-creating-an-agent-based-application.md)   \n [Walkthrough: Creating a Dataflow Agent](../../parallel/concrt/walkthrough-creating-a-dataflow-agent.md)   \n [Walkthrough: Creating an Image-Processing Network](../../parallel/concrt/walkthrough-creating-an-image-processing-network.md)   \n [Best Practices in the Parallel Patterns Library](../../parallel/concrt/best-practices-in-the-parallel-patterns-library.md)   \n [General Best Practices in the Concurrency Runtime](../../parallel/concrt/general-best-practices-in-the-concurrency-runtime.md)\n\n"}